<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta name="description" content="一个秘密空间" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>LISA后探索 |  LegendLeo Chen 的空间</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/mylogo.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
<!-- 封面标闪烁 -->
<link rel="stylesheet" href="/css/zhyBlogTitle.css">
<script src="https://cdn.bootcdn.net/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- jquery，懒加载、统计、说说需要的jquery -->
<script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-LISA后探索"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  LISA后探索
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/" class="article-date">
  <time datetime="2025-07-12T10:14:27.000Z" itemprop="datePublished">2025-07-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a class="article-category-link" href="/categories/%E7%BC%96%E7%A8%8B/">编程</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">8.5k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">37 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>本文接着以下这篇文档：</p>
<a href="/2025/05/21/LISA%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8A%E6%89%8B%E5%92%8C%E5%BE%AE%E8%B0%83/" title="LISA图像分割模型的上手和微调">LISA图像分割模型的上手和微调</a>
<p>本文记录使用个人小数据集实现微调、评估、预测LISA模型之后，进行的更细致的探索，会使用LISA本身用到的大型数据集。<span id="more"></span></p>
<h1 id="🔥概述"><a href="#🔥概述" class="headerlink" title="🔥概述"></a>🔥概述</h1><ul>
<li><p><strong>模型</strong>：LISA；</p>
</li>
<li><p><strong>任务</strong>：各类数据集针对的任务主要有语义分割（这里暂且包含实例分割）、推理分割、指代分割（短语）、视觉问答VQA。其中语义分割的数据集是纯视觉（就给图像和掩码标注等），后三个则带有文本。对于LISA而言即便语义分割也会添加prompt，训练时都是一样要输入图文得到掩码；</p>
</li>
<li><p><strong>数据集</strong>：LISA用的数据集就已经很多了，可以从中选择，暂时先考虑稍微简单点的语义分割和指代分割，其文件结构如下：</p>
</li>
</ul>
<pre class="line-numbers language-plaintext"><code class="language-plaintext">├── dataset
│   ├── ade20k
│   │   ├── annotations
│   │   └── images
│   ├── coco
│   │   └── train2017
│   │       ├── 000000000009.jpg
│   │       └── ...
│   ├── cocostuff
│   │   └── train2017
│   │       ├── 000000000009.png
│   │       └── ...
│   ├── llava_dataset
│   │   └── llava_instruct_150k.json
│   ├── mapillary
│   │   ├── config_v2.0.json
│   │   ├── testing
│   │   ├── training
│   │   └── validation
│   ├── reason_seg
│   │   └── ReasonSeg
│   │       ├── train
│   │       ├── val
│   │       └── explanatory
│   ├── refer_seg
│   │   ├── images
│   │   |   ├── saiapr_tc-12 
│   │   |   └── mscoco
│   │   |       └── images
│   │   |           └── train2014
│   │   ├── refclef
│   │   ├── refcoco
│   │   ├── refcoco+
│   │   └── refcocog
│   └── vlpart
│       ├── paco
│       │   └── annotations
│       └── pascal_part
│           ├── train.json
│           └── VOCdevkit
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>调研了一下其中的部分数据集，都是比较有代表性和热度的，主要就是ade20k。</p>
<table>
<thead>
<tr>
<th>数据集</th>
<th>任务</th>
<th>规模（train&#x2F;val）</th>
<th>排行榜</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>ade20k</td>
<td>语义分割</td>
<td>20k&#x2F;2k</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/semantic-segmentation-on-ade20k-val">验证集</a>、<a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/semantic-segmentation-on-ade20k">全数据集</a></td>
<td>这个数据集的榜有比较多模型参与，大小很合适（20k、2k），适合先行调试用。</td>
</tr>
<tr>
<td>COCO<br>COCO-stuff</td>
<td>语义分割</td>
<td>118k&#x2F;5k</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/semantic-segmentation-on-coco-stuff-test">COCO-stuff</a></td>
<td>前者只有图像，后者只有掩码标注，该数据集排行参与者也不多（可能主要在目标检测多）。</td>
</tr>
<tr>
<td>MSCOCO</td>
<td>语义分割</td>
<td>83k&#x2F;40.5k</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/semantic-segmentation-on-coco-1">MSCOCO</a></td>
<td>只有图，最好的就是HyperSeg，断档高（但是有用额外数据集训练），这个榜没多少模型。</td>
</tr>
<tr>
<td>refCOCO<br>refCOCO+<br>refCOCOg</td>
<td>指代分割</td>
<td>(短语&#x2F;目标&#x2F;图像)<br>142k&#x2F;50k&#x2F;20k、<br>142k&#x2F;50k&#x2F;20k、<br>95k&#x2F;50k&#x2F;26k</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/referring-expression-segmentation-on-refcoco">refCOCO</a>、<a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/referring-expression-segmentation-on-refcoco-3">refCOCO+</a>、<a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/referring-expression-segmentation-on-refcocog">refCOCOg</a></td>
<td>为MSCOCO数据集做文本标注，多模态的分割模型都有用这个模型。</td>
</tr>
</tbody></table>
<ul>
<li><strong>指标</strong>：一般都是mIoU（或者叫gIoU）和cIoU。</li>
</ul>
<h1 id="🔥技术原理"><a href="#🔥技术原理" class="headerlink" title="🔥技术原理"></a>🔥技术原理</h1><p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/LISA%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" alt="LISA网络结构"></p>
<p>这是通过阅读源码得到的更完整的LISA的结构，可以看到LISA使用SAM（用的第一代）时，提示编码器不再像SAM原作一样把点、框、掩码作为提示，而是把多模态大模型输出的<SEG>词元经过MLP编码后作为提示。</SEG></p>
<h2 id="🚀数据流动"><a href="#🚀数据流动" class="headerlink" title="🚀数据流动"></a>🚀数据流动</h2><p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/LISA%E6%95%B0%E6%8D%AE%E6%B5%81%E5%8A%A8%E7%A4%BA%E6%84%8F.png" alt="LISA数据流动示意"></p>
<p>使用<strong>batch size为1</strong>的图片进行输入，他可以得到如上图所示的数据变化，设置每张图随机选择其中<strong>3个mask</strong>作为预测目标。</p>
<ol>
<li><p>左边图像经过裁切、复制操作得到（3目标，3通道，224w，224h）的张量，输入视觉编码器得到（3目标，256长度，1024通道），再映射得到4096通道，此时它就是相当于是文本的token了。</p>
</li>
<li><p>而文本自然是对3个mask的prompt指令，分词编码后长度为41（不固定），图文编码合并后输入llama（正儿八经的LLM）；</p>
</li>
<li><p>llama是transformer自然不改变形状，输出映射到词表做预测，词表32004长，第32004号词是<SEG>；</SEG></p>
</li>
<li><p>输出的序列进入MLP改变通道数，再抽取其中的<SEG>进行SAM的提示编码，接着就是右边部分SAM的流程，参见<a href="https://legendleochen.top/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/#%F0%9F%94%A5%E5%9B%BE%E8%A7%A3%E6%9E%B6%E6%9E%84">《SAM2架构》</a>，最终输出掩码和文本。</SEG></p>
</li>
</ol>
<ul>
<li>可以看到LLAVA的图文输入是匹配的，有多少个目标要分割就要复制同样数量的图，而SAM的设计是只需要一张图，对应多个提示。并且分割领域，一张图通常有多个mask供训练，所以输入模型的batch通常是一张图采样的多个目标（mask），而真正的batch维度——也就是图像是通过循环实现输入，在图像编码等步骤是可以做到并行的，其它时候基本上不是并行的。</li>
</ul>
<h2 id="🚀token处理"><a href="#🚀token处理" class="headerlink" title="🚀token处理"></a>🚀token处理</h2><p>图文token在输入llama之前有进行拼接等操作，这也是多模态大模型和普通大模型的区别所在，因为多了图像编码，原本的文本中会有<code>&lt;IMAGE&gt;</code>这种特殊词元代表图片，在输入LLM前需要把它们替换成对图像抽取的特征token。</p>
<ul>
<li>对<strong>input_ids</strong>的处理流程：</li>
</ul>
<ol>
<li><p>检测token：先在每个样本的<code>input_ids</code>中找出所有<code>&lt;image&gt;</code>的位置。如果根本没碰到，就只做普通的文本embedding并加入<code>new_input_embeds</code>；</p>
</li>
<li><p>输入特征拼接：对于每个样本，遇到文本时正常编码，遇到图像的<code>&lt;image&gt;</code>会替换成图像编码。如果配置了<code>&lt;im_start&gt;</code>和<code>&lt;im_end&gt;</code>，还会把它们也做成embedding加入，如此进行以完成单个输入序列的构建；</p>
</li>
<li><p>长度对齐：把所有序列stack起来，如果不同样本的长度不同，就找到最大值max_len，对每行embedding前面或后面补0到相同长度。同时对<code>attention_mask</code>做相同的pad，使其形状变成[B，new_seq_len]。</p>
</li>
</ol>
<ul>
<li>对<strong>labels</strong>（指的是标注数据的正确回答文本）的处理流程：</li>
</ul>
<ol>
<li><p>初始化：如果原始训练没有传 <code>labels</code>（即只做推理），就直接返回 <code>None</code>；否则，为每个样本构建一个新的 label 序列 <code>cur_new_labels</code>；</p>
</li>
<li><p>每当你把一个 <code>&lt;IMAGE&gt;</code>换成 <code>image_features</code> 时，对应位置在 <code>cur_new_labels</code> 中就插入一个全值为 <code>IGNORE_INDEX</code>（比如 -100）的张量；这样训练时模型不会对这段 embedding 计算交叉熵 loss，因为那部分是图像，不是要预测的文本；</p>
</li>
<li><p>长度对齐：同上。</p>
</li>
</ol>
<h2 id="🚀训练技术"><a href="#🚀训练技术" class="headerlink" title="🚀训练技术"></a>🚀训练技术</h2><p>本节通过阅读train_ds.py脚本了解用到的技术，可以从中了解多模态大模型加载、deepspeed分布式训练、自定义目标层的LoRA等操作如何实现。</p>
<p>首先直接看main函数，先传参，<strong>加载分词器tokenizer</strong>，还会添加<SEG>和标记图像编码开头和结尾的特殊词元，到时候合并图文编码时，图像编码会塞到这个两个词元的位置。</SEG></p>
<pre class="line-numbers language-python"><code class="language-python">    args <span class="token operator">=</span> parse_args<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
    args<span class="token punctuation">.</span>log_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>log_base_dir<span class="token punctuation">,</span> args<span class="token punctuation">.</span>exp_name<span class="token punctuation">)</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>local_rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>args<span class="token punctuation">.</span>log_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span>args<span class="token punctuation">.</span>log_dir<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        writer <span class="token operator">=</span> None

    <span class="token comment" spellcheck="true"># Create model</span>
    tokenizer <span class="token operator">=</span> transformers<span class="token punctuation">.</span>AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
        args<span class="token punctuation">.</span>version<span class="token punctuation">,</span>
        cache_dir<span class="token operator">=</span>None<span class="token punctuation">,</span>
        model_max_length<span class="token operator">=</span>args<span class="token punctuation">.</span>model_max_length<span class="token punctuation">,</span>
        padding_side<span class="token operator">=</span><span class="token string">"right"</span><span class="token punctuation">,</span>
        use_fast<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    tokenizer<span class="token punctuation">.</span>pad_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>unk_token
    num_added_tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>add_tokens<span class="token punctuation">(</span><span class="token string">"[SEG]"</span><span class="token punctuation">)</span>
    args<span class="token punctuation">.</span>seg_token_idx <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">"[SEG]"</span><span class="token punctuation">,</span> add_special_tokens<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>input_ids<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>use_mm_start_end<span class="token punctuation">:</span>
        tokenizer<span class="token punctuation">.</span>add_tokens<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>DEFAULT_IM_START_TOKEN<span class="token punctuation">,</span> DEFAULT_IM_END_TOKEN<span class="token punctuation">]</span><span class="token punctuation">,</span> special_tokens<span class="token operator">=</span><span class="token boolean">True</span>
        <span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>接下来是<strong>加载模型</strong>，半精度加载，<code>vision_pretrained</code>指的是视觉网络也就是SAM，<code>vision_tower</code>是LLAVA的视觉编码器。</p>
<pre class="line-numbers language-python"><code class="language-python">    model_args <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">"train_mask_decoder"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>train_mask_decoder<span class="token punctuation">,</span>
        <span class="token string">"out_dim"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>out_dim<span class="token punctuation">,</span>
        <span class="token string">"ce_loss_weight"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>ce_loss_weight<span class="token punctuation">,</span>
        <span class="token string">"dice_loss_weight"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>dice_loss_weight<span class="token punctuation">,</span>
        <span class="token string">"bce_loss_weight"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>bce_loss_weight<span class="token punctuation">,</span>
        <span class="token string">"seg_token_idx"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>seg_token_idx<span class="token punctuation">,</span>
        <span class="token string">"vision_pretrained"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>vision_pretrained<span class="token punctuation">,</span>
        <span class="token string">"vision_tower"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>vision_tower<span class="token punctuation">,</span>
        <span class="token string">"use_mm_start_end"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>use_mm_start_end<span class="token punctuation">,</span>
    <span class="token punctuation">}</span>
    torch_dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>float32
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>precision <span class="token operator">==</span> <span class="token string">"bf16"</span><span class="token punctuation">:</span>
        torch_dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>bfloat16
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>precision <span class="token operator">==</span> <span class="token string">"fp16"</span><span class="token punctuation">:</span>
        torch_dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>half
    model <span class="token operator">=</span> LISAForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
        args<span class="token punctuation">.</span>version<span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch_dtype<span class="token punctuation">,</span> low_cpu_mem_usage<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>model_args
    <span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>eos_token_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>eos_token_id
    model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>bos_token_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>bos_token_id
    model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>pad_token_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>pad_token_id

    model<span class="token punctuation">.</span>enable_input_require_grads<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>gradient_checkpointing_enable<span class="token punctuation">(</span><span class="token punctuation">)</span>

    model<span class="token punctuation">.</span>get_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>initialize_vision_modules<span class="token punctuation">(</span>model<span class="token punctuation">.</span>get_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">)</span>
    vision_tower <span class="token operator">=</span> model<span class="token punctuation">.</span>get_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_vision_tower<span class="token punctuation">(</span><span class="token punctuation">)</span>
    vision_tower<span class="token punctuation">.</span>to<span class="token punctuation">(</span>dtype<span class="token operator">=</span>torch_dtype<span class="token punctuation">,</span> device<span class="token operator">=</span>args<span class="token punctuation">.</span>local_rank<span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token operator">not</span> args<span class="token punctuation">.</span>eval_only<span class="token punctuation">:</span>
        model<span class="token punctuation">.</span>get_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>initialize_lisa_modules<span class="token punctuation">(</span>model<span class="token punctuation">.</span>get_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">)</span>

    <span class="token keyword">for</span> p <span class="token keyword">in</span> vision_tower<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>
    <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>get_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mm_projector<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>

    conversation_lib<span class="token punctuation">.</span>default_conversation <span class="token operator">=</span> conversation_lib<span class="token punctuation">.</span>conv_templates<span class="token punctuation">[</span>
        args<span class="token punctuation">.</span>conv_type
    <span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>接着<strong>加入LoRA权重</strong>，<code>find_linear_layers()</code>是找出模型中特定层并返回层名的列表，这里选定的是线性层，并且排除了视觉相关模块，也就是不微调视觉编码的网络。<code>args.lora_target_modules.split(&quot;,&quot;)</code>选定的是”q_proj,v_proj”，也就是Q和V的矩阵加LoRA权重。</p>
<pre class="line-numbers language-python"><code class="language-python">    lora_r <span class="token operator">=</span> args<span class="token punctuation">.</span>lora_r
    <span class="token keyword">if</span> lora_r <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>

        <span class="token keyword">def</span> <span class="token function">find_linear_layers</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> lora_target_modules<span class="token punctuation">)</span><span class="token punctuation">:</span>
            cls <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear
            lora_module_names <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> name<span class="token punctuation">,</span> module <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span>
                    isinstance<span class="token punctuation">(</span>module<span class="token punctuation">,</span> cls<span class="token punctuation">)</span>
                    <span class="token operator">and</span> all<span class="token punctuation">(</span>
                        <span class="token punctuation">[</span>
                            x <span class="token operator">not</span> <span class="token keyword">in</span> name
                            <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token punctuation">[</span>
                                <span class="token string">"visual_model"</span><span class="token punctuation">,</span>
                                <span class="token string">"vision_tower"</span><span class="token punctuation">,</span>
                                <span class="token string">"mm_projector"</span><span class="token punctuation">,</span>
                                <span class="token string">"text_hidden_fcs"</span><span class="token punctuation">,</span>
                            <span class="token punctuation">]</span>
                        <span class="token punctuation">]</span>
                    <span class="token punctuation">)</span>
                    <span class="token operator">and</span> any<span class="token punctuation">(</span><span class="token punctuation">[</span>x <span class="token keyword">in</span> name <span class="token keyword">for</span> x <span class="token keyword">in</span> lora_target_modules<span class="token punctuation">]</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span><span class="token punctuation">:</span>
                    lora_module_names<span class="token punctuation">.</span>add<span class="token punctuation">(</span>name<span class="token punctuation">)</span>
            <span class="token keyword">return</span> sorted<span class="token punctuation">(</span>list<span class="token punctuation">(</span>lora_module_names<span class="token punctuation">)</span><span class="token punctuation">)</span>

        lora_alpha <span class="token operator">=</span> args<span class="token punctuation">.</span>lora_alpha
        lora_dropout <span class="token operator">=</span> args<span class="token punctuation">.</span>lora_dropout
        lora_target_modules <span class="token operator">=</span> find_linear_layers<span class="token punctuation">(</span>
            model<span class="token punctuation">,</span> args<span class="token punctuation">.</span>lora_target_modules<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        lora_config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>
            r<span class="token operator">=</span>lora_r<span class="token punctuation">,</span>
            lora_alpha<span class="token operator">=</span>lora_alpha<span class="token punctuation">,</span>
            target_modules<span class="token operator">=</span>lora_target_modules<span class="token punctuation">,</span>
            lora_dropout<span class="token operator">=</span>lora_dropout<span class="token punctuation">,</span>
            bias<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span>
            task_type<span class="token operator">=</span><span class="token string">"CAUSAL_LM"</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> lora_config<span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>print_trainable_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>把一些层的部分变得可训练，也就是这些层是<strong>全量微调</strong>的，<code>torch.cuda.device_count()</code>是有多少个GPU。</p>
<pre class="line-numbers language-python"><code class="language-python">    model<span class="token punctuation">.</span>resize_token_embeddings<span class="token punctuation">(</span>len<span class="token punctuation">(</span>tokenizer<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># make text_hidden_fcs, mask_decoder, lm_head, embed_tokens trainable</span>
    <span class="token keyword">for</span> n<span class="token punctuation">,</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> any<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>
                x <span class="token keyword">in</span> n
                <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"lm_head"</span><span class="token punctuation">,</span> <span class="token string">"embed_tokens"</span><span class="token punctuation">,</span> <span class="token string">"mask_decoder"</span><span class="token punctuation">,</span> <span class="token string">"text_hidden_fcs"</span><span class="token punctuation">]</span>
            <span class="token punctuation">]</span>
        <span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"n: "</span><span class="token punctuation">,</span> n<span class="token punctuation">,</span> <span class="token string">"p.shape: "</span><span class="token punctuation">,</span> p<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>

    world_size <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span>
    args<span class="token punctuation">.</span>distributed <span class="token operator">=</span> world_size <span class="token operator">></span> <span class="token number">1</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>数据集加载</strong>，训练集会读取多个设定好的数据集，采样会随机抽，验证集则只支持refer_seg和reason_seg，数据集详情见下一节。</p>
<pre class="line-numbers language-python"><code class="language-python">    train_dataset <span class="token operator">=</span> HybridDataset<span class="token punctuation">(</span>
        args<span class="token punctuation">.</span>dataset_dir<span class="token punctuation">,</span>
        tokenizer<span class="token punctuation">,</span>
        args<span class="token punctuation">.</span>vision_tower<span class="token punctuation">,</span>
        samples_per_epoch<span class="token operator">=</span>args<span class="token punctuation">.</span>batch_size
        <span class="token operator">*</span> args<span class="token punctuation">.</span>grad_accumulation_steps
        <span class="token operator">*</span> args<span class="token punctuation">.</span>steps_per_epoch
        <span class="token operator">*</span> world_size<span class="token punctuation">,</span>
        precision<span class="token operator">=</span>args<span class="token punctuation">.</span>precision<span class="token punctuation">,</span>
        image_size<span class="token operator">=</span>args<span class="token punctuation">.</span>image_size<span class="token punctuation">,</span>
        num_classes_per_sample<span class="token operator">=</span>args<span class="token punctuation">.</span>num_classes_per_sample<span class="token punctuation">,</span>
        exclude_val<span class="token operator">=</span>args<span class="token punctuation">.</span>exclude_val<span class="token punctuation">,</span>
        dataset<span class="token operator">=</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">,</span>
        sample_rate<span class="token operator">=</span><span class="token punctuation">[</span>float<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> args<span class="token punctuation">.</span>sample_rates<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        sem_seg_data<span class="token operator">=</span>args<span class="token punctuation">.</span>sem_seg_data<span class="token punctuation">,</span>
        refer_seg_data<span class="token operator">=</span>args<span class="token punctuation">.</span>refer_seg_data<span class="token punctuation">,</span>
        vqa_data<span class="token operator">=</span>args<span class="token punctuation">.</span>vqa_data<span class="token punctuation">,</span>
        reason_seg_data<span class="token operator">=</span>args<span class="token punctuation">.</span>reason_seg_data<span class="token punctuation">,</span>
        explanatory<span class="token operator">=</span>args<span class="token punctuation">.</span>explanatory<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>no_eval <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">:</span>
        val_dataset <span class="token operator">=</span> ValDataset<span class="token punctuation">(</span>
            args<span class="token punctuation">.</span>dataset_dir<span class="token punctuation">,</span>
            tokenizer<span class="token punctuation">,</span>
            args<span class="token punctuation">.</span>vision_tower<span class="token punctuation">,</span>
            args<span class="token punctuation">.</span>val_dataset<span class="token punctuation">,</span>
            args<span class="token punctuation">.</span>image_size<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>
            f<span class="token string">"Training with {len(train_dataset)} examples and validating with {len(val_dataset)} examples."</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        val_dataset <span class="token operator">=</span> None
        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Training with {len(train_dataset)} examples."</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>deepspeed分布式训练器</strong>及其配置如下，大部分都是传参，优化器用的adamw，使用warmup学习率调度，也就是前100步学习率会慢慢上升至预设的学习率，后面就会线性下降到最小值。<code>zero_optimization</code>是deepspeed的zero优化，它把网络不同层的<strong>梯度存储和计算</strong>分配给不同GPU并行完成，优化了通信效率和显存压力。<code>deepspeed.initialize()</code>就会得到分布式的训练模型<code>model_engine</code>，它本质也是<code>nn.Module</code>，所以用起来和非分布式没什么区别。</p>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/Zero%E5%8E%9F%E7%90%86.png" alt="Zero原理.png"></p>
<ul>
<li><p>Zero-0：不使用所有类型的分片，仅使用DeepSpeed作为DDP，速度最快（显存够时使用）;</p>
</li>
<li><p>Zero-1：切分优化器状态，分片到每个数据并行的工作进程(每个GPU)下；有微小的速度提升;</p>
</li>
<li><p>Zero-2：切分优化器状态 + 梯度，分片到每个数据并行的工作进程(每个GPU)下;</p>
</li>
<li><p>Zero-3：切分优化器状态 + 梯度 + 模型参数，分片到每个数据并行的工作进程(每个GPU)下。</p>
</li>
</ul>
<p>如上，Zero Stage从0-3训练速度越来越慢（不用offload），但训练所需显存递减。详情参考该文<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/650824387">知乎</a>。</p>
<pre class="line-numbers language-python"><code class="language-python">    ds_config <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">"train_micro_batch_size_per_gpu"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>
        <span class="token string">"gradient_accumulation_steps"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>grad_accumulation_steps<span class="token punctuation">,</span>
        <span class="token string">"optimizer"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
            <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"AdamW"</span><span class="token punctuation">,</span>
            <span class="token string">"params"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                <span class="token string">"lr"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span>
                <span class="token string">"weight_decay"</span><span class="token punctuation">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span>
                <span class="token string">"betas"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>args<span class="token punctuation">.</span>beta1<span class="token punctuation">,</span> args<span class="token punctuation">.</span>beta2<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token string">"scheduler"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
            <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"WarmupDecayLR"</span><span class="token punctuation">,</span>
            <span class="token string">"params"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                <span class="token string">"total_num_steps"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>epochs <span class="token operator">*</span> args<span class="token punctuation">.</span>steps_per_epoch<span class="token punctuation">,</span>
                <span class="token string">"warmup_min_lr"</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
                <span class="token string">"warmup_max_lr"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span>
                <span class="token string">"warmup_num_steps"</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token punctuation">,</span>
                <span class="token string">"warmup_type"</span><span class="token punctuation">:</span> <span class="token string">"linear"</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token string">"fp16"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
            <span class="token string">"enabled"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>precision <span class="token operator">==</span> <span class="token string">"fp16"</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token string">"bf16"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
            <span class="token string">"enabled"</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>precision <span class="token operator">==</span> <span class="token string">"bf16"</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token string">"gradient_clipping"</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
        <span class="token string">"zero_optimization"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
            <span class="token string">"stage"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
            <span class="token string">"contiguous_gradients"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
            <span class="token string">"overlap_comm"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
            <span class="token string">"reduce_scatter"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
            <span class="token string">"reduce_bucket_size"</span><span class="token punctuation">:</span> <span class="token number">5e8</span><span class="token punctuation">,</span>
            <span class="token string">"allgather_bucket_size"</span><span class="token punctuation">:</span> <span class="token number">5e8</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>
    model_engine<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> scheduler <span class="token operator">=</span> deepspeed<span class="token punctuation">.</span>initialize<span class="token punctuation">(</span>
        model<span class="token operator">=</span>model<span class="token punctuation">,</span>
        model_parameters<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        training_data<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>
        collate_fn<span class="token operator">=</span>partial<span class="token punctuation">(</span>
            collate_fn<span class="token punctuation">,</span>
            tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
            conv_type<span class="token operator">=</span>args<span class="token punctuation">.</span>conv_type<span class="token punctuation">,</span>
            use_mm_start_end<span class="token operator">=</span>args<span class="token punctuation">.</span>use_mm_start_end<span class="token punctuation">,</span>
            local_rank<span class="token operator">=</span>args<span class="token punctuation">.</span>local_rank<span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        config<span class="token operator">=</span>ds_config<span class="token punctuation">,</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>然后是一些杂项，如果是<strong>恢复训练</strong>，就可以加载存好的检查点checkpoint。deepspeed会在优化器参数中存储模型的主参数，存储在<code>global_step*/*optim_states.pt</code> 文件中，数据类型为fp32。想要从checkpoint中恢复训练，不用动什么配置，直接重新启动程序即可。</p>
<p>然后<strong>把验证集设成分布式</strong>的，训练集不设置是因为本来就是随机抽样训练，每张卡各干各的就行了，而验证集就配合一起测完。</p>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token comment" spellcheck="true"># resume deepspeed checkpoint</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>auto_resume <span class="token operator">and</span> len<span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        resume <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>log_dir<span class="token punctuation">,</span> <span class="token string">"ckpt_model"</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>resume<span class="token punctuation">)</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>resume <span class="token operator">=</span> resume

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>resume<span class="token punctuation">:</span>
        load_path<span class="token punctuation">,</span> client_state <span class="token operator">=</span> model_engine<span class="token punctuation">.</span>load_checkpoint<span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">)</span>
        <span class="token keyword">with</span> open<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">,</span> <span class="token string">"latest"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            ckpt_dir <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
        args<span class="token punctuation">.</span>start_epoch <span class="token operator">=</span> <span class="token punctuation">(</span>
            int<span class="token punctuation">(</span>ckpt_dir<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"global_step"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">//</span> args<span class="token punctuation">.</span>steps_per_epoch
        <span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>
            <span class="token string">"resume training from {}, start from epoch {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>
                args<span class="token punctuation">.</span>resume<span class="token punctuation">,</span> args<span class="token punctuation">.</span>start_epoch
            <span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># validation dataset</span>
    <span class="token keyword">if</span> val_dataset <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
        <span class="token keyword">assert</span> args<span class="token punctuation">.</span>val_batch_size <span class="token operator">==</span> <span class="token number">1</span>
        val_sampler <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>DistributedSampler<span class="token punctuation">(</span>
            val_dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span>
        <span class="token punctuation">)</span>
        val_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
            val_dataset<span class="token punctuation">,</span>
            batch_size<span class="token operator">=</span>args<span class="token punctuation">.</span>val_batch_size<span class="token punctuation">,</span>
            shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
            num_workers<span class="token operator">=</span>args<span class="token punctuation">.</span>workers<span class="token punctuation">,</span>
            pin_memory<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
            sampler<span class="token operator">=</span>val_sampler<span class="token punctuation">,</span>
            collate_fn<span class="token operator">=</span>partial<span class="token punctuation">(</span>
                collate_fn<span class="token punctuation">,</span>
                tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
                conv_type<span class="token operator">=</span>args<span class="token punctuation">.</span>conv_type<span class="token punctuation">,</span>
                use_mm_start_end<span class="token operator">=</span>args<span class="token punctuation">.</span>use_mm_start_end<span class="token punctuation">,</span>
                local_rank<span class="token operator">=</span>args<span class="token punctuation">.</span>local_rank<span class="token punctuation">,</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>接着就进入<strong>训练和评估</strong>环节了：</p>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">if</span> args<span class="token punctuation">.</span>eval_only<span class="token punctuation">:</span>
        giou<span class="token punctuation">,</span> ciou <span class="token operator">=</span> validate<span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> model_engine<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> writer<span class="token punctuation">,</span> args<span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>args<span class="token punctuation">.</span>start_epoch<span class="token punctuation">,</span> args<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># train for one epoch</span>
        train_iter <span class="token operator">=</span> train<span class="token punctuation">(</span>
            train_loader<span class="token punctuation">,</span>
            model_engine<span class="token punctuation">,</span>
            epoch<span class="token punctuation">,</span>
            scheduler<span class="token punctuation">,</span>
            writer<span class="token punctuation">,</span>
            train_iter<span class="token punctuation">,</span>
            args<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token keyword">if</span> args<span class="token punctuation">.</span>no_eval <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">:</span>
            giou<span class="token punctuation">,</span> ciou <span class="token operator">=</span> validate<span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> model_engine<span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> writer<span class="token punctuation">,</span> args<span class="token punctuation">)</span>
            is_best <span class="token operator">=</span> giou <span class="token operator">></span> best_score
            best_score <span class="token operator">=</span> max<span class="token punctuation">(</span>giou<span class="token punctuation">,</span> best_score<span class="token punctuation">)</span>
            cur_ciou <span class="token operator">=</span> ciou <span class="token keyword">if</span> is_best <span class="token keyword">else</span> cur_ciou

        <span class="token keyword">if</span> args<span class="token punctuation">.</span>no_eval <span class="token operator">or</span> is_best<span class="token punctuation">:</span>
            save_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>log_dir<span class="token punctuation">,</span> <span class="token string">"ckpt_model"</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> args<span class="token punctuation">.</span>local_rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>
                    <span class="token punctuation">{</span><span class="token string">"epoch"</span><span class="token punctuation">:</span> epoch<span class="token punctuation">}</span><span class="token punctuation">,</span>
                    os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>
                        args<span class="token punctuation">.</span>log_dir<span class="token punctuation">,</span>
                        <span class="token string">"meta_log_giou{:.3f}_ciou{:.3f}.pth"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>
                            best_score<span class="token punctuation">,</span> cur_ciou
                        <span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
                <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>save_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    shutil<span class="token punctuation">.</span>rmtree<span class="token punctuation">(</span>save_dir<span class="token punctuation">)</span>
            torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>
            model_engine<span class="token punctuation">.</span>save_checkpoint<span class="token punctuation">(</span>save_dir<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>训练和评估的函数不多记录，和常规深度学习训练一样。<strong>可以看到deepspeed使得分布式训练和一般的训练使用起来没什么两样，这个框架所有算法需要关心的细节都浓缩到了配置项里面。</strong></p>
<h1 id="🔥数据集"><a href="#🔥数据集" class="headerlink" title="🔥数据集"></a>🔥数据集</h1><h2 id="🚀ade20k"><a href="#🚀ade20k" class="headerlink" title="🚀ade20k"></a>🚀ade20k</h2><p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/ade20k%E6%95%B0%E6%8D%AE%E9%9B%86.png" alt="ade20k数据集"></p>
<ul>
<li>每张图都有若干个mask，每个mask的值对应一个分类，LISA在utils&#x2F;sem_seg_dataset.py中的<code>SemSegDataset</code>为该数据集提供了处理方法，每张图被dataloader加载时，会随机选择该图包含的类别中的若干个，分别取其掩码，并生成对应的问答。也就是一图多个目标，每个目标对应一个类别、一个问答和一个掩码。这个数据集datasets类可以移植SAM2这边，但是需要去掉对话部分增加点作为提示。</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SemSegDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    pixel_mean <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    pixel_std <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    img_size <span class="token operator">=</span> <span class="token number">1024</span>
    ignore_label <span class="token operator">=</span> <span class="token number">255</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        base_image_dir<span class="token punctuation">,</span>
        image_size<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">1024</span><span class="token punctuation">,</span>
        num_classes_per_sample<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>None<span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform
        self<span class="token punctuation">.</span>num_classes_per_sample <span class="token operator">=</span> num_classes_per_sample

        self<span class="token punctuation">.</span>base_image_dir <span class="token operator">=</span> base_image_dir
        self<span class="token punctuation">.</span>image_size <span class="token operator">=</span> image_size

        classes<span class="token punctuation">,</span> images<span class="token punctuation">,</span> labels <span class="token operator">=</span> self<span class="token punctuation">.</span>init_ade20k<span class="token punctuation">(</span>base_image_dir<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classes <span class="token operator">=</span> classes

    <span class="token keyword">def</span> <span class="token function">init_ade20k</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> base_image_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"./ade20k_classes.json"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            ade20k_classes <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
        ade20k_classes <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>ade20k_classes<span class="token punctuation">)</span>
        image_ids <span class="token operator">=</span> sorted<span class="token punctuation">(</span>
            os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_image_dir<span class="token punctuation">,</span> <span class="token string">"ade20k/images"</span><span class="token punctuation">,</span> <span class="token string">"training"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        ade20k_image_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> x <span class="token keyword">in</span> image_ids<span class="token punctuation">:</span>
            <span class="token keyword">if</span> x<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">".jpg"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                ade20k_image_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        ade20k_images <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> image_id <span class="token keyword">in</span> ade20k_image_ids<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># self.descriptions:</span>
            ade20k_images<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>
                    base_image_dir<span class="token punctuation">,</span>
                    <span class="token string">"ade20k"</span><span class="token punctuation">,</span>
                    <span class="token string">"images"</span><span class="token punctuation">,</span>
                    <span class="token string">"training"</span><span class="token punctuation">,</span>
                    <span class="token string">"{}.jpg"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>image_id<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
        ade20k_labels <span class="token operator">=</span> <span class="token punctuation">[</span>
            x<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">".jpg"</span><span class="token punctuation">,</span> <span class="token string">".png"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"images"</span><span class="token punctuation">,</span> <span class="token string">"annotations"</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> x <span class="token keyword">in</span> ade20k_images
        <span class="token punctuation">]</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ade20k: "</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>ade20k_images<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> ade20k_classes<span class="token punctuation">,</span> ade20k_images<span class="token punctuation">,</span> ade20k_labels
    
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Normalize pixel values and pad to a square input."""</span>
        <span class="token comment" spellcheck="true"># Normalize colors</span>
        x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> self<span class="token punctuation">.</span>pixel_mean<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>pixel_std

        <span class="token comment" spellcheck="true"># Pad</span>
        h<span class="token punctuation">,</span> w <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        padh <span class="token operator">=</span> self<span class="token punctuation">.</span>img_size <span class="token operator">-</span> h
        padw <span class="token operator">=</span> self<span class="token punctuation">.</span>img_size <span class="token operator">-</span> w
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> padw<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> padh<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">padding</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Pad</span>
        h<span class="token punctuation">,</span> w <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        padh <span class="token operator">=</span> self<span class="token punctuation">.</span>img_size <span class="token operator">-</span> h
        padw <span class="token operator">=</span> self<span class="token punctuation">.</span>img_size <span class="token operator">-</span> w
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> padw<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> padh<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image<span class="token punctuation">,</span> labels <span class="token operator">=</span> self<span class="token punctuation">.</span>data
        image_path <span class="token operator">=</span> image<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        label_path <span class="token operator">=</span> labels<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        
        label <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>label_path<span class="token punctuation">)</span>
        label <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>label<span class="token punctuation">)</span>
        label<span class="token punctuation">[</span>label <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">255</span>
        label <span class="token operator">-=</span> <span class="token number">1</span>
        label<span class="token punctuation">[</span>label <span class="token operator">==</span> <span class="token number">254</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">255</span>

        img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>
        image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span>img<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>COLOR_BGR2RGB<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># if self.transform:</span>
        <span class="token comment" spellcheck="true">#     image = self.transform(image)</span>
            
        unique_label <span class="token operator">=</span> np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 按类别分出所有mask</span>
        <span class="token keyword">if</span> <span class="token number">255</span> <span class="token keyword">in</span> unique_label<span class="token punctuation">:</span>
            unique_label<span class="token punctuation">.</span>remove<span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>unique_label<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>__getitem__<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

        classes <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>classes<span class="token punctuation">[</span>class_id<span class="token punctuation">]</span> <span class="token keyword">for</span> class_id <span class="token keyword">in</span> unique_label<span class="token punctuation">]</span>     <span class="token comment" spellcheck="true"># 图中有的类名</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>classes<span class="token punctuation">)</span> <span class="token operator">>=</span> self<span class="token punctuation">.</span>num_classes_per_sample<span class="token punctuation">:</span>
            sampled_classes <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>
                classes<span class="token punctuation">,</span> size<span class="token operator">=</span>self<span class="token punctuation">.</span>num_classes_per_sample<span class="token punctuation">,</span> replace<span class="token operator">=</span><span class="token boolean">False</span>
            <span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            sampled_classes <span class="token operator">=</span> classes

        class_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                  <span class="token comment" spellcheck="true"># 类别索引</span>
        <span class="token keyword">for</span> sampled_cls <span class="token keyword">in</span> sampled_classes<span class="token punctuation">:</span>
            class_id <span class="token operator">=</span> self<span class="token punctuation">.</span>classes<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>index<span class="token punctuation">(</span>sampled_cls<span class="token punctuation">)</span>
            class_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>class_id<span class="token punctuation">)</span>

        image <span class="token operator">=</span> self<span class="token punctuation">.</span>preprocess<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        label <span class="token operator">=</span> self<span class="token punctuation">.</span>padding<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        masks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        points <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        points_label <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> class_id <span class="token keyword">in</span> class_ids<span class="token punctuation">:</span>
            mask <span class="token operator">=</span> label <span class="token operator">==</span> class_id
            masks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>mask<span class="token punctuation">)</span>
            coords <span class="token operator">=</span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>mask<span class="token punctuation">,</span> as_tuple<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 坐标点</span>
            <span class="token keyword">if</span> coords<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
                coords <span class="token operator">=</span> coords<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
                yx <span class="token operator">=</span> coords<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> coords<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
                points<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>yx<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> yx<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                points_label<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                points<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                points_label<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        
        masks <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>masks<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>
            image<span class="token punctuation">,</span>
            masks<span class="token punctuation">,</span>
            np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>points<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span>
            np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>points_label<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># label,</span>
            <span class="token comment" spellcheck="true"># sampled_classes,</span>
            <span class="token comment" spellcheck="true"># image_path</span>
        <span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>用SAM2微调一手（50个epoch）有提升，可以看到相较于2k样本左右的LabPicsV1数据集，这个20k的数据集指标就不可能那么高了：</p>
<table>
<thead>
<tr>
<th>规模</th>
<th>IoU</th>
<th>GIoU</th>
<th>CIoU</th>
<th>Dice</th>
<th>PA</th>
<th>F1</th>
</tr>
</thead>
<tbody><tr>
<td>SAM2（L）</td>
<td>0.514</td>
<td>0219</td>
<td>0.467</td>
<td>0.610</td>
<td>0.952</td>
<td>0.193</td>
</tr>
<tr>
<td>SAM2（L，ft）exp17</td>
<td>0.594</td>
<td>0.197</td>
<td>0.560</td>
<td>0.683</td>
<td>0.981</td>
<td>0.251</td>
</tr>
</tbody></table>
<h2 id="🚀COCO-stuff"><a href="#🚀COCO-stuff" class="headerlink" title="🚀COCO-stuff"></a>🚀COCO-stuff</h2><p>这数据集结构应该和ade20k差不多，标注也是一样的。</p>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/cocostuff%E6%95%B0%E6%8D%AE%E9%9B%86.png" alt="COCO-stuff数据集"></p>
<h2 id="🚀refCOCO系列"><a href="#🚀refCOCO系列" class="headerlink" title="🚀refCOCO系列"></a>🚀refCOCO系列</h2><p>refCOCO&#x2F;refCOCO+&#x2F;refCOCOg结构应该是一样的，接下来根据LISA读取数据集的相关函数进行debug我们可以看到其数据的构成。</p>
<ul>
<li>一个<strong>instances.json</strong>文件，记录了每个图像都信息<strong>images</strong>：</li>
</ul>
<pre class="line-numbers language-json"><code class="language-json"><span class="token punctuation">{</span>
  <span class="token property">"license"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
  <span class="token property">"file_name"</span><span class="token operator">:</span> <span class="token string">"COCO_train2014_000000098304.jpg"</span><span class="token punctuation">,</span>
  <span class="token property">"coco_url"</span><span class="token operator">:</span> <span class="token string">"http://mscoco.org/images/98304"</span><span class="token punctuation">,</span>
  <span class="token property">"height"</span><span class="token operator">:</span> <span class="token number">424</span><span class="token punctuation">,</span>
  <span class="token property">"width"</span><span class="token operator">:</span> <span class="token number">640</span><span class="token punctuation">,</span>
  <span class="token property">"date_captured"</span><span class="token operator">:</span> <span class="token string">"2013-11-21 23:06:41"</span><span class="token punctuation">,</span>
  <span class="token property">"flickr_url"</span><span class="token operator">:</span> <span class="token string">"http://farm6.staticflickr.com/5062/5896644212_a326e96ea9_z.jpg"</span><span class="token punctuation">,</span>
  <span class="token property">"id"</span><span class="token operator">:</span> <span class="token number">98304</span>
<span class="token punctuation">}</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>标注信息<strong>annotations</strong>，为所有目标（一个图会有多个目标）提供了边界框、mask等信息，掩码是记录多边形顶点：</li>
</ul>
<pre class="line-numbers language-json"><code class="language-json"><span class="token punctuation">{</span>
  <span class="token property">"segmentation"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>...<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token property">"area"</span><span class="token operator">:</span> <span class="token number">197.29899999999986</span><span class="token punctuation">,</span>
  <span class="token property">"iscrowd"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">"image_id"</span><span class="token operator">:</span> <span class="token number">98304</span><span class="token punctuation">,</span>
  <span class="token property">"bbox"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">263.87</span><span class="token punctuation">,</span> <span class="token number">216.88</span><span class="token punctuation">,</span> <span class="token number">21.13</span><span class="token punctuation">,</span> <span class="token number">15.17</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token property">"category_id"</span><span class="token operator">:</span> <span class="token number">18</span><span class="token punctuation">,</span>
  <span class="token property">"id"</span><span class="token operator">:</span> <span class="token number">3007</span>
<span class="token punctuation">}</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>80个分类<strong>categories</strong>：</li>
</ul>
<pre class="line-numbers language-json"><code class="language-json"><span class="token punctuation">{</span>
  <span class="token property">"supercategory"</span><span class="token operator">:</span> <span class="token string">"person"</span><span class="token punctuation">,</span>
  <span class="token property">"id"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
  <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"person"</span>
<span class="token punctuation">}</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>一个.p结尾的文件<strong>ref(unc).p</strong>，记录每个图的每个目标的<strong>描述文本</strong>，split表示属于训练集（train）、验证集（val）：</li>
</ul>
<pre class="line-numbers language-json"><code class="language-json"><span class="token punctuation">{</span>
  <span class="token property">"sent_ids"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token property">"file_name"</span><span class="token operator">:</span> <span class="token string">"COCO_train2014_000000581857_16.jpg"</span><span class="token punctuation">,</span>
  <span class="token property">"ann_id"</span><span class="token operator">:</span> <span class="token number">1719310</span><span class="token punctuation">,</span>
  <span class="token property">"ref_id"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">"image_id"</span><span class="token operator">:</span> <span class="token number">581857</span><span class="token punctuation">,</span>
  <span class="token property">"split"</span><span class="token operator">:</span> <span class="token string">"train"</span><span class="token punctuation">,</span>
  <span class="token property">"sentences"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
      <span class="token property">"tokens"</span><span class="token operator">:</span> <span class="token punctuation">[</span>...<span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token property">"raw"</span><span class="token operator">:</span> <span class="token string">"THE LADY WITH THE BLUE SHIRT"</span><span class="token punctuation">,</span>
      <span class="token property">"sent_id"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
      <span class="token property">"sent"</span><span class="token operator">:</span> <span class="token string">"the lady with the blue shirt"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
      <span class="token property">"tokens"</span><span class="token operator">:</span> <span class="token punctuation">[</span>...<span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token property">"raw"</span><span class="token operator">:</span> <span class="token string">"lady w back to us"</span><span class="token punctuation">,</span>
      <span class="token property">"sent_id"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
      <span class="token property">"sent"</span><span class="token operator">:</span> <span class="token string">"lady with back to us"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
      <span class="token property">"tokens"</span><span class="token operator">:</span> <span class="token punctuation">[</span>...<span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token property">"raw"</span><span class="token operator">:</span> <span class="token string">"blue shirt"</span><span class="token punctuation">,</span>
      <span class="token property">"sent_id"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
      <span class="token property">"sent"</span><span class="token operator">:</span> <span class="token string">"blue shirt"</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token property">"category_id"</span><span class="token operator">:</span> <span class="token number">1</span>
<span class="token punctuation">}</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>refclef也是和refcoco系列一样的，使用MSCOCO作为图像源，但是是比较早的，表达不够自然，偏人工合成风格。</p>
<h2 id="🚀ReasonSeg"><a href="#🚀ReasonSeg" class="headerlink" title="🚀ReasonSeg"></a>🚀ReasonSeg</h2><p>LISA做的数据集，就一千多张图，标注内容主要为推理文本和多边形标注的mask，也就是文本上不会直接提出目标的名字，而是提供推理的线索，如下图为例。其它其实和refCOCO差不多。</p>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/reasonseg%E6%95%B0%E6%8D%AE%E9%9B%86.jpeg" alt="&quot;the source of power for the ship&quot;"></p>
<table>
<thead>
<tr>
<th>字段名</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>text</code></td>
<td>字符串</td>
<td>问题文本，用于引导模型在图像中寻找相关区域进行回答。通常为完整英文句子。</td>
</tr>
<tr>
<td><code>is_sentence</code></td>
<td>布尔值</td>
<td>是否为完整句子；用于判断文本结构。</td>
</tr>
<tr>
<td><code>label</code></td>
<td>字符串</td>
<td>标注的名称，通常是目标类型或角色，例如 <code>target</code> 表示被问题指向的答案对象。</td>
</tr>
<tr>
<td><code>labels</code></td>
<td>字符串列表</td>
<td>多标签版本，一般包含和 <code>label</code> 一致的标签列表，用于兼容多标签识别。</td>
</tr>
<tr>
<td><code>shape_type</code></td>
<td>字符串</td>
<td>标注类型，例如 <code>polygon</code> 表示多边形框选区域。</td>
</tr>
<tr>
<td><code>points</code></td>
<td>二维浮点数组</td>
<td>多边形的顶点坐标（像素位置），每个点为 <code>[x, y]</code>，顺序连接形成mask闭合区域。</td>
</tr>
<tr>
<td><code>image_name</code></td>
<td>字符串</td>
<td>图像文件名，标注所对应的图片，如 <code>692198_ac99d18ac5_o.jpg</code>。</td>
</tr>
<tr>
<td><code>group_id</code></td>
<td>整数或 null</td>
<td>标注组 ID，用于把多个相关标注归为一组，若为 <code>null</code> 表示无分组。</td>
</tr>
<tr>
<td><code>group_ids</code></td>
<td>列表或 null</td>
<td>与 <code>group_id</code> 类似，用于支持多组 ID。</td>
</tr>
<tr>
<td><code>flags</code></td>
<td>字典</td>
<td>可选标记，常为空 <code>&#123;&#125;</code>，也可包含如 <code>&quot;difficult&quot;: true</code> 之类的信息。</td>
</tr>
</tbody></table>
<h2 id="🚀数据集确定"><a href="#🚀数据集确定" class="headerlink" title="🚀数据集确定"></a>🚀数据集确定</h2><p>暂定如下数据集：</p>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BB%93%E6%9E%84.png" alt="数据集结构"></p>
<p>LISA上训练这些数据集是按照比例（sem_seg: refer_seg: vqa: reason_seg&#x3D;9: 3: 3: 1）随机选取一个数据集抽样，每个图片会有多个目标及其对应分类，接着会从中随机抽取若干个类生成图文对（一个图对应多个目标，每个目标对应一个描述&#x2F;问题）作为样本，对于没有描述文本的sem_seg数据集就会从预设的问题库中生成问答，有描述的如refer_seg就直接取用就行了。</p>
<h1 id="🔥跑通"><a href="#🔥跑通" class="headerlink" title="🔥跑通"></a>🔥跑通</h1><p>接下来这节记录使用数据集再次跑通训练、评估，会补充一些上一个文章没有的东西。</p>
<h2 id="🚀微调"><a href="#🚀微调" class="headerlink" title="🚀微调"></a>🚀微调</h2><ul>
<li><p>训练时每个epoch会设定指定step数（也就是不用跑满每一个样本），LISA的梯度积累是每个step内传播grad_accumulation_steps次，所以单个epoch会用到<strong>step×grad_accumulation_steps×batch_size</strong>个图像，而不是step×batch_size个；总的mask个数则<strong>不超过step×grad_accumulation_steps×batch_size×num_classes_per_sample（真正并行的只有num_classes_per_sample和部分batch_size）。</strong>如果是多卡训练，这个batch size是每张卡的batch大小，所以样本数应当再乘以卡的数量。</p>
</li>
<li><p>模型跑通训练如下，括号外是当前值（最新step），括号内是平均值。</p>
</li>
</ul>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/%E5%BE%AE%E8%B0%83%E8%BE%93%E5%87%BA.png" alt="微调输出"></p>
<p>每个step都打印太冗长，我把它用tqdm改成动态进度条：</p>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/%E8%BF%9B%E5%BA%A6%E6%9D%A1.png" alt="进度条"></p>
<h2 id="🚀评估"><a href="#🚀评估" class="headerlink" title="🚀评估"></a>🚀评估</h2><ul>
<li><p>上一篇文档用自定义的脚本和指标实现了对外部数据集的评估，而LISA的<strong>train_ds.py</strong>除了训练还提供了评估（支持官方用到的数据集），可以选择训练每一代后都接一个评估，也可以只评估或者只训练，由于该脚本的介绍已经讲过，而评估本身也只会更简单，所以就只补充一些没提到的内容；</p>
</li>
<li><p><strong>指标</strong>是gIoU和cIoU，前者是所有样本的IoU均值；后者则是积累所有样本的交集和并集面积后求IoU，它关注更大面积的目标分割效果。这是区别于GIoU和CIoU的（它们是IoU的变种）。</p>
</li>
<li><p>LISA提供的<strong>ValDataset</strong>如下（源码路径有点问题，修正了），评估只支持reason_seg和refer_seg的数据集，我们选择了后者，也就是refcoco、refcoco+、refcocog这仨。</p>
</li>
<li><p><code>__init__()</code>就是把上面提到的图像、标注等信息读取出来。</p>
</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ValDataset</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    pixel_mean <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    pixel_std <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    img_size <span class="token operator">=</span> <span class="token number">1024</span>
    ignore_label <span class="token operator">=</span> <span class="token number">255</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        base_image_dir<span class="token punctuation">,</span>
        tokenizer<span class="token punctuation">,</span>
        vision_tower<span class="token punctuation">,</span>
        val_dataset<span class="token punctuation">,</span>
        image_size<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        splits <span class="token operator">=</span> val_dataset<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"|"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>base_image_dir <span class="token operator">=</span> base_image_dir
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>splits<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>
            ds<span class="token punctuation">,</span> split <span class="token operator">=</span> splits
            images <span class="token operator">=</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>
                os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>base_image_dir<span class="token punctuation">,</span> <span class="token string">"reason_seg"</span><span class="token punctuation">,</span> ds<span class="token punctuation">,</span> split<span class="token punctuation">,</span> <span class="token string">"*.jpg"</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>images <span class="token operator">=</span> images
            self<span class="token punctuation">.</span>data_type <span class="token operator">=</span> <span class="token string">"reason_seg"</span>
        <span class="token keyword">elif</span> len<span class="token punctuation">(</span>splits<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span>
            ds<span class="token punctuation">,</span> splitBy<span class="token punctuation">,</span> split <span class="token operator">=</span> splits
            refer_api <span class="token operator">=</span> REFER<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>base_image_dir<span class="token punctuation">,</span> <span class="token string">"refer_seg"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ds<span class="token punctuation">,</span> splitBy<span class="token punctuation">)</span>
            ref_ids_val <span class="token operator">=</span> refer_api<span class="token punctuation">.</span>getRefIds<span class="token punctuation">(</span>split<span class="token operator">=</span>split<span class="token punctuation">)</span>
            images_ids_val <span class="token operator">=</span> refer_api<span class="token punctuation">.</span>getImgIds<span class="token punctuation">(</span>ref_ids<span class="token operator">=</span>ref_ids_val<span class="token punctuation">)</span>
            refs_val <span class="token operator">=</span> refer_api<span class="token punctuation">.</span>loadRefs<span class="token punctuation">(</span>ref_ids<span class="token operator">=</span>ref_ids_val<span class="token punctuation">)</span>
            refer_seg_ds <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            refer_seg_ds<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            loaded_images <span class="token operator">=</span> refer_api<span class="token punctuation">.</span>loadImgs<span class="token punctuation">(</span>image_ids<span class="token operator">=</span>images_ids_val<span class="token punctuation">)</span>
            <span class="token keyword">for</span> item <span class="token keyword">in</span> loaded_images<span class="token punctuation">:</span>
                item <span class="token operator">=</span> item<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> ds <span class="token operator">==</span> <span class="token string">"refclef"</span><span class="token punctuation">:</span>
                    item<span class="token punctuation">[</span><span class="token string">"file_name"</span><span class="token punctuation">]</span> <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>
                        self<span class="token punctuation">.</span>base_image_dir<span class="token punctuation">,</span> <span class="token string">"refer_seg"</span><span class="token punctuation">,</span> <span class="token string">"images/saiapr_tc-12"</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token string">"file_name"</span><span class="token punctuation">]</span>
                    <span class="token punctuation">)</span>
                <span class="token keyword">elif</span> ds <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"refcoco"</span><span class="token punctuation">,</span> <span class="token string">"refcoco+"</span><span class="token punctuation">,</span> <span class="token string">"refcocog"</span><span class="token punctuation">,</span> <span class="token string">"grefcoco"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                    item<span class="token punctuation">[</span><span class="token string">"file_name"</span><span class="token punctuation">]</span> <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>
                        self<span class="token punctuation">.</span>base_image_dir<span class="token punctuation">,</span> <span class="token string">"refer_seg"</span><span class="token punctuation">,</span>
                        <span class="token string">"images/mscoco/images/train2014"</span><span class="token punctuation">,</span>
                        item<span class="token punctuation">[</span><span class="token string">"file_name"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">)</span>
                refer_seg_ds<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
            refer_seg_ds<span class="token punctuation">[</span><span class="token string">"annotations"</span><span class="token punctuation">]</span> <span class="token operator">=</span> refer_api<span class="token punctuation">.</span>Anns  <span class="token comment" spellcheck="true"># anns_val</span>

            img2refs <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            <span class="token keyword">for</span> ref <span class="token keyword">in</span> refs_val<span class="token punctuation">:</span>
                image_id <span class="token operator">=</span> ref<span class="token punctuation">[</span><span class="token string">"image_id"</span><span class="token punctuation">]</span>
                img2refs<span class="token punctuation">[</span>image_id<span class="token punctuation">]</span> <span class="token operator">=</span> img2refs<span class="token punctuation">.</span>get<span class="token punctuation">(</span>image_id<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>
                    ref<span class="token punctuation">,</span>
                <span class="token punctuation">]</span>
            refer_seg_ds<span class="token punctuation">[</span><span class="token string">"img2refs"</span><span class="token punctuation">]</span> <span class="token operator">=</span> img2refs
            self<span class="token punctuation">.</span>refer_seg_ds <span class="token operator">=</span> refer_seg_ds
            self<span class="token punctuation">.</span>data_type <span class="token operator">=</span> <span class="token string">"refer_seg"</span>

        self<span class="token punctuation">.</span>ds <span class="token operator">=</span> ds
        self<span class="token punctuation">.</span>image_size <span class="token operator">=</span> image_size
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> tokenizer
        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> ResizeLongestSide<span class="token punctuation">(</span>image_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>clip_image_processor <span class="token operator">=</span> CLIPImageProcessor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>vision_tower<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li><code>__getitem__()</code>内容和训练用的dataset差不多，也是会最终输出十个变量的样本，一张图对应多个目标，每个目标一个掩码和一个对话：</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python">        <span class="token keyword">return</span> <span class="token punctuation">(</span>
            image_path<span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># 图像路径</span>
            image<span class="token punctuation">,</span>           <span class="token comment" spellcheck="true"># 图像</span>
            image_clip<span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># 变换后的图像</span>
            conversations<span class="token punctuation">,</span>   <span class="token comment" spellcheck="true"># 对话</span>
            masks<span class="token punctuation">,</span>           <span class="token comment" spellcheck="true"># 掩码，由多边形解码成能用的图像形式（一个图有多个掩码）</span>
            labels<span class="token punctuation">,</span>          <span class="token comment" spellcheck="true"># 整张图的标注(张量，每个像素属于哪一类/掩码)</span>
            resize<span class="token punctuation">,</span>          <span class="token comment" spellcheck="true"># 变换后的图像尺寸</span>
            None<span class="token punctuation">,</span>            <span class="token comment" spellcheck="true"># 问题（训练dataset有，这里不输出）</span>
            None<span class="token punctuation">,</span>            <span class="token comment" spellcheck="true"># 采样目标的分类名（训练dataset有，这里不输出）</span>
            inference<span class="token punctuation">,</span>       <span class="token comment" spellcheck="true"># 是否做推理任务</span>
        <span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="🚀参数配置"><a href="#🚀参数配置" class="headerlink" title="🚀参数配置"></a>🚀参数配置</h2><p>微调和评估用到的<strong>部分</strong>参数（有些不用调或者很容易看懂用的就没写）如下，这只是单卡的所以仅供参考。</p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>描述</th>
<th>参数值</th>
</tr>
</thead>
<tbody><tr>
<td>version</td>
<td>预训练LLaVA权重路径，可以是LISA完整权重</td>
<td>.&#x2F;weight&#x2F;lisa</td>
</tr>
<tr>
<td>precision</td>
<td>精度（前向传播等操作）</td>
<td>bf16</td>
</tr>
<tr>
<td>vision-tower</td>
<td>LLaVA视觉主干权重路径</td>
<td>.&#x2F;weight&#x2F;clip-vit-large-patch14</td>
</tr>
<tr>
<td>dataset</td>
<td>训练的数据集类型，用 || 分隔多个，默认”sem_seg||refer_seg||vqa||reason_seg”</td>
<td>sem_seg||refer_seg</td>
</tr>
<tr>
<td>sample_rates</td>
<td>每个类型数据集采样比重，数量和dataset一样，默认9,3,3,1</td>
<td>1,1</td>
</tr>
<tr>
<td>sem_seg_data</td>
<td>sem_seg类型的数据集中挑选数据集，默认”ade20k||cocostuff||pascal_part||paco_lvis||mapillary”</td>
<td>ade20k||cocostuff</td>
</tr>
<tr>
<td>refer_seg_data</td>
<td>refer_seg类型的数据集中挑选数据集，默认”refclef||refcoco||refcoco+||refcocog”</td>
<td>refcoco||refcoco+||refcocog</td>
</tr>
<tr>
<td>vqa_data</td>
<td>vaq类型数据集，这里没用到就默认</td>
<td>llava_instruct_150k</td>
</tr>
<tr>
<td>reason_seg_data</td>
<td>reason_seg类型数据集，没用到默认</td>
<td>ReasonSeg|train</td>
</tr>
<tr>
<td>val_dataset</td>
<td>验证（评估）数据集，默认ReasonSeg|val，如果是ref_seg应该是类似refcoco|unc|val，第一个是数据集名，第二个代表.p文件的编码方式（见.p文件名），第三个则是数据集切片（有val&#x2F;test等）</td>
<td>refcoco|unc|test</td>
</tr>
<tr>
<td>log_base_dir</td>
<td>记录每次训练用的文件夹，每次训练的tensorboard和权重都在里面</td>
<td>.&#x2F;runs</td>
</tr>
<tr>
<td>steps_per_epoch</td>
<td>每一代多少步</td>
<td>1500</td>
</tr>
<tr>
<td>batch_size</td>
<td>批次大小（乘以steps_per_epoch就是一代采样数），显存不够只能1</td>
<td>1</td>
</tr>
<tr>
<td>grad_accumulation_steps</td>
<td>梯度积累</td>
<td>20</td>
</tr>
<tr>
<td>val_batch_size</td>
<td>验证集批次大小</td>
<td>1</td>
</tr>
<tr>
<td>num_classes_per_sample</td>
<td>每个样本（图像）取多少个类别（mask）</td>
<td>3</td>
</tr>
<tr>
<td>no_eval</td>
<td>不做验证为True</td>
<td>False</td>
</tr>
<tr>
<td>eval_only</td>
<td>只做验证（评估）不训练为True</td>
<td>True或False</td>
</tr>
<tr>
<td>vision_pretrained</td>
<td>SAM预训练权重路径</td>
<td>.&#x2F;weight&#x2F;sam_vit_h_4b8939.pth</td>
</tr>
</tbody></table>
<h2 id="🚀复现"><a href="#🚀复现" class="headerlink" title="🚀复现"></a>🚀复现</h2><p>官方提供的7B模型评估结果（giou&#x2F;ciou）如下，似乎和论文里面（ciou）的不一样，可能放出来的模型不是它们评估成绩最好的？不过原文分高的数据集在这分也确实是更高者。</p>
<p>又微调了一下refer_seg数据集，效果上去了，说明确实不是最优模型。</p>
<table>
<thead>
<tr>
<th>数据集→</th>
<th>refCOCO</th>
<th></th>
<th></th>
<th>refCOCO+</th>
<th></th>
<th></th>
<th>refCOCOg</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>模型↓</td>
<td>val(1.5k)</td>
<td>testA(750)</td>
<td>testB(750)</td>
<td>val(1.5k)</td>
<td>testA(750)</td>
<td>testB(750)</td>
<td>val(1.3k)</td>
<td>test(2.6k)</td>
</tr>
<tr>
<td>LISA-7B</td>
<td>67.3&#x2F;66.6</td>
<td>70.3&#x2F;70.1</td>
<td>63.0&#x2F;62.3</td>
<td>52.8&#x2F;53.4</td>
<td>59.6&#x2F;59.5</td>
<td>45.1&#x2F;45.9</td>
<td>60.3&#x2F;60.2</td>
<td>61.2&#x2F;61.3</td>
</tr>
<tr>
<td>LISA-7B(ft)</td>
<td>75.7&#x2F;73.1</td>
<td>79.8&#x2F;78.0</td>
<td>72.8&#x2F;69.5</td>
<td>66.4&#x2F;61.8</td>
<td>70.6&#x2F;66.8</td>
<td>59.7&#x2F;54.3</td>
<td>68.5&#x2F;65.6</td>
<td>69.8&#x2F;67.3</td>
</tr>
</tbody></table>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/%E5%8E%9F%E8%AE%BA%E6%96%87%E6%95%B0%E6%8D%AE%E9%9B%86%E6%95%88%E6%9E%9C.png" alt="LISA论文的referseg数据集效果（ciou）"></p>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/%E8%AE%AD%E7%BB%83%E6%9B%B2%E7%BA%BF.png" alt="训练曲线"></p>
<p>健康的损失曲线和评估曲线。</p>
<h2 id="🚀多卡训练"><a href="#🚀多卡训练" class="headerlink" title="🚀多卡训练"></a>🚀多卡训练</h2><p>目前单张4090D（24G）刚好跑满LISA-7B（BF16），而且只能batch size为1，跑18k个图片样本（实际上有更多的样本），1个epoch需要近2.8h，效率很低下。</p>
<p>要有足够的训练速度保证实验进度，保守需要总显存为48G（40G以上），所以硬件至少需要2张4090（或者等价的单张计算卡），如果有更多资源能应该能同时进行多个实验。</p>
<p>最终选择<strong>5张40G显存的A100</strong>。</p>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/%E5%A4%9A%E5%8D%A1%E8%AE%AD%E7%BB%83%E8%BE%93%E5%87%BA.png" alt="多卡训练输出"></p>
<p>多卡训练如上图所示，多卡打印也会翻倍。运行时需要<code>deepspeed --include localhost:3,4,5,6,7 train_ds.py</code>指令指定需要使用的GPU的编号，这种情况下指定GPU并且不支持debug，所以debug应该单卡比较好。</p>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/%E5%A4%9A%E5%8D%A1.png" alt="多卡"></p>
<p><strong>速度问题解决</strong>：跑下来5张A100稳定时整体效率（相同时间输入的样本量）有单张4090D的3.5倍以上，显存是绰绰有余，但是训练依然要比较长的时间。</p>
<p>我发现训练时，后面的epoch花的时间比前面会少很多，刚开始1.5h每代，到后面甚至只要55分钟（此时效率大于5倍），可能是deepspeed框架会逐渐优化显存分配。最后发现++当8卡机剩余3个A100也在工作时，这5张卡速度也会上去++，AI的回答是（可能原因）：</p>
<ul>
<li><p>部分机器上，GPU 之间通过 PCIe&#x2F;NVLink 互联，当多个 GPU 同时有进程活跃时，驱动和硬件的 带宽调度机制会变得更积极，降低数据传输瓶颈。</p>
</li>
<li><p>如果 GPU 0-2 也在运作，整个 PCIe 或 NVLink 互联模块会进入高负载状态 → 激发全局带宽&#x2F;延迟优化 → 反而加速你 3-7 的训练过程。</p>
</li>
</ul>
<p>所以理论上应该所有卡都在运行比较好。</p>
<p>于是我做了个实验，运行以下脚本来使用剩余3个GPU：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> time
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'0,1,2'</span>

device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 模拟每张卡做一点小计算</span>
tensors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    d <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>f<span class="token string">"cuda:{i}"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 创建一个小矩阵放在 GPU 上</span>
    tensors<span class="token punctuation">.</span>append<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> device<span class="token operator">=</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Starting light GPU occupation loop..."</span><span class="token punctuation">)</span>
<span class="token keyword">try</span><span class="token punctuation">:</span>
    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> tensor <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>tensors<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 做一次小矩阵乘法 → 保证 GPU 有一点点算力占用</span>
            result <span class="token operator">=</span> tensor @ tensor<span class="token punctuation">.</span>T
            _ <span class="token operator">=</span> result<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 防止优化掉</span>
        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 每隔 0.5 秒运行一次</span>
<span class="token keyword">except</span> KeyboardInterrupt<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Stopped."</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>发现不运行时训练程序会3.8s&#x2F;step进行训练，而运行了脚本后能到达2.12s&#x2F;step。所以这个脚本可以一直跑，以很低的负载让0-2GPU保持工作，这样即便有他人要用这三个GPU也不用担心有影响。</p>
<p><strong>显存优化实验</strong>：我用一个小网络实验了一下，速度对比如下，所以再显存够的情况下stage0就行了，不需要做显存优化。</p>
<table>
<thead>
<tr>
<th>ZeRO Stage</th>
<th>平均步长时间 (s)</th>
<th>吞吐率 (samples&#x2F;s)</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.0112</td>
<td>1427.72</td>
</tr>
<tr>
<td>1</td>
<td>0.0119</td>
<td>1341.57</td>
</tr>
<tr>
<td>2</td>
<td>0.0125</td>
<td>1279.72</td>
</tr>
</tbody></table>
<p><strong>batch设计</strong>：每张卡B（batch_size）为4时速度2.15s&#x2F;step，而16时速度为7.65s&#x2F;step左右，B翻了4倍但是费时仅为3倍多，因为GPU算大矩阵效率更高，所以B越大效率越高，但没必要拉满，要不然样本批次分布都差不多，结合GPT的建议设置为16-20为宜。</p>
<p><img src="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/batchsize%E9%80%89%E6%8B%A9.png" alt="batch size选择（左图小，右图大"></p>
<p>左边6样本每step，右边16*5样本每step，稳定性确实有很大区别。</p>
<p><strong>参数推荐</strong></p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>参数值</th>
<th>参数名</th>
<th>参数值</th>
</tr>
</thead>
<tbody><tr>
<td>zero</td>
<td>0</td>
<td>precision</td>
<td>bf16</td>
</tr>
<tr>
<td>dataset</td>
<td>sem_seg||refer_seg||reason_seg</td>
<td>sample_rates</td>
<td>10,8,1</td>
</tr>
<tr>
<td>sem_seg_data</td>
<td>ade20k||cocostuff</td>
<td>refer_seg_data</td>
<td>refclef||refcoco||refcoco+||refcocog</td>
</tr>
<tr>
<td>reason_seg_data</td>
<td>ReasonSeg|train</td>
<td>val_dataset</td>
<td>refcoco|unc|testA</td>
</tr>
<tr>
<td>epochs</td>
<td>80</td>
<td>steps_per_epoch</td>
<td>500</td>
</tr>
<tr>
<td>batch_size</td>
<td>16</td>
<td>grad_accumulation_steps</td>
<td>1</td>
</tr>
<tr>
<td>lr</td>
<td>0.0003</td>
<td>ce_loss_weight</td>
<td>0.2</td>
</tr>
<tr>
<td>dice_loss_weight</td>
<td>1</td>
<td>bce_loss_weight</td>
<td>1.5</td>
</tr>
</tbody></table>
<p>reason_seg数据集也就200+样本，所以应该比较低的采样比例，可能是因为这个数据集文本比较长，如果不巧抽到多个这个数据集的样本，可能会爆显存。</p>
<h1 id="🔥问题解决"><a href="#🔥问题解决" class="headerlink" title="🔥问题解决"></a>🔥问题解决</h1><h2 id="🚀SAM模型加载权重无效"><a href="#🚀SAM模型加载权重无效" class="headerlink" title="🚀SAM模型加载权重无效"></a>🚀SAM模型加载权重无效</h2><p>加载模型时会出现这种情况：</p>
<pre class="line-numbers language-plaintext"><code class="language-plaintext">/home/zigaa/anaconda3/envs/leosam2/lib/python3.10/site-packages/torch/nn/modules/module.py:2409: UserWarning: for mask_decoder.iou_prediction_head.layers.2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass assign=True to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>而且不是上面这一行，而是所有SAM的模块都会报错，这是因为SAM模型构建时里有一些“meta 参数”（即占位符参数，没有在内存里真正分配张量），而你在加载检查点（checkpoint）时，试图把存储在检查点里的真实权重拷贝到这些meta参数上。因为meta参数本身并没有实际张量，所以“拷贝”操作变成了no‑op（无效操作），PyTorch就给打了Warning。</p>
<p>解决方法就是在<code>build_sam()</code>函数里面的<code>sam.load_state_dict(state_dict, strict=False)</code>添加<code>assign=True</code>，这会强制赋值权重文件的张量给meta参数的坑位。</p>
<p>这时候如果是评估不会有问题，但是训练时脚本执行到<code>deepspeed.initialize()</code>时会出现新的报错（截取最底层）：</p>
<pre class="line-numbers language-plaintext"><code class="language-plaintext">[rank0]:     work = group.broadcast([tensor], opts)
[rank0]: ValueError: Tensors must be contiguous
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>这是指那些参量虽然被强行赋值，但是依然不是真正分配在 CPU&#x2F;GPU 上的张量，那些层很可能仍保持meta状态或被封装为非连续结构，就是空有数值而形式不对。所以应该把这些meta张量用一个新的contiguous张量替换。总的对<code>build_sam()</code>的改动如下：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_build_sam</span><span class="token punctuation">(</span>
    encoder_embed_dim<span class="token punctuation">,</span>
    encoder_depth<span class="token punctuation">,</span>
    encoder_num_heads<span class="token punctuation">,</span>
    encoder_global_attn_indexes<span class="token punctuation">,</span>
    checkpoint<span class="token operator">=</span>None<span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    prompt_embed_dim <span class="token operator">=</span> <span class="token number">256</span>
    image_size <span class="token operator">=</span> <span class="token number">1024</span>
    vit_patch_size <span class="token operator">=</span> <span class="token number">16</span>
    image_embedding_size <span class="token operator">=</span> image_size <span class="token operator">//</span> vit_patch_size
    sam <span class="token operator">=</span> Sam<span class="token punctuation">(</span>
        image_encoder<span class="token operator">=</span>ImageEncoderViT<span class="token punctuation">(</span>
            depth<span class="token operator">=</span>encoder_depth<span class="token punctuation">,</span>
            embed_dim<span class="token operator">=</span>encoder_embed_dim<span class="token punctuation">,</span>
            img_size<span class="token operator">=</span>image_size<span class="token punctuation">,</span>
            mlp_ratio<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>
            norm_layer<span class="token operator">=</span>partial<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            num_heads<span class="token operator">=</span>encoder_num_heads<span class="token punctuation">,</span>
            patch_size<span class="token operator">=</span>vit_patch_size<span class="token punctuation">,</span>
            qkv_bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            use_rel_pos<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            global_attn_indexes<span class="token operator">=</span>encoder_global_attn_indexes<span class="token punctuation">,</span>
            window_size<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">,</span>
            out_chans<span class="token operator">=</span>prompt_embed_dim<span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        prompt_encoder<span class="token operator">=</span>PromptEncoder<span class="token punctuation">(</span>
            embed_dim<span class="token operator">=</span>prompt_embed_dim<span class="token punctuation">,</span>
            image_embedding_size<span class="token operator">=</span><span class="token punctuation">(</span>image_embedding_size<span class="token punctuation">,</span> image_embedding_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
            input_image_size<span class="token operator">=</span><span class="token punctuation">(</span>image_size<span class="token punctuation">,</span> image_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
            mask_in_chans<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        mask_decoder<span class="token operator">=</span>MaskDecoder<span class="token punctuation">(</span>
            num_multimask_outputs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
            transformer<span class="token operator">=</span>TwoWayTransformer<span class="token punctuation">(</span>
                depth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
                embedding_dim<span class="token operator">=</span>prompt_embed_dim<span class="token punctuation">,</span>
                mlp_dim<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span>
                num_heads<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            transformer_dim<span class="token operator">=</span>prompt_embed_dim<span class="token punctuation">,</span>
            iou_head_depth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
            iou_head_hidden_dim<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        pixel_mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        pixel_std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    sam<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> checkpoint <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
        <span class="token keyword">with</span> open<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> <span class="token string">"rb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
        sam<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> assign<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> sam<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> param<span class="token punctuation">.</span>data
        <span class="token comment" spellcheck="true"># 1) 如果是 meta 张量，先创建一个同 shape/dtype 的真实张量</span>
        <span class="token keyword">if</span> hasattr<span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token string">"is_meta"</span><span class="token punctuation">)</span> <span class="token operator">and</span> data<span class="token punctuation">.</span>is_meta<span class="token punctuation">:</span>
            real <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>
                data<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>
                dtype<span class="token operator">=</span>data<span class="token punctuation">.</span>dtype<span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># 保持原 dtype</span>
                device<span class="token operator">=</span>device          <span class="token comment" spellcheck="true"># 直接放到 CUDA</span>
            <span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 用 nn.Parameter 完全替换，确保整个 Parameter 对象都绑定到真实张量上</span>
            new_p <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>real<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span>param<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 把它插回到 model 里</span>
            parent<span class="token punctuation">,</span> attr <span class="token operator">=</span> name<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 递归拿到父 module</span>
            mod <span class="token operator">=</span> sam
            <span class="token keyword">for</span> sub <span class="token keyword">in</span> parent<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                mod <span class="token operator">=</span> getattr<span class="token punctuation">(</span>mod<span class="token punctuation">,</span> sub<span class="token punctuation">)</span>
            setattr<span class="token punctuation">(</span>mod<span class="token punctuation">,</span> attr<span class="token punctuation">,</span> new_p<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 2) 如果已经有真实张量，但是 non‑contiguous，强制 contiguous + clone + to(device)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token operator">not</span> data<span class="token punctuation">.</span>is_contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">or</span> data<span class="token punctuation">.</span>device <span class="token operator">!=</span> device<span class="token punctuation">:</span>
                new_data <span class="token operator">=</span> data<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                param<span class="token punctuation">.</span>data <span class="token operator">=</span> new_data
    <span class="token keyword">return</span> sam
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>改动前微调模型输出的评估值通常会异常低且不收敛，这说明模型原本读取SAM部分的权重确实存在问题，改动完成后微调就能正常收敛。</p>
<h2 id="🚀梯度积累问题"><a href="#🚀梯度积累问题" class="headerlink" title="🚀梯度积累问题"></a>🚀梯度积累问题</h2><p>LISA梯度积累有问题，这种写法压根没有积累，依然是每次采样都进行更新，这样训练的效果相当不稳定，甚至它还没有清空梯度：</p>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">for</span> global_step <span class="token keyword">in</span> range<span class="token punctuation">(</span>args<span class="token punctuation">.</span>steps_per_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>args<span class="token punctuation">.</span>grad_accumulation_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">try</span><span class="token punctuation">:</span>
                input_dict <span class="token operator">=</span> next<span class="token punctuation">(</span>train_iter<span class="token punctuation">)</span>
            <span class="token keyword">except</span><span class="token punctuation">:</span>
                train_iter <span class="token operator">=</span> iter<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>
                input_dict <span class="token operator">=</span> next<span class="token punctuation">(</span>train_iter<span class="token punctuation">)</span>

            data_time<span class="token punctuation">.</span>update<span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> end<span class="token punctuation">)</span>
            input_dict <span class="token operator">=</span> dict_to_cuda<span class="token punctuation">(</span>input_dict<span class="token punctuation">)</span>

            <span class="token keyword">if</span> args<span class="token punctuation">.</span>precision <span class="token operator">==</span> <span class="token string">"fp16"</span><span class="token punctuation">:</span>
                input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span> <span class="token operator">=</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>half<span class="token punctuation">(</span><span class="token punctuation">)</span>
                input_dict<span class="token punctuation">[</span><span class="token string">"images_clip"</span><span class="token punctuation">]</span> <span class="token operator">=</span> input_dict<span class="token punctuation">[</span><span class="token string">"images_clip"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>half<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">elif</span> args<span class="token punctuation">.</span>precision <span class="token operator">==</span> <span class="token string">"bf16"</span><span class="token punctuation">:</span>
                input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span> <span class="token operator">=</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bfloat16<span class="token punctuation">(</span><span class="token punctuation">)</span>
                input_dict<span class="token punctuation">[</span><span class="token string">"images_clip"</span><span class="token punctuation">]</span> <span class="token operator">=</span> input_dict<span class="token punctuation">[</span><span class="token string">"images_clip"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bfloat16<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span> <span class="token operator">=</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
                input_dict<span class="token punctuation">[</span><span class="token string">"images_clip"</span><span class="token punctuation">]</span> <span class="token operator">=</span> input_dict<span class="token punctuation">[</span><span class="token string">"images_clip"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>

            output_dict <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>input_dict<span class="token punctuation">)</span>

            loss <span class="token operator">=</span> output_dict<span class="token punctuation">[</span><span class="token string">"loss"</span><span class="token punctuation">]</span>
            ce_loss <span class="token operator">=</span> output_dict<span class="token punctuation">[</span><span class="token string">"ce_loss"</span><span class="token punctuation">]</span>
            mask_bce_loss <span class="token operator">=</span> output_dict<span class="token punctuation">[</span><span class="token string">"mask_bce_loss"</span><span class="token punctuation">]</span>
            mask_dice_loss <span class="token operator">=</span> output_dict<span class="token punctuation">[</span><span class="token string">"mask_dice_loss"</span><span class="token punctuation">]</span>
            mask_loss <span class="token operator">=</span> output_dict<span class="token punctuation">[</span><span class="token string">"mask_loss"</span><span class="token punctuation">]</span>

            losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            ce_losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>ce_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            mask_bce_losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>mask_bce_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            mask_dice_losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>mask_dice_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            mask_losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>mask_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            model<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
            model<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>应该改成这样（就改后面部分），只反向传播得到梯度，到次数后在更新参数，清零梯度：</p>
<pre class="line-numbers language-python"><code class="language-python">            losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            ce_losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>ce_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            mask_bce_losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>mask_bce_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            mask_dice_losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>mask_dice_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            mask_losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>mask_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_dict<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
            model<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
            
        model<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="🚀tensorboard记录问题"><a href="#🚀tensorboard记录问题" class="headerlink" title="🚀tensorboard记录问题"></a>🚀tensorboard记录问题</h2><p>如下的这种tensorboard写法每个epoch都会重置step，从前面给到的源码可以看到<code>global_step</code>实际上并不是全局的（估计是编写的人没意识到），是单epoch的，所以应该用<code>now_step = global_step + epoch * args.steps_per_epoch</code>算出真正的全局step以替换<code>global_step</code>。</p>
<pre class="line-numbers language-python"><code class="language-python">            <span class="token keyword">if</span> args<span class="token punctuation">.</span>local_rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                progress<span class="token punctuation">.</span>display<span class="token punctuation">(</span>global_step <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
                writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"train/loss"</span><span class="token punctuation">,</span> losses<span class="token punctuation">.</span>avg<span class="token punctuation">,</span> global_step<span class="token punctuation">)</span>
                writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"train/ce_loss"</span><span class="token punctuation">,</span> ce_losses<span class="token punctuation">.</span>avg<span class="token punctuation">,</span> global_step<span class="token punctuation">)</span>
                writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span>
                    <span class="token string">"train/mask_bce_loss"</span><span class="token punctuation">,</span> mask_bce_losses<span class="token punctuation">.</span>avg<span class="token punctuation">,</span> global_step
                <span class="token punctuation">)</span>
                writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span>
                    <span class="token string">"train/mask_dice_loss"</span><span class="token punctuation">,</span> mask_dice_losses<span class="token punctuation">.</span>avg<span class="token punctuation">,</span> global_step
                <span class="token punctuation">)</span>
                writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"train/mask_loss"</span><span class="token punctuation">,</span> mask_losses<span class="token punctuation">.</span>avg<span class="token punctuation">,</span> global_step<span class="token punctuation">)</span>
                writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span>
                    <span class="token string">"metrics/total_secs_per_batch"</span><span class="token punctuation">,</span> batch_time<span class="token punctuation">.</span>avg<span class="token punctuation">,</span> global_step
                <span class="token punctuation">)</span>
                writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span>
                    <span class="token string">"metrics/data_secs_per_batch"</span><span class="token punctuation">,</span> data_time<span class="token punctuation">.</span>avg<span class="token punctuation">,</span> global_step
                <span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="🚀Zero1权重保存"><a href="#🚀Zero1权重保存" class="headerlink" title="🚀Zero1权重保存"></a>🚀Zero1权重保存</h2><p>Zero1方法训练时优化器参数不会分片，所以可以直接用如下代码代替zero_to_fp32.py的功能（这个脚本负责的是zero2和3）生成bin文件，然后再运行merge的脚本。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># zero1训练后获取完整权重（代替zero_to_fp32）</span>
<span class="token keyword">import</span> torch

<span class="token comment" spellcheck="true"># 加载你的 checkpoint 文件路径</span>
ckpt_path <span class="token operator">=</span> <span class="token string">"runs/lisa_feedback/ckpt_model/global_step22500/mp_rank_00_model_states.pt"</span>

<span class="token comment" spellcheck="true"># 加载 checkpoint 文件</span>
ckpt <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 检查是否包含 'module' 这个关键 key（DeepSpeed Stage 1 保存方式）</span>
<span class="token keyword">if</span> <span class="token string">'module'</span> <span class="token operator">not</span> <span class="token keyword">in</span> ckpt<span class="token punctuation">:</span>
    <span class="token keyword">raise</span> KeyError<span class="token punctuation">(</span><span class="token string">"'module' key not found in checkpoint — 这不是一个合法的 DeepSpeed ZeRO Stage 1 模型参数文件。"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 提取模型参数</span>
state_dict <span class="token operator">=</span> ckpt<span class="token punctuation">[</span><span class="token string">'module'</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 打印所有参数 key（检查是不是完整的，比如包含 q_proj.weight 等）</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n== 模型参数 key 列表（共 {} 个） =="</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>len<span class="token punctuation">(</span>state_dict<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> key <span class="token keyword">in</span> list<span class="token punctuation">(</span>state_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 只打印前 20 个参数</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 也可以保存为临时的 pytorch_model.bin 以供 merge LoRA 使用</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>state_dict<span class="token punctuation">,</span> <span class="token string">"pytorch_model.bin"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n已保存模型参数到 pytorch_model.bin（可用于 merge_lora_weights_and_save_hf_model.py）"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="🔥总结"><a href="#🔥总结" class="headerlink" title="🔥总结"></a>🔥总结</h1><p>本文在前文的基础上，使用LISA官方用的数据集复现了微调和评估，体验了多卡分布式训练，对数据集处理、基于deepspeed的分布式训练技术以及LISA本身的原理都有了很多深入的理解和认知，对多模态大模型的方方面面都有了初步的学习和理解。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://legendleochen.top/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LISA/" rel="tag">LISA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LORA/" rel="tag">LORA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PEFT/" rel="tag">PEFT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SAM2/" rel="tag">SAM2</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/VLLM/" rel="tag">VLLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/" rel="tag">图像分割</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">SAM2架构概览和详细解读</div>
      </a>
    
  </nav>

  
   
  
    
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2023-2025
        <i class="ri-heart-fill heart_icon"></i> LegendLeo Chen
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/mylogo.png" alt="LegendLeo Chen 的空间"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">🚀主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">💾归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">🧭分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">🏷️标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">🛸关于</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/analytics">📊统计</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=1491212&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
  <!-- 背景气泡 -->
  <!--
  <div class="balls-container">
    <div class="balls-particles">
      <span style="--i:11;"></span>
      <span style="--i:12;"></span>
      <span style="--i:24;"></span>
      <span style="--i:10;"></span>
      <span style="--i:14;"></span>
      <span style="--i:23;"></span>
      <span style="--i:18;"></span>
      <span style="--i:16;"></span>
      <span style="--i:19;"></span>
      <span style="--i:20;"></span>
      <span style="--i:22;"></span>
      <span style="--i:25;"></span>
      <span style="--i:18;"></span>
      <span style="--i:21;"></span>
      <span style="--i:13;"></span>
      <span style="--i:15;"></span>
      <span style="--i:26;"></span>
      <span style="--i:17;"></span>
      <span style="--i:13;"></span>
      <span style="--i:26;"></span>
      <span style="--i:28;"></span>
      <span style="--i:11;"></span>
      <span style="--i:12;"></span>
      <span style="--i:24;"></span>
      <span style="--i:10;"></span>
      <span style="--i:14;"></span>
      <span style="--i:23;"></span>
      <span style="--i:18;"></span>
      <span style="--i:16;"></span>
      <span style="--i:19;"></span>
      <span style="--i:20;"></span>
      <span style="--i:22;"></span>
      <span style="--i:25;"></span>
      <span style="--i:18;"></span>
      <span style="--i:21;"></span>
      <span style="--i:13;"></span>
      <span style="--i:15;"></span>
      <span style="--i:26;"></span>
      <span style="--i:17;"></span>
      <span style="--i:13;"></span>
      <span style="--i:26;"></span>
      <span style="--i:28;"></span>
    </div>
  </div>
  <style>
    *
    {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    .balls-container
    { 
      position: fixed;
      top: 0px;
      left: 0px;
      width: 100%;
      height: 100vh;
      overflow: hidden;
      opacity: 0.3;
    }
    
    .balls-particles
    {
      position: fixed;
      display: flex;
      z-index: 3;
      padding: 0 20px;
    }
    
    .balls-particles span
    {
      position: relative;
      bottom: 30px;
      width: 30px;
      height: 30px;
      background-color: #4fc3dc;
      box-shadow: 0 0 0 10px #4fc3dc44,
      0 0 50px #4fc3dc,
      -100px 0 #4fc3dc99,
      100px 0 #ff2d7599;
      margin: 0 4px;
      border-radius: 50%;
      animation: animate 15s ease infinite;
      animation-delay: calc(125s / var(--i));
      transform: translateY(120vh);
    }
    .balls-particles span:nth-child(even) {
      background-color: #ff2d75;
      box-shadow: 0 0 0 10px #ff267544,
      0 0 50px #ff2d75,
      -100px 0 #4fc3dc99,
      100px 0 #4fc3dc99;
      ;
    }
    
    @keyframes animate {
      0%
      {
        transform: translateY(120vh) scale(0) rotate(0deg);
      }
      20%
      {
        transform: translateY(100vh) scale(1) rotate(0deg);
      }
      100%
      {
        transform: translateY(-50vh) scale(0.5) rotate(360deg);
      }
    }
  </style> -->
  <!-- 地月系统 -->
  <!-- <div class="earth-container" >
    <div class="planet"></div>
    <div class="satellite"></div>
   </div>
   <style>
    *{
      padding: 0;
      margin: 0;
      }
      .earth-container {
        width: 36.25em;
        height: 36.25em;
        position: absolute;
        top:5%;
        left: 93%;
        transform: translate(-50%, -50%);
        opacity: 0.3;
      }
      
      .planet{
        width: 15.62*3em;
        height: 15.62*3em;
        background-color: #02c0f5;
        border-radius: 50%;
        position: absolute;
        margin: auto;
        top:0;
        right: 0;
        bottom: 0;
        left: 0;
        z-index: 1;
      }
      
      .planet::before{
        content: '';
        width: 4em;
        height: 4em;
        background-color: #008fd6;
        position: absolute;
        top:10em;
        left: 8em;
        border-radius: 50%; 
        box-shadow: 15em 15em 0 2em #00d68b, 5em 8em 0 3em #10ade1;
      }
      
      .satellite{
        width: 5em;
        height: 5em;
        background-color: #dee517;
        border-radius: 50%;
        position: relative;
        left: -5em;
        bottom: -30em;
        animation: spin 5s infinite;
        z-index: 1;
      }
      
      @keyframes spin {
        49%{
          z-index: 1;
        }
        50%{
          bottom: 3em;
          left: 35em;
          z-index: -1;
        }
        100%{
          z-index: -1;
        }
      }
    </style> -->
<!-- 三角彩带背景 -->
  <canvas id="evanyou-canvas" style="opacity: 0.3; position: fixed; top: 0px; left: 0px; z-index: -1; width: 100%; height: 100%; pointer-events: none;"></canvas>
  <script src="https://cdn.jsdelivr.net/gh/XXXZhy/Blog_Image/js/evanyou_canvas.js"></script>
</body>

</html>