<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta name="description" content="ä¸€ä¸ªç§˜å¯†ç©ºé—´" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>SAM2æ¶æ„æ¦‚è§ˆå’Œè¯¦ç»†è§£è¯» |  LegendLeo Chen çš„ç©ºé—´</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/mylogo.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
<!-- å°é¢æ ‡é—ªçƒ -->
<link rel="stylesheet" href="/css/zhyBlogTitle.css">
<script src="https://cdn.bootcdn.net/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- jqueryï¼Œæ‡’åŠ è½½ã€ç»Ÿè®¡ã€è¯´è¯´éœ€è¦çš„jquery -->
<script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-SAM2æ¶æ„æ¦‚è§ˆå’Œè¯¦ç»†è§£è¯»"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  SAM2æ¶æ„æ¦‚è§ˆå’Œè¯¦ç»†è§£è¯»
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/" class="article-date">
  <time datetime="2025-06-12T11:14:49.000Z" itemprop="datePublished">2025-06-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">æ·±åº¦å­¦ä¹ </a> / <a class="article-category-link" href="/categories/%E7%BC%96%E7%A8%8B/">ç¼–ç¨‹</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> å­—æ•°ç»Ÿè®¡:</span>
            <span class="post-count">9.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> é˜…è¯»æ—¶é•¿â‰ˆ</span>
            <span class="post-count">44 åˆ†é’Ÿ</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>å‰æ–‡<a href="/2025/05/07/SAM2%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83/" title="SAM2å›¾åƒåˆ†å‰²æ¨¡å‹çš„å¾®è°ƒ">SAM2å›¾åƒåˆ†å‰²æ¨¡å‹çš„å¾®è°ƒ</a>è®°å½•äº†å¦‚ä½•ä½¿ç”¨SAM2åœ¨ä¸‹æ¸¸æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€é¢„æµ‹ã€è¯„ä¼°ç­‰ã€‚</p>
<p>æœ¬æ–‡å°†é€šè¿‡å¯¹SAM2æºç çš„é˜…è¯»å’Œdebugï¼Œè¿›ä¸€æ­¥äº†è§£SAM2çš„æ¶æ„å’Œæµç¨‹ã€‚</p>
<p>æœ¬æ–‡ç›®å‰åªè€ƒè™‘å›¾ç‰‡ä»»åŠ¡ï¼Œä¸è€ƒè™‘è§†é¢‘ä»»åŠ¡æ¶‰åŠçš„æ¨¡å—ï¼Œæ‰€ä»¥SAM2æ¶æ„ä¸Šå°±æ˜¯ç”±imageÂ encoderã€maskÂ decoderã€promptÂ encoderä¸‰ä¸ªæ¨¡å—æ„æˆã€‚<span id="more"></span><br><img src="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/SAM2%E6%9E%B6%E6%9E%84.png" alt="SAM2æ¶æ„"></p>
<h1 id="ğŸ”¥é¡¹ç›®ç»“æ„"><a href="#ğŸ”¥é¡¹ç›®ç»“æ„" class="headerlink" title="ğŸ”¥é¡¹ç›®ç»“æ„"></a>ğŸ”¥é¡¹ç›®ç»“æ„</h1><blockquote>
<p>assetsï¼šæ•°æ®é›†æ–‡ä»¶å¤¹ï¼›<br>checkpointsï¼šä¸‹è½½å®˜æ–¹æä¾›çš„æƒé‡ï¼›<br>notebooksï¼šä½¿ç”¨jupyterè¿›è¡Œé¢„æµ‹ã€å…¨æ™¯åˆ†å‰²ï¼Œç”¨äºä¸Šæ‰‹ä½“éªŒï¼›<br><strong>sam2ï¼šSAM2æœ¬ä½“</strong>ï¼›<br>sam2_configï¼šSAM2çš„æ¶æ„é…ç½®ï¼Œæ¨¡å‹å‚æ•°è®¾ç½®ï¼›<br>sav_datasetï¼šå®˜æ–¹çš„1Bå¤§å°æ•°æ®é›†ç›¸å…³ï¼›<br>toolsï¼šè§†é¢‘é¢„æµ‹ç”¨çš„å·¥å…·ï¼›</p>
</blockquote>
<p>æ‰€ä»¥å®é™…ä¸Š<strong>sam2</strong>æ–‡ä»¶å¤¹å½“ä¸­å°±åŒ…å«äº†æ‰€æœ‰é‡è¦çš„å†…å®¹ã€‚</p>
<h1 id="ğŸ”¥æµç¨‹"><a href="#ğŸ”¥æµç¨‹" class="headerlink" title="ğŸ”¥æµç¨‹"></a>ğŸ”¥æµç¨‹</h1><p>æ ¹æ®<strong>è®­ç»ƒçš„è¿‡ç¨‹</strong>æ¥è§£è¯»SAM2æ˜¯å¦‚ä½•è¿›è¡Œæ•°æ®å¤„ç†ã€å‰å‘ä¼ æ’­ç­‰æ“ä½œçš„ã€‚å¦‚æœåªæƒ³ç†è§£è®­ç»ƒè¿‡ç¨‹ï¼ˆéªŒè¯å’Œé¢„æµ‹ä¹Ÿå·®ä¸å¤šï¼‰å¹¶äº†è§£æ•°æ®æ˜¯å¦‚ä½•åœ¨SAM2ä¼ æ’­æœ€ç»ˆè¾“å‡ºåˆ†å‰²ç»“æœçš„ï¼Œå¯ä»¥é€šè¿‡è¿™èŠ‚äº†è§£ã€‚</p>
<p><img src="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/SAM2%E6%9E%B6%E6%9E%84%E7%AE%80%E5%9B%BE.png" alt="SAM2æ¶æ„ç®€å›¾"></p>
<p>å®é™…ä¸Šå»æ‰äº†SAM2æ–°å¢çš„ç”¨äºè§†é¢‘ä»»åŠ¡çš„å†…å­˜æœºåˆ¶ï¼Œåœ¨å›¾åƒä»»åŠ¡ä¸­å…¶ç»“æ„å¯ä»¥ç”¨1ä»£çš„æ¥è¡¨ç¤ºï¼ˆä¸Šå›¾ï¼‰ã€‚</p>
<h2 id="ğŸš æ„å»ºæ¨¡å‹"><a href="#ğŸš æ„å»ºæ¨¡å‹" class="headerlink" title="ğŸš æ„å»ºæ¨¡å‹"></a>ğŸš æ„å»ºæ¨¡å‹</h2><pre class="line-numbers language-python"><code class="language-python">sam2_model <span class="token operator">=</span> build_sam2<span class="token punctuation">(</span>model_cfg<span class="token punctuation">,</span> sam2_checkpoint<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
predictor <span class="token operator">=</span> SAM2ImagePredictor<span class="token punctuation">(</span>sam2_model<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>é¦–å…ˆï¼Œæ— è®ºæ˜¯é¢„æµ‹è¿˜æ˜¯è®­ç»ƒéƒ½æœ‰ä»¥ä¸Šä¸¤è¡Œæ„å»ºSAM2ã€‚</p>
<h3 id="åŠ è½½æƒé‡ï¼šbuild-sam-py"><a href="#åŠ è½½æƒé‡ï¼šbuild-sam-py" class="headerlink" title="åŠ è½½æƒé‡ï¼šbuild_sam.py"></a>åŠ è½½æƒé‡ï¼šbuild_sam.py</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_sam2</span><span class="token punctuation">(</span>
    config_file<span class="token punctuation">,</span>
    ckpt_path<span class="token operator">=</span>None<span class="token punctuation">,</span>
    device<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">,</span>
    mode<span class="token operator">=</span><span class="token string">"eval"</span><span class="token punctuation">,</span>
    hydra_overrides_extra<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    apply_postprocessing<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">if</span> apply_postprocessing<span class="token punctuation">:</span>
        hydra_overrides_extra <span class="token operator">=</span> hydra_overrides_extra<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        hydra_overrides_extra <span class="token operator">+=</span> <span class="token punctuation">[</span>
            <span class="token comment" spellcheck="true"># dynamically fall back to multi-mask if the single mask is not stable</span>
            <span class="token string">"++model.sam_mask_decoder_extra_args.dynamic_multimask_via_stability=true"</span><span class="token punctuation">,</span>
            <span class="token string">"++model.sam_mask_decoder_extra_args.dynamic_multimask_stability_delta=0.05"</span><span class="token punctuation">,</span>
            <span class="token string">"++model.sam_mask_decoder_extra_args.dynamic_multimask_stability_thresh=0.98"</span><span class="token punctuation">,</span>
        <span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># Read config and init model</span>
    cfg <span class="token operator">=</span> compose<span class="token punctuation">(</span>config_name<span class="token operator">=</span>config_file<span class="token punctuation">,</span> overrides<span class="token operator">=</span>hydra_overrides_extra<span class="token punctuation">)</span>
    OmegaConf<span class="token punctuation">.</span>resolve<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span>
    model <span class="token operator">=</span> instantiate<span class="token punctuation">(</span>cfg<span class="token punctuation">.</span>model<span class="token punctuation">,</span> _recursive_<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    _load_checkpoint<span class="token punctuation">(</span>model<span class="token punctuation">,</span> ckpt_path<span class="token punctuation">)</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">"eval"</span><span class="token punctuation">:</span>
        model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>build_sam2()</code>è¿™ä¸ªå‡½æ•°ä»config.yamlé‡Œé¢åŠ è½½å¯¹åº”è§„æ¨¡æ¨¡å‹å‚æ•°ï¼Œæ„å»ºæ¨¡å‹ã€‚</p>
<h3 id="SAM2æ ¸å¿ƒï¼šsam2-image-predictor-py"><a href="#SAM2æ ¸å¿ƒï¼šsam2-image-predictor-py" class="headerlink" title="SAM2æ ¸å¿ƒï¼šsam2_image_predictor.py"></a>SAM2æ ¸å¿ƒï¼šsam2_image_predictor.py</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SAM2ImagePredictor</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        sam_model<span class="token punctuation">:</span> SAM2Base<span class="token punctuation">,</span>
        mask_threshold<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>
        max_hole_area<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>
        max_sprinkle_area<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Uses SAM-2 to calculate the image embedding for an image, and then
        allow repeated, efficient mask prediction given prompts.

        Arguments:
          sam_model (Sam-2): The model to use for mask prediction.
          mask_threshold (float): The threshold to use when converting mask logits
            to binary masks. Masks are thresholded at 0 by default.
          fill_hole_area (int): If fill_hole_area > 0, we fill small holes in up to
            the maximum area of fill_hole_area in low_res_masks.
        """</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> sam_model
        self<span class="token punctuation">.</span>_transforms <span class="token operator">=</span> SAM2Transforms<span class="token punctuation">(</span>
            resolution<span class="token operator">=</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>image_size<span class="token punctuation">,</span>
            mask_threshold<span class="token operator">=</span>mask_threshold<span class="token punctuation">,</span>
            max_hole_area<span class="token operator">=</span>max_hole_area<span class="token punctuation">,</span>
            max_sprinkle_area<span class="token operator">=</span>max_sprinkle_area<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Predictor state</span>
        self<span class="token punctuation">.</span>_is_image_set <span class="token operator">=</span> <span class="token boolean">False</span>
        self<span class="token punctuation">.</span>_features <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>_orig_hw <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># Whether the predictor is set for single image or a batch of images</span>
        self<span class="token punctuation">.</span>_is_batch <span class="token operator">=</span> <span class="token boolean">False</span>

        <span class="token comment" spellcheck="true"># Predictor config</span>
        self<span class="token punctuation">.</span>mask_threshold <span class="token operator">=</span> mask_threshold

        <span class="token comment" spellcheck="true"># Spatial dim for backbone feature maps</span>
        self<span class="token punctuation">.</span>_bb_feat_sizes <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>SAM2ImagePredictor</code>åŒ…å«äº†æ¨¡å‹çš„æç¤ºå¤„ç†ã€å›¾åƒç¼–ç ã€é¢„æµ‹ï¼Œä½¿å¾—æˆ‘ä»¬ç”¨å®ƒå°±å¯ä»¥è¿›è¡Œé¢„æµ‹æ‰€éœ€çš„å¤§éƒ¨åˆ†æ“ä½œã€‚å®ƒçš„åˆå§‹åŒ–å…¶å®å°±æ˜¯åœ¨æ¨¡å‹ä¹‹å¤–åŠ äº†ä¸ª<code>SAM2Transforms</code>ï¼Œå®ƒåŒ…å«å¯¹æ•°æ®çš„é¢„å¤„ç†ï¼ˆresizeã€å½’ä¸€åŒ–ç­‰ï¼‰å’Œè¾“å‡ºmasksçš„åå¤„ç†ã€‚</p>
<p><code>SAM2ImagePredictor</code>è¿˜æä¾›äº†<code>predict</code>ã€<code>_predict</code>ã€<code>predict_batch</code>å‡ ä¸ªå‡½æ•°ï¼Œç”¨äºé¢„æµ‹ï¼Œå†…å®¹å’Œè®­ç»ƒçš„è¿‡ç¨‹å·®ä¸å¤šï¼Œåªä¸è¿‡æ²¡æœ‰æ¢¯åº¦ã€‚</p>
<h2 id="ğŸš å›¾åƒç¼–ç "><a href="#ğŸš å›¾åƒç¼–ç " class="headerlink" title="ğŸš å›¾åƒç¼–ç "></a>ğŸš å›¾åƒç¼–ç </h2><p>å‰å‘ä¼ æ’­å¼€å§‹ï¼Œé¦–å…ˆå¯¹å›¾åƒè¿›è¡Œç¼–ç ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">predictor<span class="token punctuation">.</span>set_image_batch<span class="token punctuation">(</span>image_list<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">def</span> <span class="token function">set_image_batch</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        image_list<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> List<span class="token punctuation">[</span>Union<span class="token punctuation">[</span>np<span class="token punctuation">.</span>ndarray<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Calculates the image embeddings for the provided image batch, allowing
        masks to be predicted with the 'predict_batch' method.

        Arguments:
          image_list (List[np.ndarray]): The input images to embed in RGB format. The image should be in HWC format if np.ndarray
          with pixel values in [0, 255].
        """</span>
        self<span class="token punctuation">.</span>reset_predictor<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># assert isinstance(image_list, list)</span>
        self<span class="token punctuation">.</span>_orig_hw <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>image_list<span class="token punctuation">,</span> list<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> image <span class="token keyword">in</span> image_list<span class="token punctuation">:</span>
                <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>
                    image<span class="token punctuation">,</span> np<span class="token punctuation">.</span>ndarray
                <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"Images are expected to be an np.ndarray in RGB format, and of shape  HWC"</span>
                self<span class="token punctuation">.</span>_orig_hw<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># Transform the image to the form expected by the model</span>
            img_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>_transforms<span class="token punctuation">.</span>forward_batch<span class="token punctuation">(</span>image_list<span class="token punctuation">)</span>
            img_batch <span class="token operator">=</span> img_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>                   <span class="token comment" spellcheck="true"># æ˜¯torchå¼ é‡</span>
            <span class="token keyword">for</span> image <span class="token keyword">in</span> torch<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span>image_list<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>_orig_hw<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            img_batch <span class="token operator">=</span> image_list<span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        batch_size <span class="token operator">=</span> img_batch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>
            len<span class="token punctuation">(</span>img_batch<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">4</span> <span class="token operator">and</span> img_batch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">3</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span> f<span class="token string">"img_batch must be of size Bx3xHxW, got {img_batch.shape}"</span>
        logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Computing image embeddings for the provided images..."</span><span class="token punctuation">)</span>
        backbone_out <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>forward_image<span class="token punctuation">(</span>img_batch<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span> vision_feats<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>_prepare_backbone_features<span class="token punctuation">(</span>backbone_out<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># Add no_mem_embed, which is added to the lowest rest feat. map during training on videos</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>directly_add_no_mem_embed<span class="token punctuation">:</span>
            vision_feats<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> vision_feats<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>no_mem_embed

        feats <span class="token operator">=</span> <span class="token punctuation">[</span>
            feat<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">*</span>feat_size<span class="token punctuation">)</span>
            <span class="token keyword">for</span> feat<span class="token punctuation">,</span> feat_size <span class="token keyword">in</span> zip<span class="token punctuation">(</span>vision_feats<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>_bb_feat_sizes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>_features <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"image_embed"</span><span class="token punctuation">:</span> feats<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"high_res_feats"</span><span class="token punctuation">:</span> feats<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>_is_image_set <span class="token operator">=</span> <span class="token boolean">True</span>
        self<span class="token punctuation">.</span>_is_batch <span class="token operator">=</span> <span class="token boolean">True</span>
        logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Image embeddings computed."</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>SAM2ImagePredictor</code>çš„<code>set_image()</code>å’Œ<code>set_image_batch()</code>ä¸¤ä¸ªå‡½æ•°ç”¨äºæŠŠè¾“å…¥çš„å›¾åƒç»è¿‡<code>SAM2Transforms</code>å¤„ç†åï¼Œè¾“å…¥åˆ°imageÂ encoderå½“ä¸­è¿›è¡Œç¼–ç ï¼Œç»è¿‡ç®€å•çš„å¤„ç†åå­˜åœ¨<code>self._features</code>å½“ä¸­ï¼Œ<code>image_embed</code>å’Œ<code>high_res_feats</code>åˆ†åˆ«æ˜¯é‡‘å­—å¡”ç»“æ„è¾“å‡ºçš„æœ€åä¸€å±‚å’Œå‰é¢è‹¥å¹²å±‚çš„ç‰¹å¾ï¼Œå‰é¢çš„å±‚çš„ç‰¹å¾ä¼šæœ‰æ›´é«˜çš„åˆ†è¾¨ç‡ï¼Œ<strong>æœ‰åŠ©äºè¾“å‡ºçš„æ©ç è¿˜åŸåˆ†è¾¨ç‡</strong>ã€‚</p>
<h2 id="ğŸš æç¤ºç¼–ç "><a href="#ğŸš æç¤ºç¼–ç " class="headerlink" title="ğŸš æç¤ºç¼–ç "></a>ğŸš æç¤ºç¼–ç </h2><pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">if</span> use_prompt<span class="token punctuation">:</span>
        mask_input<span class="token punctuation">,</span> unnorm_coords<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> unnorm_box <span class="token operator">=</span> predictor<span class="token punctuation">.</span>_prep_prompts<span class="token punctuation">(</span>input_point<span class="token punctuation">,</span> input_label<span class="token punctuation">,</span> box<span class="token operator">=</span>None<span class="token punctuation">,</span> mask_logits<span class="token operator">=</span>None<span class="token punctuation">,</span> normalize_coords<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># æœ‰æç¤º</span>
        sparse_embeddings<span class="token punctuation">,</span> dense_embeddings <span class="token operator">=</span> predictor<span class="token punctuation">.</span>model<span class="token punctuation">.</span>sam_prompt_encoder<span class="token punctuation">(</span>points<span class="token operator">=</span><span class="token punctuation">(</span>unnorm_coords<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">,</span> boxes<span class="token operator">=</span>None<span class="token punctuation">,</span> masks<span class="token operator">=</span>None<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        sparse_embeddings<span class="token punctuation">,</span> dense_embeddings <span class="token operator">=</span> predictor<span class="token punctuation">.</span>model<span class="token punctuation">.</span>sam_prompt_encoder<span class="token punctuation">(</span>points<span class="token operator">=</span>None<span class="token punctuation">,</span> boxes<span class="token operator">=</span>None<span class="token punctuation">,</span> masks<span class="token operator">=</span>None<span class="token punctuation">)</span>       <span class="token comment" spellcheck="true"># æ— æç¤º</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>ä»¥ä¸Šæ˜¯å¯¹æç¤ºï¼ˆç‚¹åŠå…¶labelã€æ¡†ã€æ©ç ç­‰ï¼‰è¿›è¡Œç¼–ç çš„ç¤ºä¾‹ã€‚</p>
<ul>
<li><p><code>SAM2ImagePredictor._prep_prompts()</code>ï¼šç”¨æ¥é¢„å¤„ç†æç¤ºï¼ŒæŠŠåˆ—è¡¨è¿™äº›æ ¼å¼è½¬ä¸ºå¼ é‡ï¼›</p>
</li>
<li><p><code>predictor.model.sam_prompt_encoder</code>ï¼šåˆ™æ˜¯ç›´æ¥æ‰¾åˆ°promptÂ encoderè¿›è¡Œå‰å‘ä¼ æ’­ï¼Œå¦‚ä¸‹ï¼Œè¾“å‡ºçš„<code>sparse_embeddings</code>ç”±ç‚¹å’Œæ¡†è¿™ç§ç¨€ç–æç¤ºåµŒå…¥å¾—æ¥ï¼Œ<code>dense_embeddings</code>åˆ™ç”±æ©ç è¿™ç§å¯†é›†æç¤ºåµŒå…¥å¾—æ¥ã€‚</p>
</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python">        bs <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_batch_size<span class="token punctuation">(</span>points<span class="token punctuation">,</span> boxes<span class="token punctuation">,</span> masks<span class="token punctuation">)</span>
        sparse_embeddings <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>
            <span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>embed_dim<span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>_get_device<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">if</span> points <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
            coords<span class="token punctuation">,</span> labels <span class="token operator">=</span> points
            point_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>_embed_points<span class="token punctuation">(</span>coords<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token punctuation">(</span>boxes <span class="token keyword">is</span> None<span class="token punctuation">)</span><span class="token punctuation">)</span>
            sparse_embeddings <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>sparse_embeddings<span class="token punctuation">,</span> point_embeddings<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> boxes <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
            box_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>_embed_boxes<span class="token punctuation">(</span>boxes<span class="token punctuation">)</span>
            sparse_embeddings <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>sparse_embeddings<span class="token punctuation">,</span> box_embeddings<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> masks <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
            dense_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>_embed_masks<span class="token punctuation">(</span>masks<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            dense_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>no_mask_embed<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span>
                bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>image_embedding_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>image_embedding_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token punctuation">)</span>

        <span class="token keyword">return</span> sparse_embeddings<span class="token punctuation">,</span> dense_embeddings
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="ğŸš æ©ç è§£ç "><a href="#ğŸš æ©ç è§£ç " class="headerlink" title="ğŸš æ©ç è§£ç "></a>ğŸš æ©ç è§£ç </h2><p>æ¥ä¸‹æ¥å°±æ˜¯å°†æç¤ºå’Œå›¾åƒçš„ç¼–ç é€šè¿‡maskÂ decoderè¿›è¡Œè§£ç è¾“å‡ºæ©ç ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">    high_res_features <span class="token operator">=</span> <span class="token punctuation">[</span>feat_level<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> feat_level <span class="token keyword">in</span> predictor<span class="token punctuation">.</span>_features<span class="token punctuation">[</span><span class="token string">"high_res_feats"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    low_res_masks<span class="token punctuation">,</span> prd_scores<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _ <span class="token operator">=</span> predictor<span class="token punctuation">.</span>model<span class="token punctuation">.</span>sam_mask_decoder<span class="token punctuation">(</span>
        image_embeddings<span class="token operator">=</span>predictor<span class="token punctuation">.</span>_features<span class="token punctuation">[</span><span class="token string">"image_embed"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        image_pe<span class="token operator">=</span>predictor<span class="token punctuation">.</span>model<span class="token punctuation">.</span>sam_prompt_encoder<span class="token punctuation">.</span>get_dense_pe<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        sparse_prompt_embeddings<span class="token operator">=</span>sparse_embeddings<span class="token punctuation">,</span>
        dense_prompt_embeddings<span class="token operator">=</span>dense_embeddings<span class="token punctuation">,</span>
        multimask_output<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        repeat_image<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        high_res_features<span class="token operator">=</span>high_res_features
    <span class="token punctuation">)</span>
    prd_masks <span class="token operator">=</span> predictor<span class="token punctuation">.</span>_transforms<span class="token punctuation">.</span>postprocess_masks<span class="token punctuation">(</span>low_res_masks<span class="token punctuation">,</span> predictor<span class="token punctuation">.</span>_orig_hw<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="è§£ç ï¼šmask-decoder-py"><a href="#è§£ç ï¼šmask-decoder-py" class="headerlink" title="è§£ç ï¼šmaskÂ decoder.py"></a>è§£ç ï¼šmaskÂ decoder.py</h3><p><code>sam_mask_decoder</code>æ˜¯æ‰¾åˆ°maskÂ decoderè¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè¾“å…¥åŒ…å«å›¾åƒç¼–ç <code>image_embeddings</code>ã€å›¾åƒä½ç½®ç¼–ç <code>image_pe</code>ã€æç¤ºçš„ç¨€ç–ç¼–ç <code>sparse_prompt_embeddings</code>ã€æç¤ºçš„å¯†é›†ç¼–ç <code>dense_prompt_embeddings</code>ã€æ˜¯å¦é¢„æµ‹å¤šæ©ç <code>multimask_output</code>ã€å›¾åƒé«˜åˆ†è¾¨ç‡ç‰¹å¾<code>high_res_features</code>ï¼›</p>
<pre class="line-numbers language-python"><code class="language-python">        masks<span class="token punctuation">,</span> iou_pred<span class="token punctuation">,</span> mask_tokens_out<span class="token punctuation">,</span> object_score_logits <span class="token operator">=</span> self<span class="token punctuation">.</span>predict_masks<span class="token punctuation">(</span>
            image_embeddings<span class="token operator">=</span>image_embeddings<span class="token punctuation">,</span>
            image_pe<span class="token operator">=</span>image_pe<span class="token punctuation">,</span>
            sparse_prompt_embeddings<span class="token operator">=</span>sparse_prompt_embeddings<span class="token punctuation">,</span>
            dense_prompt_embeddings<span class="token operator">=</span>dense_prompt_embeddings<span class="token punctuation">,</span>
            repeat_image<span class="token operator">=</span>repeat_image<span class="token punctuation">,</span>
            high_res_features<span class="token operator">=</span>high_res_features<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Select the correct mask or masks for output</span>
        <span class="token keyword">if</span> multimask_output<span class="token punctuation">:</span>
            masks <span class="token operator">=</span> masks<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            iou_pred <span class="token operator">=</span> iou_pred<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>dynamic_multimask_via_stability <span class="token operator">and</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>
            masks<span class="token punctuation">,</span> iou_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>_dynamic_multimask_via_stability<span class="token punctuation">(</span>masks<span class="token punctuation">,</span> iou_pred<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            masks <span class="token operator">=</span> masks<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            iou_pred <span class="token operator">=</span> iou_pred<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>

        <span class="token keyword">if</span> multimask_output <span class="token operator">and</span> self<span class="token punctuation">.</span>use_multimask_token_for_obj_ptr<span class="token punctuation">:</span>
            sam_tokens_out <span class="token operator">=</span> mask_tokens_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># [b, 3, c] shape</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># Take the mask output token. Here we *always* use the token for single mask output.</span>
            <span class="token comment" spellcheck="true"># At test time, even if we track after 1-click (and using multimask_output=True),</span>
            <span class="token comment" spellcheck="true"># we still take the single mask token here. The rationale is that we always track</span>
            <span class="token comment" spellcheck="true"># after multiple clicks during training, so the past tokens seen during training</span>
            <span class="token comment" spellcheck="true"># are always the single mask token (and we'll let it be the object-memory token).</span>
            sam_tokens_out <span class="token operator">=</span> mask_tokens_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># [b, 1, c] shape</span>

        <span class="token comment" spellcheck="true"># Prepare output</span>
        <span class="token keyword">return</span> masks<span class="token punctuation">,</span> iou_pred<span class="token punctuation">,</span> sam_tokens_out<span class="token punctuation">,</span> object_score_logits
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>é‡ç‚¹æ˜¾ç„¶åœ¨<code>predict_masks()</code>å‡½æ•°ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">def</span> <span class="token function">predict_masks</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        image_embeddings<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span>
        image_pe<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span>
        sparse_prompt_embeddings<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span>
        dense_prompt_embeddings<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span>
        repeat_image<span class="token punctuation">:</span> bool<span class="token punctuation">,</span>
        high_res_features<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> None<span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Tuple<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Predicts masks. See 'forward' for more details."""</span>
        <span class="token comment" spellcheck="true"># Concatenate output tokens</span>
        s <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pred_obj_scores<span class="token punctuation">:</span>
            output_tokens <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>
                <span class="token punctuation">[</span>
                    self<span class="token punctuation">.</span>obj_score_token<span class="token punctuation">.</span>weight<span class="token punctuation">,</span>
                    self<span class="token punctuation">.</span>iou_token<span class="token punctuation">.</span>weight<span class="token punctuation">,</span>
                    self<span class="token punctuation">.</span>mask_tokens<span class="token punctuation">.</span>weight<span class="token punctuation">,</span>
                <span class="token punctuation">]</span><span class="token punctuation">,</span>
                dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
            s <span class="token operator">=</span> <span class="token number">1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            output_tokens <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>
                <span class="token punctuation">[</span>self<span class="token punctuation">.</span>iou_token<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> self<span class="token punctuation">.</span>mask_tokens<span class="token punctuation">.</span>weight<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span>
            <span class="token punctuation">)</span>
        output_tokens <span class="token operator">=</span> output_tokens<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span>
            sparse_prompt_embeddings<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span>
        <span class="token punctuation">)</span>
        tokens <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>output_tokens<span class="token punctuation">,</span> sparse_prompt_embeddings<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Expand per-image data in batch direction to be per-mask</span>
        <span class="token keyword">if</span> repeat_image<span class="token punctuation">:</span>
            src <span class="token operator">=</span> torch<span class="token punctuation">.</span>repeat_interleave<span class="token punctuation">(</span>image_embeddings<span class="token punctuation">,</span> tokens<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># assert image_embeddings.shape[0] == tokens.shape[0]</span>
            src <span class="token operator">=</span> image_embeddings
        src <span class="token operator">=</span> src <span class="token operator">+</span> dense_prompt_embeddings
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>
            image_pe<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"image_pe should have size 1 in batch dim (from `get_dense_pe()`)"</span>
        pos_src <span class="token operator">=</span> torch<span class="token punctuation">.</span>repeat_interleave<span class="token punctuation">(</span>image_pe<span class="token punctuation">,</span> tokens<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w <span class="token operator">=</span> src<span class="token punctuation">.</span>shape

        <span class="token comment" spellcheck="true"># Run the transformer</span>
        hs<span class="token punctuation">,</span> src <span class="token operator">=</span> self<span class="token punctuation">.</span>transformer<span class="token punctuation">(</span>src<span class="token punctuation">,</span> pos_src<span class="token punctuation">,</span> tokens<span class="token punctuation">)</span>
        iou_token_out <span class="token operator">=</span> hs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> s<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        mask_tokens_out <span class="token operator">=</span> hs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> s <span class="token operator">+</span> <span class="token number">1</span> <span class="token punctuation">:</span> <span class="token punctuation">(</span>s <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>num_mask_tokens<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

        <span class="token comment" spellcheck="true"># Upscale mask embeddings and predict masks using the mask tokens</span>
        src <span class="token operator">=</span> src<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>use_high_res_features<span class="token punctuation">:</span>
            upscaled_embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>output_upscaling<span class="token punctuation">(</span>src<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            dc1<span class="token punctuation">,</span> ln1<span class="token punctuation">,</span> act1<span class="token punctuation">,</span> dc2<span class="token punctuation">,</span> act2 <span class="token operator">=</span> self<span class="token punctuation">.</span>output_upscaling
            feat_s0<span class="token punctuation">,</span> feat_s1 <span class="token operator">=</span> high_res_features
            upscaled_embedding <span class="token operator">=</span> act1<span class="token punctuation">(</span>ln1<span class="token punctuation">(</span>dc1<span class="token punctuation">(</span>src<span class="token punctuation">)</span> <span class="token operator">+</span> feat_s1<span class="token punctuation">)</span><span class="token punctuation">)</span>
            upscaled_embedding <span class="token operator">=</span> act2<span class="token punctuation">(</span>dc2<span class="token punctuation">(</span>upscaled_embedding<span class="token punctuation">)</span> <span class="token operator">+</span> feat_s0<span class="token punctuation">)</span>

        hyper_in_list<span class="token punctuation">:</span> List<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_mask_tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>
            hyper_in_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>output_hypernetworks_mlps<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>mask_tokens_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
        hyper_in <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>hyper_in_list<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w <span class="token operator">=</span> upscaled_embedding<span class="token punctuation">.</span>shape
        masks <span class="token operator">=</span> <span class="token punctuation">(</span>hyper_in @ upscaled_embedding<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h <span class="token operator">*</span> w<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Generate mask quality predictions</span>
        iou_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>iou_prediction_head<span class="token punctuation">(</span>iou_token_out<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pred_obj_scores<span class="token punctuation">:</span>
            <span class="token keyword">assert</span> s <span class="token operator">==</span> <span class="token number">1</span>
            object_score_logits <span class="token operator">=</span> self<span class="token punctuation">.</span>pred_obj_score_head<span class="token punctuation">(</span>hs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># Obj scores logits - default to 10.0, i.e. assuming the object is present, sigmoid(10)=1</span>
            object_score_logits <span class="token operator">=</span> <span class="token number">10.0</span> <span class="token operator">*</span> iou_pred<span class="token punctuation">.</span>new_ones<span class="token punctuation">(</span>iou_pred<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> masks<span class="token punctuation">,</span> iou_pred<span class="token punctuation">,</span> mask_tokens_out<span class="token punctuation">,</span> object_score_logits
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/%E6%8E%A9%E7%A0%81%E8%A7%A3%E7%A0%81%E5%99%A8%E7%BB%93%E6%9E%84.png" alt="æ©ç è§£ç å™¨ç»“æ„"></p>
<p>ä»£ç ä¸ä¸Šå›¾ç»“åˆçœ‹ï¼ˆ<em>æ–œä½“</em>ä»£è¡¨å›¾ä¸­å¯¹åº”çš„åç§°ï¼‰ï¼Œ<strong>è¾“å…¥ç«¯</strong>ï¼Œè¾“å‡ºå±‚æƒé‡<code>output_tokens</code>ï¼ˆ<code>iou_token</code>å’Œ<code>mask_tokens</code>ï¼‰ä¸ç¨€ç–æç¤ºç¼–ç æ‹¼æ¥æˆ<code>tokens</code><em>ï¼ˆoutputÂ tokens+promptÂ tokensï¼‰</em>ï¼Œè€Œå›¾åƒç¼–ç ä¸å¯†é›†æç¤ºç¼–ç ï¼ˆæ©ç ï¼‰ç›´æ¥ç›¸åŠ æˆ<code>src</code><em>ï¼ˆimageÂ embeddingï¼‰</em>ï¼Œç„¶åæŠŠ<code>tokens</code>ã€<code>src</code>ã€å›¾åƒä½ç½®ç¼–ç <code>pos_src</code>è¾“å…¥åˆ°<code>self.transformer</code>ï¼ˆSAM2ç”¨çš„2å±‚çš„åŒè·¯transformerï¼Œ<em>çº¢è‰²éƒ¨åˆ†</em>ï¼‰ã€‚</p>
<p><strong>è¾“å‡ºç«¯</strong>ï¼Œé«˜åˆ†è¾¨ç‡ç‰¹å¾ï¼ˆ<em>strideÂ 4,Â 8Â feats</em>ï¼‰å¯é€‰æ‹©åœ°è¢«ç”¨åœ¨ä¸Šé‡‡æ ·ç¯èŠ‚ï¼ˆè½¬ç½®å·ç§¯ï¼Œ<em>conv.trans</em>ï¼‰ç”Ÿæˆmasksï¼Œæ³¨æ„åŠ›è¾“å‡ºå±‚çš„è¾“å‡º<code>hs</code>ä¼šåˆ†è§£æˆ3ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«ç»è¿‡å„è‡ªçš„MLPï¼ˆ<em>å³è¾¹3ä¸ªmlp</em>ï¼‰è¾“å‡ºæ©ç ã€IoUé¢„æµ‹åˆ†æ•°ã€é®æŒ¡åˆ†æ•°ï¼Œç¬¬ä¸€éƒ¨åˆ†åœ¨ç»è¿‡mlpä¹‹å‰ä¼šç›´æ¥ä½œä¸ºç›®æ ‡å¸§çš„æŒ‡é’ˆï¼ˆé®æŒ¡åˆ†æ•°å’ŒæŒ‡é’ˆä»…ç”¨äºè§†é¢‘ä»»åŠ¡ï¼‰ã€‚masksç”±ä¸Šé‡‡æ ·æ¨¡å—å’Œç¬¬ä¸€ä»½MLPçš„è¾“å‡ºè¿›è¡ŒçŸ©é˜µä¹˜æ³•å¾—åˆ°ï¼Œå¦‚æœä¸€æ¬¡ç”Ÿæˆå¤šä¸ªmasksï¼Œåˆ™æ¯ä¸ªmaskéƒ½ä¼šå¯¹åº”ä¸€ä¸ªMLPï¼ˆ<code>self.output_hypernetworks_mlps</code>é‡Œé¢ï¼‰ã€‚</p>
<h3 id="åå¤„ç†ç”Ÿæˆæœ€ç»ˆmasks"><a href="#åå¤„ç†ç”Ÿæˆæœ€ç»ˆmasks" class="headerlink" title="åå¤„ç†ç”Ÿæˆæœ€ç»ˆmasks"></a>åå¤„ç†ç”Ÿæˆæœ€ç»ˆmasks</h3><p>è¾“å‡ºçš„ä½åˆ†è¾¨ç‡å›¾åƒéœ€è¦è½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡çš„ï¼Œç”¨åˆ°ä¹‹å‰è¯´çš„<code>SAM2Transforms</code>çš„åå¤„ç†å‡½æ•°<code>postprocess_masks()</code>ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">def</span> <span class="token function">postprocess_masks</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> masks<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> orig_hw<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Perform PostProcessing on output masks.
        """</span>
        <span class="token keyword">from</span> sam2<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>misc <span class="token keyword">import</span> get_connected_components

        masks <span class="token operator">=</span> masks<span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>max_hole_area <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># Holes are those connected components in background with area &lt;= self.fill_hole_area</span>
            <span class="token comment" spellcheck="true"># (background regions are those with mask scores &lt;= self.mask_threshold)</span>
            mask_flat <span class="token operator">=</span> masks<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># flatten as 1-channel image</span>
            labels<span class="token punctuation">,</span> areas <span class="token operator">=</span> get_connected_components<span class="token punctuation">(</span>mask_flat <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>mask_threshold<span class="token punctuation">)</span>
            is_hole <span class="token operator">=</span> <span class="token punctuation">(</span>labels <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>areas <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>max_hole_area<span class="token punctuation">)</span>
            is_hole <span class="token operator">=</span> is_hole<span class="token punctuation">.</span>reshape_as<span class="token punctuation">(</span>masks<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># We fill holes with a small positive mask score (10.0) to change them to foreground.</span>
            masks <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>is_hole<span class="token punctuation">,</span> self<span class="token punctuation">.</span>mask_threshold <span class="token operator">+</span> <span class="token number">10.0</span><span class="token punctuation">,</span> masks<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>max_sprinkle_area <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
            labels<span class="token punctuation">,</span> areas <span class="token operator">=</span> get_connected_components<span class="token punctuation">(</span>mask_flat <span class="token operator">></span> self<span class="token punctuation">.</span>mask_threshold<span class="token punctuation">)</span>
            is_hole <span class="token operator">=</span> <span class="token punctuation">(</span>labels <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>areas <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>max_sprinkle_area<span class="token punctuation">)</span>
            is_hole <span class="token operator">=</span> is_hole<span class="token punctuation">.</span>reshape_as<span class="token punctuation">(</span>masks<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># We fill holes with negative mask score (-10.0) to change them to background.</span>
            masks <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>is_hole<span class="token punctuation">,</span> self<span class="token punctuation">.</span>mask_threshold <span class="token operator">-</span> <span class="token number">10.0</span><span class="token punctuation">,</span> masks<span class="token punctuation">)</span>

        masks <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>masks<span class="token punctuation">,</span> orig_hw<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"bilinear"</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> masks
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>ç®€å•æ¥è¯´ï¼Œè¯¥å‡½æ•°å®Œæˆäº†å¡«å‘ã€å»å™ªã€æ’å€¼è¿˜åŸå°ºå¯¸ï¼Œè¿”å›äº†çœŸæ­£çš„åŸå°ºå¯¸é¢„æµ‹æ©ç masksã€‚</p>
<p>&#x3D;&#x3D;è‡³æ­¤ï¼Œæˆ‘ä»¬å¯¹è®­ç»ƒã€éªŒè¯ã€é¢„æµ‹éƒ½ä¼šç”¨åˆ°çš„å…³é”®éƒ¨åˆ†ä»£ç éƒ½è¿›è¡Œäº†äº†è§£ï¼Œè¿˜æœ‰æ›´ç»†èŠ‚çš„å‰å‘ä¼ æ’­å’Œç½‘ç»œç»“æ„å‚è§ä¸‹ä¸€å¤§èŠ‚ã€‚&#x3D;&#x3D;</p>
<h1 id="ğŸ”¥ç½‘ç»œç»“æ„"><a href="#ğŸ”¥ç½‘ç»œç»“æ„" class="headerlink" title="ğŸ”¥ç½‘ç»œç»“æ„"></a>ğŸ”¥ç½‘ç»œç»“æ„</h1><p>æ¥ä¸‹æ¥ç›´æ¥ç»†çœ‹ç½‘ç»œå„ä¸ªéƒ¨åˆ†çš„ç»“æ„ï¼Œä»¥åŠç”¨äº†å†™ä»€ä¹ˆæŠ€æœ¯ã€‚sam2&#x2F;modelingæ–‡ä»¶å¤¹åŒ…å«äº†æ•´ä¸ªSAM2çš„ç»“æ„ã€‚</p>
<blockquote>
<p>modeling&#x2F;<br>â”œâ”€â”€Â backbones&#x2F;<br>â”‚Â Â Â â”œâ”€â”€Â hierdet.py<br>â”‚Â Â Â â”œâ”€â”€Â image_encoder.py<br>â”‚Â Â Â â””â”€â”€Â utils.py<br>â””â”€â”€Â sam&#x2F;<br>â”‚Â Â Â â”œâ”€â”€Â mask_decoder.py<br>â”‚Â Â Â â”œâ”€â”€Â prompt_encoder.py<br>â”‚Â Â Â â”œâ”€â”€Â transformer.py<br>â”œâ”€â”€Â memory_attention.py<br>â”œâ”€â”€Â memory_encoder.py<br>â”œâ”€â”€Â position_encoding.py<br>â”œâ”€â”€Â sam2_base.py<br>â””â”€â”€Â sam2_utils.py</p>
</blockquote>
<p>å¯ä»¥çœ‹åˆ°å›¾åƒç¼–ç å™¨åœ¨backbonesï¼Œmaskè§£ç å™¨å’Œæç¤ºç¼–ç å™¨åœ¨samï¼ŒSAM2æ–°å¢çš„å†…å­˜æœºåˆ¶åœ¨modelingï¼ˆä¸è§†é¢‘ç›¸å…³ï¼Œä¸ç»†çœ‹ï¼‰ã€‚</p>
<h2 id="ğŸš å·¥å…·ï¼šsam2-util-py"><a href="#ğŸš å·¥å…·ï¼šsam2-util-py" class="headerlink" title="ğŸš å·¥å…·ï¼šsam2_util.py"></a>ğŸš å·¥å…·ï¼šsam2_util.py</h2><p>é‡Œé¢æœ‰SAM2çš„ä¸€äº›å·¥å…·å‡½æ•°å’Œç±»ï¼š</p>
<ul>
<li><p><code>select_closest_cond_frames()</code>ï¼šå¯»æ‰¾æœ€è¿‘çš„æç¤ºå¸§ï¼Œç”¨äºè§†é¢‘ï¼›</p>
</li>
<li><p><code>get_1d_sine_pe()</code>ï¼šè·å–ä¸€ç»´çš„æ­£å¼¦ä½ç½®ç¼–ç ï¼›</p>
</li>
<li><p><code>get_activation_fn()</code>ï¼šæ ¹æ®é…ç½®è·å–æ¿€æ´»å‡½æ•°ï¼›</p>
</li>
<li><p>è‡ªå®šä¹‰çš„dropout<code>DropPath</code>ã€<code>MLP</code>å’Œ<code>LayerNorm2d</code>å±‚ã€‚</p>
</li>
</ul>
<h2 id="ğŸš ä½ç½®ç¼–ç ï¼šposition-encoding-py"><a href="#ğŸš ä½ç½®ç¼–ç ï¼šposition-encoding-py" class="headerlink" title="ğŸš ä½ç½®ç¼–ç ï¼šposition_encoding.py"></a>ğŸš ä½ç½®ç¼–ç ï¼šposition_encoding.py</h2><p>æä¾›äº†ä¸‰ç§ä½ç½®ç¼–ç ï¼Œ2Dæ­£å¼¦ä½ç½®ç¼–ç <code>PositionEmbeddingSine</code>ã€éšæœºç©ºé—´é¢‘ç‡ä½ç½®ç¼–ç <code>PositionEmbeddingRandom</code>ã€æ—‹è½¬ä½ç½®ç¼–ç RoPEã€‚</p>
<p>SAM2çš„imageÂ encoderç”¨çš„åº”è¯¥æ˜¯<code>PositionEmbeddingSine</code>ï¼›è€ŒpromptÂ encoderç”¨çš„æ˜¯<code>PositionEmbeddingRandom</code>ï¼Œå®ƒå°†åæ ‡æ˜ å°„åˆ°[0,Â 1]åŒºé—´ï¼Œç„¶åä½¿ç”¨éšæœºç”Ÿæˆçš„çŸ©é˜µè¿›è¡Œå˜æ¢ï¼Œæœ€åé€šè¿‡æ­£å¼¦å’Œä½™å¼¦å‡½æ•°ç”Ÿæˆç¼–ç ã€‚</p>
<h2 id="ğŸš SAM2ç½‘ç»œï¼šsam2-base-py"><a href="#ğŸš SAM2ç½‘ç»œï¼šsam2-base-py" class="headerlink" title="ğŸš SAM2ç½‘ç»œï¼šsam2_base.py"></a>ğŸš SAM2ç½‘ç»œï¼šsam2_base.py</h2><p><code>SAM2Base</code>å°±æ˜¯<strong>æ•´ä¸ªSAM2ç½‘ç»œ</strong>ï¼Œåˆå§‹åŒ–å‡½æ•°æ˜¯ä¸€å †ç½‘ç»œç»“æ„æ–¹é¢çš„å‚æ•°è®¾ç½®ï¼Œä¸è¯¦ç»†å±•å¼€äº†ï¼Œå…¶ä¸­æœ€é‡è¦çš„æ˜¯è°ƒç”¨äº†<code>SAM2Base._build_sam_heads()</code>ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">def</span> <span class="token function">_build_sam_heads</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Build SAM-style prompt encoder and mask decoder."""</span>
        self<span class="token punctuation">.</span>sam_prompt_embed_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>hidden_dim
        self<span class="token punctuation">.</span>sam_image_embedding_size <span class="token operator">=</span> self<span class="token punctuation">.</span>image_size <span class="token operator">//</span> self<span class="token punctuation">.</span>backbone_stride

        <span class="token comment" spellcheck="true"># build PromptEncoder and MaskDecoder from SAM</span>
        <span class="token comment" spellcheck="true"># (their hyperparameters like `mask_in_chans=16` are from SAM code)</span>
        self<span class="token punctuation">.</span>sam_prompt_encoder <span class="token operator">=</span> PromptEncoder<span class="token punctuation">(</span>
            embed_dim<span class="token operator">=</span>self<span class="token punctuation">.</span>sam_prompt_embed_dim<span class="token punctuation">,</span>
            image_embedding_size<span class="token operator">=</span><span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>sam_image_embedding_size<span class="token punctuation">,</span>
                self<span class="token punctuation">.</span>sam_image_embedding_size<span class="token punctuation">,</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            input_image_size<span class="token operator">=</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>image_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>image_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
            mask_in_chans<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sam_mask_decoder <span class="token operator">=</span> MaskDecoder<span class="token punctuation">(</span>
            num_multimask_outputs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
            transformer<span class="token operator">=</span>TwoWayTransformer<span class="token punctuation">(</span>
                depth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
                embedding_dim<span class="token operator">=</span>self<span class="token punctuation">.</span>sam_prompt_embed_dim<span class="token punctuation">,</span>
                mlp_dim<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span>
                num_heads<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            transformer_dim<span class="token operator">=</span>self<span class="token punctuation">.</span>sam_prompt_embed_dim<span class="token punctuation">,</span>
            iou_head_depth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
            iou_head_hidden_dim<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>
            use_high_res_features<span class="token operator">=</span>self<span class="token punctuation">.</span>use_high_res_features_in_sam<span class="token punctuation">,</span>
            iou_prediction_use_sigmoid<span class="token operator">=</span>self<span class="token punctuation">.</span>iou_prediction_use_sigmoid<span class="token punctuation">,</span>
            pred_obj_scores<span class="token operator">=</span>self<span class="token punctuation">.</span>pred_obj_scores<span class="token punctuation">,</span>
            pred_obj_scores_mlp<span class="token operator">=</span>self<span class="token punctuation">.</span>pred_obj_scores_mlp<span class="token punctuation">,</span>
            use_multimask_token_for_obj_ptr<span class="token operator">=</span>self<span class="token punctuation">.</span>use_multimask_token_for_obj_ptr<span class="token punctuation">,</span>
            <span class="token operator">**</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>sam_mask_decoder_extra_args <span class="token operator">or</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_obj_ptrs_in_encoder<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># a linear projection on SAM output tokens to turn them into object pointers</span>
            self<span class="token punctuation">.</span>obj_ptr_proj <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">)</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_mlp_for_obj_ptr_proj<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>obj_ptr_proj <span class="token operator">=</span> MLP<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> <span class="token number">3</span>
                <span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>obj_ptr_proj <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>proj_tpos_enc_in_obj_ptrs<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># a linear projection on temporal positional encoding in object pointers to</span>
            <span class="token comment" spellcheck="true"># avoid potential interference with spatial positional encoding</span>
            self<span class="token punctuation">.</span>obj_ptr_tpos_proj <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>mem_dim<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>obj_ptr_tpos_proj <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>_build_sam_heads()</code>ä¸»è¦æ„å»ºçš„æ˜¯promptÂ encoderå’ŒmaskÂ decoderä¸¤ä¸ªéƒ¨åˆ†ï¼ŒimageÂ encoderæ˜¯å¤–éƒ¨ä¼ å…¥çš„ï¼ˆyamlæ–‡ä»¶è®¾ç½®ï¼‰ã€‚æ‰€ä»¥å¯ä»¥çœ‹åˆ°yamlæ–‡ä»¶é‡Œé¢æ˜¯ä¸ä¼šæœ‰è¿™ä¸¤ä¸ªéƒ¨åˆ†çš„å‚æ•°çš„ï¼Œå› ä¸ºåœ¨è¿™é‡Œè®¾ç½®äº†ã€‚</p>
<ul>
<li><p><code>_forward_sam_heads()</code>ï¼špromptÂ encoderå’ŒmaskÂ decoderä¸¤ä¸ªéƒ¨åˆ†çš„å‰å‘ä¼ æ’­ï¼›</p>
</li>
<li><p><code>forward_image()</code>ï¼šè§†è§‰ä¸»å¹²imageÂ encoderçš„å‰å‘ä¼ æ’­ï¼›</p>
</li>
<li><p><code>_prepare_backbone_features()</code>ï¼šä¹‹å‰æåˆ°è¿‡ï¼Œå›¾åƒç¼–ç åä¼šè§£æè¾“å‡ºç”¨ä½œåç»­çš„ç‰¹å¾ï¼›</p>
</li>
<li><p><code>SAM2Base</code>ç¦ç”¨äº†<code>forward</code>ï¼Œéœ€è¦åœ¨ä¹‹å‰æåˆ°çš„<code>SAM2ImagePredictor</code>é‡Œé¢è°ƒç”¨ã€‚</p>
</li>
<li><p><code>SAM2Base</code>ä¸­é™¤äº†ä»¥ä¸Šå‡½æ•°ï¼Œå‰©ä¸‹çš„éƒ½æ˜¯å’Œè§†é¢‘ä»»åŠ¡æœ‰å…³çš„ã€‚</p>
</li>
</ul>
<p>&#x3D;&#x3D;è‡³æ­¤æˆ‘ä»¬å®Œæˆäº†å¯¹æ•´ä¸ªSAM2æ¨¡å‹æœ‰å®è§‚çš„äº†è§£ï¼Œå¯ä»¥çœ‹åˆ°Â SAM2ImagePredictorÂ å’ŒÂ SAM2VideoPredictorÂ æœ¬è´¨ä¸Šç®—æ˜¯SAM2Baseçš„â€œå­ç±»â€ï¼Œåªä¸è¿‡ä¸¤è€…ä¸åŒç¨‹åº¦åœ°ç”¨åˆ°SAM2Baseçš„åŠŸèƒ½ï¼Œæ‰€ä»¥å®˜æ–¹åˆ†å¼€ç»™ä¸åŒéœ€æ±‚è€…ä½¿ç”¨ã€‚&#x3D;&#x3D;</p>
<h2 id="ğŸš å›¾åƒç¼–ç å™¨ï¼šimage-encoder-py"><a href="#ğŸš å›¾åƒç¼–ç å™¨ï¼šimage-encoder-py" class="headerlink" title="ğŸš å›¾åƒç¼–ç å™¨ï¼šimage_encoder.py"></a>ğŸš å›¾åƒç¼–ç å™¨ï¼šimage_encoder.py</h2><p>imageÂ encoderçš„æ„å»ºæ˜¯è¯»å–å¦‚ä¸‹çš„yamlæ–‡ä»¶ï¼Œè¿™æ˜¯SAM2Â b+æ¨¡å‹çš„é…ç½®ï¼Œçœå»äº†å†…å­˜æœºåˆ¶éƒ¨åˆ†ã€‚</p>
<pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token key atrule">model</span><span class="token punctuation">:</span>
  <span class="token key atrule">_target_</span><span class="token punctuation">:</span> sam2.modeling.sam2_base.SAM2Base
  <span class="token key atrule">image_encoder</span><span class="token punctuation">:</span>
    <span class="token key atrule">_target_</span><span class="token punctuation">:</span> sam2.modeling.backbones.image_encoder.ImageEncoder
    <span class="token key atrule">scalp</span><span class="token punctuation">:</span> <span class="token number">1</span>
    <span class="token key atrule">trunk</span><span class="token punctuation">:</span>
      <span class="token key atrule">_target_</span><span class="token punctuation">:</span> sam2.modeling.backbones.hieradet.Hiera
      <span class="token key atrule">embed_dim</span><span class="token punctuation">:</span> <span class="token number">112</span>
      <span class="token key atrule">num_heads</span><span class="token punctuation">:</span> <span class="token number">2</span>
    <span class="token key atrule">neck</span><span class="token punctuation">:</span>
      <span class="token key atrule">_target_</span><span class="token punctuation">:</span> sam2.modeling.backbones.image_encoder.FpnNeck
      <span class="token key atrule">position_encoding</span><span class="token punctuation">:</span>
        <span class="token key atrule">_target_</span><span class="token punctuation">:</span> sam2.modeling.position_encoding.PositionEmbeddingSine
        <span class="token key atrule">num_pos_feats</span><span class="token punctuation">:</span> <span class="token number">256</span>
        <span class="token key atrule">normalize</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
        <span class="token key atrule">scale</span><span class="token punctuation">:</span> <span class="token null important">null</span>
        <span class="token key atrule">temperature</span><span class="token punctuation">:</span> <span class="token number">10000</span>
      <span class="token key atrule">d_model</span><span class="token punctuation">:</span> <span class="token number">256</span>
      <span class="token key atrule">backbone_channel_list</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">896</span><span class="token punctuation">,</span> <span class="token number">448</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">]</span>
      <span class="token key atrule">fpn_top_down_levels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># output level 0 and 1 directly use the backbone features</span>
      <span class="token key atrule">fpn_interp_model</span><span class="token punctuation">:</span> nearest
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ImageEncoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        trunk<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">,</span>
        neck<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">,</span>
        scalp<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>trunk <span class="token operator">=</span> trunk
        self<span class="token punctuation">.</span>neck <span class="token operator">=</span> neck
        self<span class="token punctuation">.</span>scalp <span class="token operator">=</span> scalp
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>trunk<span class="token punctuation">.</span>channel_list <span class="token operator">==</span> self<span class="token punctuation">.</span>neck<span class="token punctuation">.</span>backbone_channel_list
        <span class="token punctuation">)</span><span class="token punctuation">,</span> f<span class="token string">"Channel dims of trunk and neck do not match. Trunk: {self.trunk.channel_list}, neck: {self.neck.backbone_channel_list}"</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sample<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Forward through backbone</span>
        features<span class="token punctuation">,</span> pos <span class="token operator">=</span> self<span class="token punctuation">.</span>neck<span class="token punctuation">(</span>self<span class="token punctuation">.</span>trunk<span class="token punctuation">(</span>sample<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>scalp <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># Discard the lowest resolution features</span>
            features<span class="token punctuation">,</span> pos <span class="token operator">=</span> features<span class="token punctuation">[</span><span class="token punctuation">:</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>scalp<span class="token punctuation">]</span><span class="token punctuation">,</span> pos<span class="token punctuation">[</span><span class="token punctuation">:</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>scalp<span class="token punctuation">]</span>

        src <span class="token operator">=</span> features<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        output <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">"vision_features"</span><span class="token punctuation">:</span> src<span class="token punctuation">,</span>
            <span class="token string">"vision_pos_enc"</span><span class="token punctuation">:</span> pos<span class="token punctuation">,</span>
            <span class="token string">"backbone_fpn"</span><span class="token punctuation">:</span> features<span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">return</span> output
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>ImageEncoder</code>ç”±trunkã€neckç»„æˆï¼Œå®ƒä»¬å·²ç»åœ¨build_sam.pyé‡Œé¢è¯»å–yamlé…ç½®æ—¶å®Œæˆäº†åŠ è½½ï¼Œæ‰€ä»¥è¿™é‡Œç›´æ¥èµ‹å€¼ç»™å±æ€§å°±å¥½äº†ã€‚è€Œå¯¹äºè¿™ä¸¤ä¸ªéƒ¨åˆ†ï¼Œ<strong>å¯ä»¥ç±»æ¯”YOLOç³»åˆ—ç½‘ç»œçš„trunkã€neckéƒ¨åˆ†ï¼ˆä¸‹å›¾å·¦ã€ä¸­éƒ¨åˆ†ï¼‰ï¼Œå®ƒä»¬ç†å¿µä¸Šå‡ ä¹å®Œå…¨ä¸€æ ·</strong>ï¼Œéšç€ä»£ç çš„è§£è¯»å°±èƒ½æ˜ç™½è¿™ç‚¹ã€‚</p>
<p><img src="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/YOLOv8.png" alt="YOLOv8"></p>
<p>å‰å‘ä¼ æ’­ä¹Ÿæ¯”è¾ƒç®€å•ï¼Œç”Ÿæˆçš„<code>output</code>åŒ…å«äº†æœ€ç»ˆå±‚è¾“å‡º<code>vision_features</code>ã€ä½ç½®ç¼–ç <code>vision_pos_enc</code>ã€å¤šå°ºåº¦ç‰¹å¾<code>backbone_fpn</code>ï¼Œå…·ä½“éœ€è¦ä»è¿™ä¸¤ä¸ªéƒ¨åˆ†å»è¯¦ç»†ç†è§£ã€‚æ‰€ä»¥æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹imageÂ encoderçš„ä¸¤ä¸ªéƒ¨åˆ†ã€‚</p>
<h3 id="trunkï¼šhieradet-py"><a href="#trunkï¼šhieradet-py" class="headerlink" title="trunkï¼šhieradet.py"></a>trunkï¼šhieradet.py</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MultiScaleBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        dim<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        dim_out<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        num_heads<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        mlp_ratio<span class="token punctuation">:</span> float <span class="token operator">=</span> <span class="token number">4.0</span><span class="token punctuation">,</span>
        drop_path<span class="token punctuation">:</span> float <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span>
        norm_layer<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">,</span> str<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"LayerNorm"</span><span class="token punctuation">,</span>
        q_stride<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>int<span class="token punctuation">,</span> int<span class="token punctuation">]</span> <span class="token operator">=</span> None<span class="token punctuation">,</span>
        act_layer<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Module <span class="token operator">=</span> nn<span class="token punctuation">.</span>GELU<span class="token punctuation">,</span>
        window_size<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>norm_layer<span class="token punctuation">,</span> str<span class="token punctuation">)</span><span class="token punctuation">:</span>
            norm_layer <span class="token operator">=</span> partial<span class="token punctuation">(</span>getattr<span class="token punctuation">(</span>nn<span class="token punctuation">,</span> norm_layer<span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> dim
        self<span class="token punctuation">.</span>dim_out <span class="token operator">=</span> dim_out
        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>window_size <span class="token operator">=</span> window_size

        self<span class="token punctuation">.</span>pool<span class="token punctuation">,</span> self<span class="token punctuation">.</span>q_stride <span class="token operator">=</span> None<span class="token punctuation">,</span> q_stride
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>q_stride<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>
                kernel_size<span class="token operator">=</span>q_stride<span class="token punctuation">,</span> stride<span class="token operator">=</span>q_stride<span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span>
            <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> MultiScaleAttention<span class="token punctuation">(</span>
            dim<span class="token punctuation">,</span>
            dim_out<span class="token punctuation">,</span>
            num_heads<span class="token operator">=</span>num_heads<span class="token punctuation">,</span>
            q_pool<span class="token operator">=</span>self<span class="token punctuation">.</span>pool<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>drop_path <span class="token operator">=</span> DropPath<span class="token punctuation">(</span>drop_path<span class="token punctuation">)</span> <span class="token keyword">if</span> drop_path <span class="token operator">></span> <span class="token number">0.0</span> <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>dim_out<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mlp <span class="token operator">=</span> MLP<span class="token punctuation">(</span>
            dim_out<span class="token punctuation">,</span>
            int<span class="token punctuation">(</span>dim_out <span class="token operator">*</span> mlp_ratio<span class="token punctuation">)</span><span class="token punctuation">,</span>
            dim_out<span class="token punctuation">,</span>
            num_layers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
            activation<span class="token operator">=</span>act_layer<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token keyword">if</span> dim <span class="token operator">!=</span> dim_out<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim_out<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>MultiScaleBlock</code>æ˜¯åŸºæœ¬çš„transformerå—ï¼ŒåŒ…æ‹¬äº†è¯¥æœ‰çš„å½’ä¸€åŒ–å±‚<code>LayerNorm</code>ã€æ³¨æ„åŠ›å±‚<code>MultiScaleAttention</code>ã€dropoutå±‚<code>DropPath</code>ã€FFNå±‚<code>MLP</code>ï¼Œå…¶ä¸­<code>MultiScaleAttention</code>æ˜¯åŒæ–‡ä»¶ä¸‹å®ç°çš„å¤šå¤´ç‚¹ç§¯æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå’ŒViTçš„æ²¡å¤šå¤§åŒºåˆ«ï¼‰ã€‚å‰å‘ä¼ æ’­æ²¡ä»€ä¹ˆç‰¹åˆ«çš„å°±ä¸å±•ç¤ºã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Hiera</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Reference: https://arxiv.org/abs/2306.00989
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        embed_dim<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">96</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># initial embed dim</span>
        num_heads<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># initial number of heads</span>
        drop_path_rate<span class="token punctuation">:</span> float <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># stochastic depth</span>
        q_pool<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># number of q_pool stages</span>
        q_stride<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>int<span class="token punctuation">,</span> int<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># downsample stride bet. stages</span>
        stages<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>int<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># blocks per stage</span>
        dim_mul<span class="token punctuation">:</span> float <span class="token operator">=</span> <span class="token number">2.0</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># dim_mul factor at stage shift</span>
        head_mul<span class="token punctuation">:</span> float <span class="token operator">=</span> <span class="token number">2.0</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># head_mul factor at stage shift</span>
        window_pos_embed_bkg_spatial_size<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>int<span class="token punctuation">,</span> int<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token comment" spellcheck="true"># window size per stage, when not using global att.</span>
        window_spec<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>int<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>
            <span class="token number">8</span><span class="token punctuation">,</span>
            <span class="token number">4</span><span class="token punctuation">,</span>
            <span class="token number">14</span><span class="token punctuation">,</span>
            <span class="token number">7</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token comment" spellcheck="true"># global attn in these blocks</span>
        global_att_blocks<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>int<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>
            <span class="token number">12</span><span class="token punctuation">,</span>
            <span class="token number">16</span><span class="token punctuation">,</span>
            <span class="token number">20</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        return_interm_layers<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># return feats from every stage</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">assert</span> len<span class="token punctuation">(</span>stages<span class="token punctuation">)</span> <span class="token operator">==</span> len<span class="token punctuation">(</span>window_spec<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>window_spec <span class="token operator">=</span> window_spec

        depth <span class="token operator">=</span> sum<span class="token punctuation">(</span>stages<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>q_stride <span class="token operator">=</span> q_stride
        self<span class="token punctuation">.</span>stage_ends <span class="token operator">=</span> <span class="token punctuation">[</span>sum<span class="token punctuation">(</span>stages<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>stages<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">assert</span> <span class="token number">0</span> <span class="token operator">&lt;=</span> q_pool <span class="token operator">&lt;=</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>stage_ends<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>q_pool_blocks <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token operator">+</span> <span class="token number">1</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> self<span class="token punctuation">.</span>stage_ends<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span>q_pool<span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>return_interm_layers <span class="token operator">=</span> return_interm_layers

        self<span class="token punctuation">.</span>patch_embed <span class="token operator">=</span> PatchEmbed<span class="token punctuation">(</span>
            embed_dim<span class="token operator">=</span>embed_dim<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># Which blocks have global att?</span>
        self<span class="token punctuation">.</span>global_att_blocks <span class="token operator">=</span> global_att_blocks

        <span class="token comment" spellcheck="true"># Windowed positional embedding (https://arxiv.org/abs/2311.05613)</span>
        self<span class="token punctuation">.</span>window_pos_embed_bkg_spatial_size <span class="token operator">=</span> window_pos_embed_bkg_spatial_size
        self<span class="token punctuation">.</span>pos_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>
            torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> embed_dim<span class="token punctuation">,</span> <span class="token operator">*</span>self<span class="token punctuation">.</span>window_pos_embed_bkg_spatial_size<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pos_embed_window <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>
            torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> embed_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_spec<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_spec<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        dpr <span class="token operator">=</span> <span class="token punctuation">[</span>
            x<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> drop_path_rate<span class="token punctuation">,</span> depth<span class="token punctuation">)</span>
        <span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># stochastic depth decay rule</span>

        cur_stage <span class="token operator">=</span> <span class="token number">1</span>
        self<span class="token punctuation">.</span>blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>depth<span class="token punctuation">)</span><span class="token punctuation">:</span>
            dim_out <span class="token operator">=</span> embed_dim
            <span class="token comment" spellcheck="true"># lags by a block, so first block of</span>
            <span class="token comment" spellcheck="true"># next stage uses an initial window size</span>
            <span class="token comment" spellcheck="true"># of previous stage and final window size of current stage</span>
            window_size <span class="token operator">=</span> self<span class="token punctuation">.</span>window_spec<span class="token punctuation">[</span>cur_stage <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span>

            <span class="token keyword">if</span> self<span class="token punctuation">.</span>global_att_blocks <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
                window_size <span class="token operator">=</span> <span class="token number">0</span> <span class="token keyword">if</span> i <span class="token keyword">in</span> self<span class="token punctuation">.</span>global_att_blocks <span class="token keyword">else</span> window_size

            <span class="token keyword">if</span> i <span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>stage_ends<span class="token punctuation">:</span>
                dim_out <span class="token operator">=</span> int<span class="token punctuation">(</span>embed_dim <span class="token operator">*</span> dim_mul<span class="token punctuation">)</span>
                num_heads <span class="token operator">=</span> int<span class="token punctuation">(</span>num_heads <span class="token operator">*</span> head_mul<span class="token punctuation">)</span>
                cur_stage <span class="token operator">+=</span> <span class="token number">1</span>

            block <span class="token operator">=</span> MultiScaleBlock<span class="token punctuation">(</span>
                dim<span class="token operator">=</span>embed_dim<span class="token punctuation">,</span>
                dim_out<span class="token operator">=</span>dim_out<span class="token punctuation">,</span>
                num_heads<span class="token operator">=</span>num_heads<span class="token punctuation">,</span>
                drop_path<span class="token operator">=</span>dpr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>
                q_stride<span class="token operator">=</span>self<span class="token punctuation">.</span>q_stride <span class="token keyword">if</span> i <span class="token keyword">in</span> self<span class="token punctuation">.</span>q_pool_blocks <span class="token keyword">else</span> None<span class="token punctuation">,</span>
                window_size<span class="token operator">=</span>window_size<span class="token punctuation">,</span>
            <span class="token punctuation">)</span>

            embed_dim <span class="token operator">=</span> dim_out
            self<span class="token punctuation">.</span>blocks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>channel_list <span class="token operator">=</span> <span class="token punctuation">(</span>
            <span class="token punctuation">[</span>self<span class="token punctuation">.</span>blocks<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>dim_out <span class="token keyword">for</span> i <span class="token keyword">in</span> self<span class="token punctuation">.</span>stage_ends<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
            <span class="token keyword">if</span> return_interm_layers
            <span class="token keyword">else</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>blocks<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dim_out<span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
  
    <span class="token keyword">def</span> <span class="token function">_get_pos_embed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hw<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>int<span class="token punctuation">,</span> int<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>
        h<span class="token punctuation">,</span> w <span class="token operator">=</span> hw
        window_embed <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_embed_window
        pos_embed <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pos_embed<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"bicubic"</span><span class="token punctuation">)</span>
        pos_embed <span class="token operator">=</span> pos_embed <span class="token operator">+</span> window_embed<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>x <span class="token operator">//</span> y <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> zip<span class="token punctuation">(</span>pos_embed<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> window_embed<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
        pos_embed <span class="token operator">=</span> pos_embed<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> pos_embed

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>patch_embed<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># x: (B, H, W, C)</span>

        <span class="token comment" spellcheck="true"># Add pos embed</span>
        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>_get_pos_embed<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> blk <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> blk<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">==</span> self<span class="token punctuation">.</span>stage_ends<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token punctuation">(</span>
                i <span class="token keyword">in</span> self<span class="token punctuation">.</span>stage_ends <span class="token operator">and</span> self<span class="token punctuation">.</span>return_interm_layers
            <span class="token punctuation">)</span><span class="token punctuation">:</span>
                feats <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
                outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>feats<span class="token punctuation">)</span>

        <span class="token keyword">return</span> outputs
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>Hiera</code>å°±æ˜¯trunkæœ¬èº«ï¼Œ<code>__init__()</code>çœ‹ä¼¼æ¯”è¾ƒå¤æ‚ï¼Œå¯ä»¥å…ˆçœ‹<code>forward()</code>ï¼šå°±æ˜¯å°†<strong>å›¾ç‰‡åˆ†å—</strong>ï¼ˆpatchï¼‰åï¼Œåš<strong>ä½ç½®ç¼–ç </strong>ï¼ˆæ³¨æ„è¿™é‡Œä¸æ˜¯æ­£å¼¦ç¼–ç è€Œæ˜¯ç”¨ä¸€ä¸ªå±‚å»å­¦ï¼‰åå°†<code>x</code>è¾“å…¥åˆ°<strong>ç¼–ç å™¨</strong>ï¼ˆå¤šå±‚<code>MultiScaleBlock</code>ï¼‰ä¸­ï¼Œç¼–ç å™¨æ¯ä¸€çº§çš„ç‰¹å¾éƒ½ä¼šå­˜åˆ°<code>outputs</code>ä¸­ï¼Œä¼ é€’ç»™neckéƒ¨åˆ†ï¼Œè¿™å’Œtransformerå·¥ä½œå½“ä¸­çš„ç¼–ç å™¨æ²¡å¤šå¤§åŒºåˆ«ã€‚</p>
<p>æ‰€ä»¥åè¿‡æ¥çœ‹ï¼Œinitä¹Ÿå°±æ˜¯åšäº†<strong>åˆ†å—åµŒå…¥å±‚</strong>ã€<strong>ä½ç½®ç¼–ç å±‚</strong>ã€<strong>ç¼–ç å™¨</strong>çš„æ„å»ºã€‚å…¶ä¸­<code>PatchEmbed</code>æ˜¯ç”¨å·ç§¯åˆ†å—ï¼Œæ¯ä¸ª<code>MultiScaleBlock</code>æœ‰ä¸åŒçš„çª—å£ï¼ˆpatchï¼‰å¤§å°ï¼Œç›¸å½“äºè¾“å‡ºç‰¹å¾æœ‰å¤šä¸ªä¸åŒçš„å°ºåº¦ã€‚</p>
<h3 id="neckï¼šFpnNeck"><a href="#neckï¼šFpnNeck" class="headerlink" title="neckï¼šFpnNeck"></a>neckï¼šFpnNeck</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FpnNeck</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A modified variant of Feature Pyramid Network (FPN) neck
    (we remove output conv and also do bicubic interpolation similar to ViT
    pos embed interpolation)
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        position_encoding<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">,</span>
        d_model<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        backbone_channel_list<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">,</span>
        kernel_size<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        stride<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        padding<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>
        fpn_interp_model<span class="token punctuation">:</span> str <span class="token operator">=</span> <span class="token string">"bilinear"</span><span class="token punctuation">,</span>
        fuse_type<span class="token punctuation">:</span> str <span class="token operator">=</span> <span class="token string">"sum"</span><span class="token punctuation">,</span>
        fpn_top_down_levels<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> None<span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Initialize the neck
        :param trunk: the backbone
        :param position_encoding: the positional encoding to use
        :param d_model: the dimension of the model
        :param neck_norm: the normalization to use
        """</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>position_encoding <span class="token operator">=</span> position_encoding
        self<span class="token punctuation">.</span>convs <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>backbone_channel_list <span class="token operator">=</span> backbone_channel_list
        <span class="token keyword">for</span> dim <span class="token keyword">in</span> backbone_channel_list<span class="token punctuation">:</span>
            current <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
            current<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span>
                <span class="token string">"conv"</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>
                    in_channels<span class="token operator">=</span>dim<span class="token punctuation">,</span>
                    out_channels<span class="token operator">=</span>d_model<span class="token punctuation">,</span>
                    kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>
                    stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>
                    padding<span class="token operator">=</span>padding<span class="token punctuation">,</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>

            self<span class="token punctuation">.</span>convs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fpn_interp_model <span class="token operator">=</span> fpn_interp_model
        <span class="token keyword">assert</span> fuse_type <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"sum"</span><span class="token punctuation">,</span> <span class="token string">"avg"</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>fuse_type <span class="token operator">=</span> fuse_type

        <span class="token comment" spellcheck="true"># levels to have top-down features in its outputs</span>
        <span class="token comment" spellcheck="true"># e.g. if fpn_top_down_levels is [2, 3], then only outputs of level 2 and 3</span>
        <span class="token comment" spellcheck="true"># have top-down propagation, while outputs of level 0 and level 1 have only</span>
        <span class="token comment" spellcheck="true"># lateral features from the same backbone level.</span>
        <span class="token keyword">if</span> fpn_top_down_levels <span class="token keyword">is</span> None<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># default is to have top-down features on all levels</span>
            fpn_top_down_levels <span class="token operator">=</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>convs<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fpn_top_down_levels <span class="token operator">=</span> list<span class="token punctuation">(</span>fpn_top_down_levels<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>å›¾åƒç¼–ç å™¨çš„neckéƒ¨åˆ†æ˜¯ä¸€ä¸ªç‰¹å¾é‡‘å­—å¡”ï¼Œåˆå§‹åŒ–äº†<strong>ä½ç½®ç¼–ç </strong>ï¼ˆ<code>PositionEmbeddingSine</code>ï¼‰ï¼Œä»¥åŠ<strong>å·ç§¯ç½‘ç»œ</strong>ï¼ˆåˆ—è¡¨ï¼‰ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> xs<span class="token punctuation">:</span> List<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        out <span class="token operator">=</span> <span class="token punctuation">[</span>None<span class="token punctuation">]</span> <span class="token operator">*</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>convs<span class="token punctuation">)</span>
        pos <span class="token operator">=</span> <span class="token punctuation">[</span>None<span class="token punctuation">]</span> <span class="token operator">*</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>convs<span class="token punctuation">)</span>
        <span class="token keyword">assert</span> len<span class="token punctuation">(</span>xs<span class="token punctuation">)</span> <span class="token operator">==</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>convs<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># fpn forward pass</span>
        <span class="token comment" spellcheck="true"># see https://github.com/facebookresearch/detectron2/blob/main/detectron2/modeling/backbone/fpn.py</span>
        prev_features <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># forward in top-down order (from low to high resolution)</span>
        n <span class="token operator">=</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>convs<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> xs<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            lateral_features <span class="token operator">=</span> self<span class="token punctuation">.</span>convs<span class="token punctuation">[</span>n <span class="token operator">-</span> i<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">if</span> i <span class="token keyword">in</span> self<span class="token punctuation">.</span>fpn_top_down_levels <span class="token operator">and</span> prev_features <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
                top_down_features <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>
                    prev_features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    scale_factor<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span>
                    mode<span class="token operator">=</span>self<span class="token punctuation">.</span>fpn_interp_model<span class="token punctuation">,</span>
                    align_corners<span class="token operator">=</span><span class="token punctuation">(</span>
                        None <span class="token keyword">if</span> self<span class="token punctuation">.</span>fpn_interp_model <span class="token operator">==</span> <span class="token string">"nearest"</span> <span class="token keyword">else</span> <span class="token boolean">False</span>
                    <span class="token punctuation">)</span><span class="token punctuation">,</span>
                    antialias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
                prev_features <span class="token operator">=</span> lateral_features <span class="token operator">+</span> top_down_features
                <span class="token keyword">if</span> self<span class="token punctuation">.</span>fuse_type <span class="token operator">==</span> <span class="token string">"avg"</span><span class="token punctuation">:</span>
                    prev_features <span class="token operator">/=</span> <span class="token number">2</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                prev_features <span class="token operator">=</span> lateral_features
            x_out <span class="token operator">=</span> prev_features
            out<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> x_out
            pos<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>position_encoding<span class="token punctuation">(</span>x_out<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>x_out<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>

        <span class="token keyword">return</span> out<span class="token punctuation">,</span> pos
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>å‰å‘ä¼ æ’­ï¼Œå°†trunkä¼ æ¥çš„å¤šå°ºåº¦ç‰¹å¾åˆ†åˆ«è¾“å…¥åˆ°å„è‡ªçš„å·ç§¯ç½‘ç»œä¸­ç”Ÿæˆ<code>lateral_features</code>ï¼Œåœ¨<code>self.fpn_top_down_levels</code>ä¸­çš„å±‚éœ€è¦è¿›è¡Œä¸Šé‡‡æ ·ï¼Œå…¶ç»“æœä¼šä½œä¸ºä¸Šä¸€å¤§èŠ‚çš„&#x3D;&#x3D;ğŸš å›¾åƒç¼–ç &#x3D;&#x3D;å½“ä¸­çš„<code>high_res_feats</code>ç”¨äºååŠ©è¿˜åŸé«˜åˆ†è¾¨ç‡çš„masksã€‚å·ç§¯è¾“å‡º<code>out</code>åœ¨è¿›è¡Œä½ç½®ç¼–ç å¾—åˆ°<code>pos</code>ã€‚</p>
<p>&#x3D;&#x3D;æ‰€ä»¥å›åˆ°<code>ImageEncoder</code>çš„å±‚æ¬¡çœ‹ï¼Œæ•´ä¸ªå›¾ç‰‡ç¼–ç å™¨å°±æ˜¯åƒYOLOä¸€æ ·æå–å¤šå±‚ä¸åŒå°ºåº¦ç‰¹å¾ï¼Œç„¶ååˆ†åˆ«è¾“å…¥åˆ°é‡‘å­—å¡”å½“ä¸­è¿›ä¸€æ­¥æå–ç‰¹å¾ï¼Œæœ€åè¾“å‡ºå›¾åƒç¼–ç ã€‚åŒºåˆ«å°±æ˜¯ä¸»å¹²ç”¨çš„æ˜¯æ³¨æ„åŠ›è€Œä¸æ˜¯å·ç§¯ã€é‡‘å­—å¡”ä¸åƒYOLOçš„PANé‚£æ ·å¤æ‚åœ°æ¥å›èåˆã€‚&#x3D;&#x3D;</p>
<h2 id="ğŸš æç¤ºç¼–ç å™¨ï¼šprompt-encoder-py"><a href="#ğŸš æç¤ºç¼–ç å™¨ï¼šprompt-encoder-py" class="headerlink" title="ğŸš æç¤ºç¼–ç å™¨ï¼šprompt_encoder.py"></a>ğŸš æç¤ºç¼–ç å™¨ï¼šprompt_encoder.py</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">PromptEncoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        embed_dim<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        image_embedding_size<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>int<span class="token punctuation">,</span> int<span class="token punctuation">]</span><span class="token punctuation">,</span>
        input_image_size<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>int<span class="token punctuation">,</span> int<span class="token punctuation">]</span><span class="token punctuation">,</span>
        mask_in_chans<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        activation<span class="token punctuation">:</span> Type<span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>GELU<span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Encodes prompts for input to SAM's mask decoder.

        Arguments:
          embed_dim (int): The prompts' embedding dimension
          image_embedding_size (tuple(int, int)): The spatial size of the
            image embedding, as (H, W).
          input_image_size (int): The padded size of the image as input
            to the image encoder, as (H, W).
          mask_in_chans (int): The number of hidden channels used for
            encoding input masks.
          activation (nn.Module): The activation to use when encoding
            input masks.
        """</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>embed_dim <span class="token operator">=</span> embed_dim
        self<span class="token punctuation">.</span>input_image_size <span class="token operator">=</span> input_image_size
        self<span class="token punctuation">.</span>image_embedding_size <span class="token operator">=</span> image_embedding_size
        self<span class="token punctuation">.</span>pe_layer <span class="token operator">=</span> PositionEmbeddingRandom<span class="token punctuation">(</span>embed_dim <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>num_point_embeddings<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">4</span>  <span class="token comment" spellcheck="true"># pos/neg point + 2 box corners</span>
        point_embeddings <span class="token operator">=</span> <span class="token punctuation">[</span>
            nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_point_embeddings<span class="token punctuation">)</span>
        <span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>point_embeddings <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>point_embeddings<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>not_a_point_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>mask_input_size <span class="token operator">=</span> <span class="token punctuation">(</span>
            <span class="token number">4</span> <span class="token operator">*</span> image_embedding_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token number">4</span> <span class="token operator">*</span> image_embedding_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mask_downscaling <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> mask_in_chans <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            LayerNorm2d<span class="token punctuation">(</span>mask_in_chans <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            activation<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>mask_in_chans <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">,</span> mask_in_chans<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            LayerNorm2d<span class="token punctuation">(</span>mask_in_chans<span class="token punctuation">)</span><span class="token punctuation">,</span>
            activation<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>mask_in_chans<span class="token punctuation">,</span> embed_dim<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>no_mask_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>PromptEncoder</code>ä¸»è¦åˆå§‹åŒ–äº†ä½ç½®ç¼–ç <code>pe_layer</code>ã€ç‚¹åµŒå…¥å±‚<code>point_embeddings</code>ï¼ˆ2+2å…±4ä¸ªç¼–ç å±‚ï¼Œåˆ†åˆ«ç»™<strong>æ­£&#x2F;è´Ÿä¸¤ç§æç¤ºç‚¹åæ ‡</strong>å’Œ<strong>æ¡†çš„ä¸¤ä¸ªé¡¶ç‚¹åæ ‡</strong>ç”¨ï¼‰ã€maskåµŒå…¥å±‚<code>mask_downscaling</code>ï¼ˆç”¨å·ç§¯é™é‡‡æ ·ï¼‰ï¼Œæ²¡æœ‰æç¤ºæ—¶ä¹Ÿä¼šç”¨é•¿åº¦1çš„åµŒå…¥å±‚ä»£æ›¿ã€‚</p>
<p>å¯¹ä¸‰ç§æç¤ºçš„ç¼–ç å¦‚ä¸‹ï¼Œå®ƒä»¬<code>forward()</code>å½“ä¸­ç”¨åˆ°ï¼ˆä¸Šä¸€å¤§èŠ‚&#x3D;&#x3D;ğŸš æç¤ºç¼–ç &#x3D;&#x3D;éƒ¨åˆ†ä»‹ç»è¿‡ï¼‰ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">def</span> <span class="token function">_embed_points</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        points<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span>
        labels<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span>
        pad<span class="token punctuation">:</span> bool<span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Embeds point prompts."""</span>
        points <span class="token operator">=</span> points <span class="token operator">+</span> <span class="token number">0.5</span>  <span class="token comment" spellcheck="true"># Shift to center of pixel</span>
        <span class="token keyword">if</span> pad<span class="token punctuation">:</span>
            padding_point <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>points<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>points<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
            padding_label <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>labels<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>labels<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
            points <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>points<span class="token punctuation">,</span> padding_point<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>labels<span class="token punctuation">,</span> padding_label<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        point_embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>pe_layer<span class="token punctuation">.</span>forward_with_coords<span class="token punctuation">(</span>
            points<span class="token punctuation">,</span> self<span class="token punctuation">.</span>input_image_size
        <span class="token punctuation">)</span>
        point_embedding<span class="token punctuation">[</span>labels <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.0</span>
        point_embedding<span class="token punctuation">[</span>labels <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>not_a_point_embed<span class="token punctuation">.</span>weight
        point_embedding<span class="token punctuation">[</span>labels <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>point_embeddings<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight
        point_embedding<span class="token punctuation">[</span>labels <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>point_embeddings<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight
        point_embedding<span class="token punctuation">[</span>labels <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>point_embeddings<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight
        point_embedding<span class="token punctuation">[</span>labels <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>point_embeddings<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight
        <span class="token keyword">return</span> point_embedding

    <span class="token keyword">def</span> <span class="token function">_embed_boxes</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> boxes<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Embeds box prompts."""</span>
        boxes <span class="token operator">=</span> boxes <span class="token operator">+</span> <span class="token number">0.5</span>  <span class="token comment" spellcheck="true"># Shift to center of pixel</span>
        coords <span class="token operator">=</span> boxes<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        corner_embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>pe_layer<span class="token punctuation">.</span>forward_with_coords<span class="token punctuation">(</span>
            coords<span class="token punctuation">,</span> self<span class="token punctuation">.</span>input_image_size
        <span class="token punctuation">)</span>
        corner_embedding<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>point_embeddings<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight
        corner_embedding<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>point_embeddings<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight
        <span class="token keyword">return</span> corner_embedding

    <span class="token keyword">def</span> <span class="token function">_embed_masks</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> masks<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Embeds mask inputs."""</span>
        mask_embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>mask_downscaling<span class="token punctuation">(</span>masks<span class="token punctuation">)</span>
        <span class="token keyword">return</span> mask_embedding
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li><p>ç‚¹ç¼–ç ï¼šå¯¹pos&#x2F;negä¸¤ç§æç¤ºç‚¹åœ¨ä½ç½®ç¼–ç ä¹‹åï¼Œå†åˆ†åˆ«ç”¨ç¬¬0ã€1ä¸¤ä¸ªç¼–ç å±‚ç¼–ç å³å¯ï¼Œåœ¨æ²¡æœ‰æ¡†æç¤ºæ—¶ä¼šç”¨0æŠŠ2ç»´åæ ‡è¡¥é½åˆ°4ç»´ï¼Œä¿è¯4ä¸ªç¼–ç å±‚éƒ½æœ‰å‚ä¸å‰å‘ä¼ æ’­ï¼›</p>
</li>
<li><p>æ¡†ç¼–ç ï¼šç›´æ¥å¯¹2ä¸ªåæ ‡ç‚¹è¿›è¡Œä½ç½®ç¼–ç ï¼Œå†åˆ†åˆ«ç”¨ç¬¬2ã€3ä¸¤ä¸ªç¼–ç å±‚è¿›è¡Œç¼–ç ï¼›</p>
</li>
<li><p>æ©ç ç¼–ç ï¼šè¾“å…¥åˆ°é™é‡‡æ ·çš„å·ç§¯ç½‘ç»œå³å¯ã€‚</p>
</li>
</ul>
<p>&#x3D;&#x3D;æç¤ºç¼–ç å™¨çš„ç»“æ„å¾ˆç®€å•ï¼Œå‚æ•°é‡å¾ˆå°ï¼Œåœ¨æ²¡æœ‰æç¤ºæ—¶æ•´ä¸ªç¼–ç å™¨å‡ ä¹ä¸å‘æŒ¥ä½œç”¨ã€‚&#x3D;&#x3D;</p>
<h2 id="ğŸš æ©ç è§£ç å™¨ï¼šmask-decoder-py"><a href="#ğŸš æ©ç è§£ç å™¨ï¼šmask-decoder-py" class="headerlink" title="ğŸš æ©ç è§£ç å™¨ï¼šmask_decoder.py"></a>ğŸš æ©ç è§£ç å™¨ï¼šmask_decoder.py</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MaskDecoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        <span class="token operator">*</span><span class="token punctuation">,</span>
        transformer_dim<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        transformer<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">,</span>
        num_multimask_outputs<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>
        activation<span class="token punctuation">:</span> Type<span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>GELU<span class="token punctuation">,</span>
        iou_head_depth<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>
        iou_head_hidden_dim<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">256</span><span class="token punctuation">,</span>
        use_high_res_features<span class="token punctuation">:</span> bool <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
        iou_prediction_use_sigmoid<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        dynamic_multimask_via_stability<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        dynamic_multimask_stability_delta<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span>
        dynamic_multimask_stability_thresh<span class="token operator">=</span><span class="token number">0.98</span><span class="token punctuation">,</span>
        pred_obj_scores<span class="token punctuation">:</span> bool <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
        pred_obj_scores_mlp<span class="token punctuation">:</span> bool <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
        use_multimask_token_for_obj_ptr<span class="token punctuation">:</span> bool <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Predicts masks given an image and prompt embeddings, using a
        transformer architecture.

        Arguments:
          transformer_dim (int): the channel dimension of the transformer
          transformer (nn.Module): the transformer used to predict masks
          num_multimask_outputs (int): the number of masks to predict
            when disambiguating masks
          activation (nn.Module): the type of activation to use when
            upscaling masks
          iou_head_depth (int): the depth of the MLP used to predict
            mask quality
          iou_head_hidden_dim (int): the hidden dimension of the MLP
            used to predict mask quality
        """</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>transformer_dim <span class="token operator">=</span> transformer_dim
        self<span class="token punctuation">.</span>transformer <span class="token operator">=</span> transformer

        self<span class="token punctuation">.</span>num_multimask_outputs <span class="token operator">=</span> num_multimask_outputs

        self<span class="token punctuation">.</span>iou_token <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> transformer_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_mask_tokens <span class="token operator">=</span> num_multimask_outputs <span class="token operator">+</span> <span class="token number">1</span>
        self<span class="token punctuation">.</span>mask_tokens <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_mask_tokens<span class="token punctuation">,</span> transformer_dim<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>pred_obj_scores <span class="token operator">=</span> pred_obj_scores
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pred_obj_scores<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>obj_score_token <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> transformer_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>use_multimask_token_for_obj_ptr <span class="token operator">=</span> use_multimask_token_for_obj_ptr

        self<span class="token punctuation">.</span>output_upscaling <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>
                transformer_dim<span class="token punctuation">,</span> transformer_dim <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            LayerNorm2d<span class="token punctuation">(</span>transformer_dim <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            activation<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>
                transformer_dim <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">,</span> transformer_dim <span class="token operator">//</span> <span class="token number">8</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            activation<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>use_high_res_features <span class="token operator">=</span> use_high_res_features
        <span class="token keyword">if</span> use_high_res_features<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>conv_s0 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>
                transformer_dim<span class="token punctuation">,</span> transformer_dim <span class="token operator">//</span> <span class="token number">8</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span>
            <span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>conv_s1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>
                transformer_dim<span class="token punctuation">,</span> transformer_dim <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span>
            <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>output_hypernetworks_mlps <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>
                MLP<span class="token punctuation">(</span>transformer_dim<span class="token punctuation">,</span> transformer_dim<span class="token punctuation">,</span> transformer_dim <span class="token operator">//</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
                <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_mask_tokens<span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>iou_prediction_head <span class="token operator">=</span> MLP<span class="token punctuation">(</span>
            transformer_dim<span class="token punctuation">,</span>
            iou_head_hidden_dim<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>num_mask_tokens<span class="token punctuation">,</span>
            iou_head_depth<span class="token punctuation">,</span>
            sigmoid_output<span class="token operator">=</span>iou_prediction_use_sigmoid<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pred_obj_scores<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>pred_obj_score_head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>transformer_dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> pred_obj_scores_mlp<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>pred_obj_score_head <span class="token operator">=</span> MLP<span class="token punctuation">(</span>transformer_dim<span class="token punctuation">,</span> transformer_dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># When outputting a single mask, optionally we can dynamically fall back to the best</span>
        <span class="token comment" spellcheck="true"># multimask output token if the single mask output token gives low stability scores.</span>
        self<span class="token punctuation">.</span>dynamic_multimask_via_stability <span class="token operator">=</span> dynamic_multimask_via_stability
        self<span class="token punctuation">.</span>dynamic_multimask_stability_delta <span class="token operator">=</span> dynamic_multimask_stability_delta
        self<span class="token punctuation">.</span>dynamic_multimask_stability_thresh <span class="token operator">=</span> dynamic_multimask_stability_thresh
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>è§£ç å™¨æ ¸å¿ƒæ˜¯ä¸ª<strong>transformer</strong>ï¼Œé™¤æ­¤ä¹‹å¤–æœ‰<strong>é¢„æµ‹IoUå’Œmaskç”¨çš„ç¼–ç å±‚</strong>ï¼ˆ<code>self.iou_token</code>å’Œ<code>self.mask_tokens</code>ï¼‰ã€<strong>ä¸Šé‡‡æ ·maskçš„è½¬ç½®å·ç§¯ç½‘ç»œ</strong><code>self.output_upscaling</code>ã€<strong>ç”Ÿæˆå¤šæ©ç çš„MLPåˆ—è¡¨</strong><code>self.output_hypernetworks_mlps</code>ã€<strong>é¢„æµ‹IoUåˆ†æ•°çš„MLP</strong><code>self.iou_prediction_head</code>ã€<strong>é¢„æµ‹é®æŒ¡åˆ†æ•°çš„MLP</strong><code>self.pred_obj_score_head</code>ï¼Œåé¢è¿™äº›å°±æ²¡æœ‰ä»€ä¹ˆç‰¹åˆ«ä¹‹å¤„ã€‚</p>
<p>å‰å‘ä¼ æ’­åœ¨ç½‘ç»œä¸­çš„è¿‡ç¨‹åœ¨ä¸Šä¸€å¤§èŠ‚çš„&#x3D;&#x3D;ğŸš æ©ç è§£ç &#x3D;&#x3D;å·²ç»è¯¦ç»†ä»‹ç»äº†ï¼Œè¿™é‡Œè¡¥å……ä¸€ä¸‹<code>forward()</code>å‡½æ•°å½“ä¸­åœ¨ç½‘ç»œè¾“å‡ºåè°ƒç”¨çš„<code>masks,Â iou_predÂ =Â self._dynamic_multimask_via_stability(masks,Â iou_pred)</code>ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">def</span> <span class="token function">_get_stability_scores</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mask_logits<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Compute stability scores of the mask logits based on the IoU between upper and
        lower thresholds, similar to https://github.com/fairinternal/onevision/pull/568.
        """</span>
        mask_logits <span class="token operator">=</span> mask_logits<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>
        stability_delta <span class="token operator">=</span> self<span class="token punctuation">.</span>dynamic_multimask_stability_delta
        area_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>mask_logits <span class="token operator">></span> stability_delta<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
        area_u <span class="token operator">=</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>mask_logits <span class="token operator">></span> <span class="token operator">-</span>stability_delta<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
        stability_scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>area_u <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">,</span> area_i <span class="token operator">/</span> area_u<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> stability_scores

    <span class="token keyword">def</span> <span class="token function">_dynamic_multimask_via_stability</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> all_mask_logits<span class="token punctuation">,</span> all_iou_scores<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        When outputting a single mask, if the stability score from the current single-mask
        output (based on output token 0) falls below a threshold, we instead select from
        multi-mask outputs (based on output token 1~3) the mask with the highest predicted
        IoU score. This is intended to ensure a valid mask for both clicking and tracking.
        """</span>
        <span class="token comment" spellcheck="true"># The best mask from multimask output tokens (1~3)</span>
        multimask_logits <span class="token operator">=</span> all_mask_logits<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        multimask_iou_scores <span class="token operator">=</span> all_iou_scores<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        best_scores_inds <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>multimask_iou_scores<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        batch_inds <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>
            multimask_iou_scores<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>all_iou_scores<span class="token punctuation">.</span>device
        <span class="token punctuation">)</span>
        best_multimask_logits <span class="token operator">=</span> multimask_logits<span class="token punctuation">[</span>batch_inds<span class="token punctuation">,</span> best_scores_inds<span class="token punctuation">]</span>
        best_multimask_logits <span class="token operator">=</span> best_multimask_logits<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        best_multimask_iou_scores <span class="token operator">=</span> multimask_iou_scores<span class="token punctuation">[</span>batch_inds<span class="token punctuation">,</span> best_scores_inds<span class="token punctuation">]</span>
        best_multimask_iou_scores <span class="token operator">=</span> best_multimask_iou_scores<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># The mask from singlemask output token 0 and its stability score</span>
        singlemask_logits <span class="token operator">=</span> all_mask_logits<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        singlemask_iou_scores <span class="token operator">=</span> all_iou_scores<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>
        stability_scores <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_stability_scores<span class="token punctuation">(</span>singlemask_logits<span class="token punctuation">)</span>
        is_stable <span class="token operator">=</span> stability_scores <span class="token operator">>=</span> self<span class="token punctuation">.</span>dynamic_multimask_stability_thresh

        <span class="token comment" spellcheck="true"># Dynamically fall back to best multimask output upon low stability scores.</span>
        mask_logits_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>
            is_stable<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> None<span class="token punctuation">,</span> None<span class="token punctuation">]</span><span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>singlemask_logits<span class="token punctuation">)</span><span class="token punctuation">,</span>
            singlemask_logits<span class="token punctuation">,</span>
            best_multimask_logits<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        iou_scores_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>
            is_stable<span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>singlemask_iou_scores<span class="token punctuation">)</span><span class="token punctuation">,</span>
            singlemask_iou_scores<span class="token punctuation">,</span>
            best_multimask_iou_scores<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> mask_logits_out<span class="token punctuation">,</span> iou_scores_out
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>è¯¥å‡½æ•°çš„ç›®çš„æ˜¯åœ¨ä»…ç”Ÿæˆå•ä¸ªæ©ç æ—¶ï¼Œå¦‚æœåŸºäºè¾“å‡ºtokenÂ 0çš„æ©ç çš„ç¨³å®šæ€§åˆ†æ•°ä½äºé˜ˆå€¼ï¼Œåˆ™ä»å¤šæ©ç è¾“å‡ºï¼ˆåŸºäºè¾“å‡ºtokenÂ 1~3ï¼‰ä¸­é€‰æ‹©å…·æœ‰æœ€é«˜é¢„æµ‹IoUåˆ†æ•°çš„æ©ç ã€‚ç¨³å®šæ€§åˆ†æ•°å°±æ˜¯æ ¹æ®Â <code>area_u</code>ï¼ˆä¸Šç•Œé˜ˆå€¼å¯¹åº”çš„åŒºåŸŸé¢ç§¯ï¼‰æ˜¯å¦å¤§äº0æ¥è®¡ç®—ç¨³å®šæ€§åˆ†æ•°Â <code>stability_scores</code>ï¼Œæœ¬è´¨ä¸Šæ˜¯ä¸ªç±»ä¼¼IoUçš„å€¼ã€‚æ‰€ä»¥è¯¥å‡½æ•°å°±æ˜¯å¯¹ç”Ÿæˆæ©ç çš„ä¸€ç§ä¼˜åŒ–æ‰‹æ®µã€‚</p>
<h3 id="åŒè·¯Transformerï¼štransformer-py"><a href="#åŒè·¯Transformerï¼štransformer-py" class="headerlink" title="åŒè·¯Transformerï¼štransformer.py"></a>åŒè·¯Transformerï¼štransformer.py</h3><p><img src="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/%E6%8E%A9%E7%A0%81%E8%A7%A3%E7%A0%81%E5%99%A8%E5%8F%8C%E8%B7%AFtransformer.png" alt="æ©ç è§£ç å™¨åŒè·¯transformer"></p>
<p>è¿™æ˜¯æ©ç è§£ç å™¨ç”¨åˆ°çš„transformeræ¨¡å—ï¼ŒTwoWayæŒ‡çš„åº”è¯¥æ˜¯æœ‰ä¸¤ä¸ªè¾“å…¥å½¢æˆä¸¤æ¡ä¼ æ’­è·¯å¾„ï¼Œé‡Œé¢æœ‰ï¼š</p>
<ul>
<li><p><code>classÂ Attention(nn.Module)</code>ï¼šæ©ç è§£ç å™¨å†…++æ‰€æœ‰çš„æ³¨æ„åŠ›æœºåˆ¶++éƒ½æ˜¯è¿™ä¸ªæ¨¡å—ï¼Œå°±æ˜¯ä¸€ä¸ª<strong>ç‚¹ç§¯å¤šå¤´æ³¨æ„åŠ›å±‚</strong>ï¼Œæ·»åŠ äº†çº¿æ€§å±‚å¯ä»¥å…ˆæ”¹å˜è¾“å…¥qã€kã€vçš„ç»´åº¦å†è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ï¼›</p>
</li>
<li><p><code>classÂ TwoWayAttentionBlock(nn.Module)</code>ï¼šå¦‚ä¸Šå›¾å°æ¡†ï¼ŒåŒ…å«ä¸€ä¸ª<strong>è‡ªæ³¨æ„åŠ›</strong>ã€ä¸¤ä¸ª<strong>äº¤å‰æ³¨æ„åŠ›</strong>å’Œä¸€ä¸ª<strong>MLP</strong>ï¼Œè¿˜æœ‰<strong>LN</strong>å±‚ã€‚</p>
</li>
<li><p><code>classÂ TwoWayTransformer(nn.Module)</code>ï¼šå¦‚ä¸Šå›¾å¤§æ¡†ï¼ŒåŒ…å«2å±‚<code>TwoWayAttentionBlock</code>å’Œä¸€ä¸ª<strong>è¾“å‡ºæ³¨æ„åŠ›å±‚</strong><code>self.final_attn_token_to_image</code>ã€‚</p>
</li>
</ul>
<p>ä»£ç å¦‚ä¸‹ï¼Œå‰å‘ä¼ æ’­ç¡®å®æ˜¯ä¸Šå›¾ä¸­çš„ä¼ æ’­è·¯å¾„ï¼Œ<code>TwoWayAttentionBlock.forward()</code>çš„<code>queries</code>å’Œ<code>keys</code>åˆ†åˆ«æ˜¯æç¤ºç¼–ç ï¼ˆç¨€ç–ï¼‰å’ŒåŠ äº†maskæç¤ºçš„å›¾åƒç¼–ç ï¼ˆå¯†é›†ï¼‰ï¼›å€¼å¾—æ³¨æ„çš„æ˜¯ä¸¤ä¸ªäº¤å‰æ³¨æ„åŠ›çš„qã€kæ˜¯ç›¸åçš„ï¼Œç¬¦åˆä¸Šå›¾çš„Â <strong>tokenÂ toÂ image</strong>Â å’ŒÂ <strong>imageÂ toÂ token</strong>ï¼›è¿˜æœ‰<code>TwoWayAttentionBlock</code>æœ€ç»ˆè¾“å‡ºçš„<code>queries</code>æ˜¯MLPä¹‹åçš„ï¼Œè€Œ<code>keys</code>æ˜¯æœ€åä¸€ä¸ªäº¤å‰æ³¨æ„åŠ›ä¹‹åçš„ï¼Œç¬¦åˆå›¾ä¸­ä¸¤ä¸ªä¸åŒä½ç½®çš„å‡ºå£ç®­å¤´ï¼Œè¿™ä¸¤ä¸ªè¾“å‡ºå¦‚æœæ˜¯æœ€åä¸€ä¸ªå—çš„åˆ™ä¼šè¾“å‡ºç»™<code>self.final_attn_token_to_image</code>å’Œé™é‡‡æ ·æ¨¡å—ï¼Œå¦åˆ™ä¼šä½œä¸ºqã€kè¾“å…¥åˆ°ä¸‹ä¸€ä¸ªå—ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TwoWayTransformer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        depth<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        embedding_dim<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        num_heads<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        mlp_dim<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        activation<span class="token punctuation">:</span> Type<span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">,</span>
        attention_downsample_rate<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        A transformer decoder that attends to an input image using
        queries whose positional embedding is supplied.

        Args:
          depth (int): number of layers in the transformer
          embedding_dim (int): the channel dimension for the input embeddings
          num_heads (int): the number of heads for multihead attention. Must
            divide embedding_dim
          mlp_dim (int): the channel dimension internal to the MLP block
          activation (nn.Module): the activation to use in the MLP block
        """</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>depth <span class="token operator">=</span> depth
        self<span class="token punctuation">.</span>embedding_dim <span class="token operator">=</span> embedding_dim
        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads
        self<span class="token punctuation">.</span>mlp_dim <span class="token operator">=</span> mlp_dim
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>depth<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                TwoWayAttentionBlock<span class="token punctuation">(</span>
                    embedding_dim<span class="token operator">=</span>embedding_dim<span class="token punctuation">,</span>
                    num_heads<span class="token operator">=</span>num_heads<span class="token punctuation">,</span>
                    mlp_dim<span class="token operator">=</span>mlp_dim<span class="token punctuation">,</span>
                    activation<span class="token operator">=</span>activation<span class="token punctuation">,</span>
                    attention_downsample_rate<span class="token operator">=</span>attention_downsample_rate<span class="token punctuation">,</span>
                    skip_first_layer_pe<span class="token operator">=</span><span class="token punctuation">(</span>i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
            <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>final_attn_token_to_image <span class="token operator">=</span> Attention<span class="token punctuation">(</span>
            embedding_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> downsample_rate<span class="token operator">=</span>attention_downsample_rate
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>norm_final_attn <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        image_embedding<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span>
        image_pe<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span>
        point_embedding<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Tuple<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Args:
          image_embedding (torch.Tensor): image to attend to. Should be shape
            B x embedding_dim x h x w for any h and w.
          image_pe (torch.Tensor): the positional encoding to add to the image. Must
            have the same shape as image_embedding.
          point_embedding (torch.Tensor): the embedding to add to the query points.
            Must have shape B x N_points x embedding_dim for any N_points.

        Returns:
          torch.Tensor: the processed point_embedding
          torch.Tensor: the processed image_embedding
        """</span>
        <span class="token comment" spellcheck="true"># BxCxHxW -> BxHWxC == B x N_image_tokens x C</span>
        bs<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w <span class="token operator">=</span> image_embedding<span class="token punctuation">.</span>shape
        image_embedding <span class="token operator">=</span> image_embedding<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        image_pe <span class="token operator">=</span> image_pe<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Prepare queries</span>
        queries <span class="token operator">=</span> point_embedding
        keys <span class="token operator">=</span> image_embedding

        <span class="token comment" spellcheck="true"># Apply transformer blocks and final layernorm</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            queries<span class="token punctuation">,</span> keys <span class="token operator">=</span> layer<span class="token punctuation">(</span>
                queries<span class="token operator">=</span>queries<span class="token punctuation">,</span>
                keys<span class="token operator">=</span>keys<span class="token punctuation">,</span>
                query_pe<span class="token operator">=</span>point_embedding<span class="token punctuation">,</span>
                key_pe<span class="token operator">=</span>image_pe<span class="token punctuation">,</span>
            <span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Apply the final attention layer from the points to the image</span>
        q <span class="token operator">=</span> queries <span class="token operator">+</span> point_embedding
        k <span class="token operator">=</span> keys <span class="token operator">+</span> image_pe
        attn_out <span class="token operator">=</span> self<span class="token punctuation">.</span>final_attn_token_to_image<span class="token punctuation">(</span>q<span class="token operator">=</span>q<span class="token punctuation">,</span> k<span class="token operator">=</span>k<span class="token punctuation">,</span> v<span class="token operator">=</span>keys<span class="token punctuation">)</span>
        queries <span class="token operator">=</span> queries <span class="token operator">+</span> attn_out
        queries <span class="token operator">=</span> self<span class="token punctuation">.</span>norm_final_attn<span class="token punctuation">(</span>queries<span class="token punctuation">)</span>

        <span class="token keyword">return</span> queries<span class="token punctuation">,</span> keys
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TwoWayAttentionBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        embedding_dim<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        num_heads<span class="token punctuation">:</span> int<span class="token punctuation">,</span>
        mlp_dim<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">2048</span><span class="token punctuation">,</span>
        activation<span class="token punctuation">:</span> Type<span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">,</span>
        attention_downsample_rate<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>
        skip_first_layer_pe<span class="token punctuation">:</span> bool <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        A transformer block with four layers: (1) self-attention of sparse
        inputs, (2) cross attention of sparse inputs to dense inputs, (3) mlp
        block on sparse inputs, and (4) cross attention of dense inputs to sparse
        inputs.

        Arguments:
          embedding_dim (int): the channel dimension of the embeddings
          num_heads (int): the number of heads in the attention layers
          mlp_dim (int): the hidden dimension of the mlp block
          activation (nn.Module): the activation of the mlp block
          skip_first_layer_pe (bool): skip the PE on the first layer
        """</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>self_attn <span class="token operator">=</span> Attention<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>cross_attn_token_to_image <span class="token operator">=</span> Attention<span class="token punctuation">(</span>
            embedding_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> downsample_rate<span class="token operator">=</span>attention_downsample_rate
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>mlp <span class="token operator">=</span> MLP<span class="token punctuation">(</span>
            embedding_dim<span class="token punctuation">,</span> mlp_dim<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>activation
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>norm3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>norm4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cross_attn_image_to_token <span class="token operator">=</span> Attention<span class="token punctuation">(</span>
            embedding_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> downsample_rate<span class="token operator">=</span>attention_downsample_rate
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>skip_first_layer_pe <span class="token operator">=</span> skip_first_layer_pe

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span> queries<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> keys<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> query_pe<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> key_pe<span class="token punctuation">:</span> Tensor
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Tuple<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Self attention block</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>skip_first_layer_pe<span class="token punctuation">:</span>
            queries <span class="token operator">=</span> self<span class="token punctuation">.</span>self_attn<span class="token punctuation">(</span>q<span class="token operator">=</span>queries<span class="token punctuation">,</span> k<span class="token operator">=</span>queries<span class="token punctuation">,</span> v<span class="token operator">=</span>queries<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            q <span class="token operator">=</span> queries <span class="token operator">+</span> query_pe
            attn_out <span class="token operator">=</span> self<span class="token punctuation">.</span>self_attn<span class="token punctuation">(</span>q<span class="token operator">=</span>q<span class="token punctuation">,</span> k<span class="token operator">=</span>q<span class="token punctuation">,</span> v<span class="token operator">=</span>queries<span class="token punctuation">)</span>
            queries <span class="token operator">=</span> queries <span class="token operator">+</span> attn_out
        queries <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>queries<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Cross attention block, tokens attending to image embedding</span>
        q <span class="token operator">=</span> queries <span class="token operator">+</span> query_pe
        k <span class="token operator">=</span> keys <span class="token operator">+</span> key_pe
        attn_out <span class="token operator">=</span> self<span class="token punctuation">.</span>cross_attn_token_to_image<span class="token punctuation">(</span>q<span class="token operator">=</span>q<span class="token punctuation">,</span> k<span class="token operator">=</span>k<span class="token punctuation">,</span> v<span class="token operator">=</span>keys<span class="token punctuation">)</span>
        queries <span class="token operator">=</span> queries <span class="token operator">+</span> attn_out
        queries <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>queries<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># MLP block</span>
        mlp_out <span class="token operator">=</span> self<span class="token punctuation">.</span>mlp<span class="token punctuation">(</span>queries<span class="token punctuation">)</span>
        queries <span class="token operator">=</span> queries <span class="token operator">+</span> mlp_out
        queries <span class="token operator">=</span> self<span class="token punctuation">.</span>norm3<span class="token punctuation">(</span>queries<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Cross attention block, image embedding attending to tokens</span>
        q <span class="token operator">=</span> queries <span class="token operator">+</span> query_pe
        k <span class="token operator">=</span> keys <span class="token operator">+</span> key_pe
        attn_out <span class="token operator">=</span> self<span class="token punctuation">.</span>cross_attn_image_to_token<span class="token punctuation">(</span>q<span class="token operator">=</span>k<span class="token punctuation">,</span> k<span class="token operator">=</span>q<span class="token punctuation">,</span> v<span class="token operator">=</span>queries<span class="token punctuation">)</span>
        keys <span class="token operator">=</span> keys <span class="token operator">+</span> attn_out
        keys <span class="token operator">=</span> self<span class="token punctuation">.</span>norm4<span class="token punctuation">(</span>keys<span class="token punctuation">)</span>

        <span class="token keyword">return</span> queries<span class="token punctuation">,</span> keys
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>&#x3D;&#x3D;æ©ç è§£ç å™¨çš„ç»“æ„ç›¸å¯¹å¤æ‚ï¼Œä½†æ˜¯é‚£å¼ å›¾ç”»çš„å’Œä»£ç å®ç°åˆ«æ— äºŒè‡´ï¼Œæ‰€ä»¥åªéœ€è¦çœ‹æ‡‚é‚£å¼ å›¾å°±å¤Ÿäº†ã€‚&#x3D;&#x3D;</p>
<h1 id="ğŸ”¥å›¾è§£æ¶æ„"><a href="#ğŸ”¥å›¾è§£æ¶æ„" class="headerlink" title="ğŸ”¥å›¾è§£æ¶æ„"></a>ğŸ”¥å›¾è§£æ¶æ„</h1><p>&#x3D;&#x3D;è‡³æ­¤ï¼Œæˆ‘ä»¬é€šè¿‡è®­ç»ƒçš„è¿‡ç¨‹äº†è§£äº†é«˜å±‚æ¬¡ä¸‹SAM2æ„å»ºå’Œå‰å‘ä¼ æ’­è¿‡ç¨‹ï¼Œå†é€šè¿‡sam2æ–‡ä»¶å¤¹çš„è§£è¯»äº†è§£äº†æ›´ç»†è‡´çš„ç½‘ç»œç»“æ„ã€å‰å‘ä¼ æ’­ç»†èŠ‚ä»¥åŠä¸€äº›æŠ€æœ¯è¦ç‚¹ã€‚&#x3D;&#x3D;</p>
<p>è¿™æ˜¯æˆ‘ç»“åˆæºç å’Œè®ºæ–‡ç»˜åˆ¶çš„æ€»ç»“SAM2çš„å›¾ï¼Œå³ä¸Šè§’æ˜¯ç®€å›¾ï¼Œè¯¥å›¾èƒ½è¾ƒå‡†ç¡®å±•ç¤ºSAM2çš„ç»“æ„å’Œå·¥ä½œåŸç†ï¼š</p>
<p><img src="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/%E6%9C%80%E8%AF%A6%E7%BB%86SAM2%E6%9E%B6%E6%9E%84.png" alt="æœ€è¯¦ç»†SAM2æ¶æ„"></p>
<p><img src="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/%E6%95%B0%E6%8D%AE%E6%B5%81%E5%8A%A8%E5%9B%BE.png" alt="æ•°æ®æµåŠ¨å›¾"></p>
<p>ä¸Šå›¾æ˜¯é¢„æµ‹çš„ä¸€ä¸ªæ ·ä¾‹ï¼Œæ¸å˜æ¡†å±•ç¤ºäº†æ¯ä¸ªå…³é”®èŠ‚ç‚¹æ•°æ®çš„å½¢çŠ¶ï¼Œè¾“å…¥2ä¸ªå›¾åƒï¼Œæ¯ä¸ªå›¾åƒæœ‰4ä¸ªç›®æ ‡æ¡†ä½œä¸ºæç¤ºï¼Œé¢„æµ‹æ•ˆæœè§ä¸‹å›¾ï¼Œå°±æ˜¯å®ä¾‹åˆ†å‰²äº†ï¼Œæ¥ä¸‹æ¥è®²ä¸€ä¸‹ä¸€äº›å…³é”®éƒ¨åˆ†æ˜¯å¦‚ä½•ä½“ç°å‰é¢ä»‹ç»çš„æ¨¡å‹ç‰¹ç‚¹çš„ï¼š</p>
<ul>
<li><p>å›¾åƒç¼–ç å™¨ï¼šè¾“å…¥3é€šé“å›¾åƒç»è¿‡åˆ†å—é™ä½åˆ°256å°ºå¯¸ï¼Œåœ¨å›¾åƒç¼–ç å™¨çš„trunkå¾—åˆ°å››ä¸ªé˜¶æ®µçš„ä¸åŒå°ºå¯¸çš„ç‰¹å¾ï¼ˆ256ï¼Œ128ï¼Œ64ï¼Œ32ï¼‰ï¼Œå››ç»„ç‰¹å¾åˆ†åˆ«ä¸€ä¸€å¯¹åº”åœ°ç»™åˆ°neckéƒ¨åˆ†çš„å·ç§¯ï¼Œè¾“å‡ºé€šé“æ•°ç»Ÿä¸€ä¸º256ï¼Œé«˜åˆ†è¾¨ç‡high_res_featsä¿å­˜128å’Œ256å°ºå¯¸ï¼Œ64å°ºå¯¸åˆ™ä½œä¸ºå›¾åƒç¼–ç ç‰¹å¾image_embedã€‚</p>
</li>
<li><p>æç¤ºç¼–ç å™¨ï¼šè¾“å‡ºé€šé“æ•°ä¹Ÿæ˜¯256ï¼Œç¨€ç–å’Œå¯†é›†çš„æç¤ºç¼–ç æ˜¾ç„¶å‚æ•°é‡ä¸Šæœ‰åŒºåˆ«ï¼Œè¾“å…¥åˆ°è§£ç å™¨å‰ï¼Œå›¾åƒå’Œæç¤ºç¼–ç éƒ½ä¼šå˜å½¢ï¼ˆå…¶ä¸­4è¡¨ç¤ºçš„æ˜¯4ä¸ªæç¤ºæ¡†ï¼‰ï¼›</p>
</li>
<li><p>è¿›å…¥è§£ç å™¨ï¼Œoutput_tokensç”±iou_tokenï¼ˆ1ï¼‰ã€mask_tokensï¼ˆ4ï¼Œå¤šæ©ç è¾“å‡ºåŠŸèƒ½1+3ï¼‰ã€obj_tokenï¼ˆ1ï¼Œå›¾åƒä»»åŠ¡æ²¡ç”¨å°±æ²¡å†™ï¼‰ä¸€å…±6ä¸ªtokenï¼›åœ¨è§£ç å™¨å½“ä¸­ä¸éš¾å‘ç°ç´«çº¿éƒ½æ˜¯å¯†é›†ç‰¹å¾ï¼Œç»¿è‰²çº¿æ˜¯ç¨€ç–ç‰¹å¾ã€‚</p>
</li>
<li><p>è¾“å‡ºå±‚é¢ï¼š</p>
<ol>
<li><p>æœ€åçš„äº¤å‰æ³¨æ„åŠ›å±‚çš„è¾“å‡ºä¼šé‡æ–°å–å›iou_tokenã€mask_tokensã€obj_tokenï¼Œå…¶ä¸­mask_tokensæ¯ä¸€ä¸ªéƒ½ä¼šå¯¹åº”ä¸€ä¸ªMLPé¢„æµ‹æ©ç ï¼Œæ‰€ä»¥è¾“å‡º2Ã—4Ã—4Ã—32ï¼›</p>
</li>
<li><p>IoUÂ scoresçš„å½¢çŠ¶æ˜¯ï¼ˆ2â†’batchï¼Œ4â†’æ¡†ä¸ªæ•°ï¼Œ4â†’å¤šæ©ç è¾“å‡ºï¼‰æ˜¯å› ä¸ºæ¯ä¸ªæ©ç éƒ½è¦åšä¸€ä¸ªIoUé¢„æµ‹ï¼›</p>
</li>
<li><p>é®æŒ¡åˆ†æ•°æ˜¯ï¼ˆ2â†’batchï¼Œ4â†’æ¡†ä¸ªæ•°ï¼Œ1ï¼‰æ˜¯å› ä¸ºæ¯ä¸ªç‰©ä½“åªè¦åˆ¤æ–­ä¸€æ¬¡æ˜¯ä¸æ˜¯è¢«æŒ¡ä½ï¼ˆå›¾åƒä»»åŠ¡æ²¡ç”¨ï¼‰ï¼›</p>
</li>
<li><p>åœ¨ä¹˜æ³•çš„ä½ç½®è¾“å‡ºäº†ï¼ˆ2â†’batchï¼Œ4â†’æ¡†ä¸ªæ•°ï¼Œ4â†’å¤šæ©ç è¾“å‡ºï¼Œ256â†’å°ºå¯¸ï¼Œ256â†’å°ºå¯¸ï¼‰çš„masksã€‚</p>
</li>
</ol>
</li>
<li><p>åœ¨è§£ç å™¨å¤–ï¼Œå¦‚æœæ¯ä¸ªç›®æ ‡çš„ç¬¬0ä¸ªmaskç¨³å®šæ€§åˆ†æ•°ä¸å¤ªè¡Œï¼Œåˆ™ä¼šåœ¨å‰©ä¸‹3ä¸ªä¸­é€‰æ‹©IoUæœ€å¤§çš„æ©ç è¾“å‡ºï¼ˆä¹‹å‰æåˆ°çš„<code>self._dynamic_multimask_via_stability</code>ï¼‰ï¼Œåªå‰©ä¸‹ï¼ˆ2ï¼Œ4ï¼Œ1ï¼Œ256ï¼Œ256ï¼‰ï¼ŒIoUåˆ†æ•°è‡ªç„¶ä¹Ÿåªå‰©ä¸€ä¸ªï¼Œæœ€åmasksä¼šè¿˜åŸä¸ºåŸå›¾åƒå°ºå¯¸ã€‚</p>
</li>
<li><p>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œé¢„æµ‹æ—¶ï¼Œç”±äºæ¯å¼ å›¾æç¤ºä¸ªæ•°ä¸åŒï¼Œæ„å‘³ç€è¦é¢„æµ‹çš„maskä¸ªæ•°ä¹Ÿä¸åŒï¼Œæ‰€ä»¥å¯¼è‡´ä¸èƒ½ç”¨å¼ é‡è¡¨ç¤ºï¼Œè€Œæ˜¯ç”¨åˆ—è¡¨å­˜å‚¨ï¼Œè¿™æ„å‘³ç€åªèƒ½ä¸€å¼ ä¸€å¼ åœ°ä¼ è¿›æç¤ºç¼–ç å™¨å’Œæ©ç è§£ç å™¨ï¼ŒbatchÂ sizeå°±å˜æˆäº†æ¯å¼ å›¾è¦é¢„æµ‹çš„ç›®æ ‡ä¸ªæ•°ï¼ˆè§£ç å™¨é‡Œé¢çš„2åªæ˜¯ä¸ªç¤ºæ„ï¼‰ã€‚</p>
</li>
</ul>
<p><img src="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/%E9%A2%84%E6%B5%8B%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="é¢„æµ‹ç¤ºæ„å›¾"></p>
<p>å¦‚ä¸‹ï¼Œç®€å•æè¿°æ€»ç»“æ¯ä¸€ä¸ªæ¨¡å—çš„ä½œç”¨ï¼š</p>
<p><img src="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/SAM2%E6%A8%A1%E5%9D%97%E5%88%86%E5%B7%A5%E6%A6%82%E6%8B%AC.png" alt="SAM2æ¨¡å—åŠŸèƒ½æ¦‚æ‹¬"></p>
<p>ä»é¡¹ç›®ç»“æ„ï¼Œæ€»ç»“sam2&#x2F;modelingä¸‹å„ä¸ªè„šæœ¬çš„ä½œç”¨å¦‚ä¸‹ï¼š</p>
<p><img src="/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/SAM2%E6%96%87%E4%BB%B6%E5%8A%9F%E8%83%BD%E6%A6%82%E6%8B%AC.png" alt="SAM2æ–‡ä»¶åŠŸèƒ½æ¦‚æ‹¬"></p>
<h1 id="ğŸ”¥ä¼˜åŠ£åˆ†æ"><a href="#ğŸ”¥ä¼˜åŠ£åˆ†æ" class="headerlink" title="ğŸ”¥ä¼˜åŠ£åˆ†æ"></a>ğŸ”¥ä¼˜åŠ£åˆ†æ</h1><p>SAM2èƒ½å–å¾—è¾ƒå¥½çš„æ•ˆæœç¦»ä¸å¼€ä»¥ä¸‹åŸå› ï¼š</p>
<ol>
<li><p>æ€§èƒ½æå‡ä¸Šï¼Œæœ€é‡è¦çš„æ˜¯<strong>æ³¨æ„åŠ›æœºåˆ¶</strong>çš„å¼•å…¥ï¼Œå¤§å‚æ•°é‡å’Œå¤§è§„æ¨¡æ•°æ®é›†çš„æƒ…å†µä¸‹æ¯”ä¼ ç»Ÿå·ç§¯è¦å¼ºå¾ˆå¤šï¼›</p>
</li>
<li><p><strong>å¤šå°ºåº¦</strong>çš„ä½¿ç”¨ï¼Œåœ¨å›¾åƒæŠ½ç‰¹å¾å’Œæœ€åä¸Šé‡‡æ ·çš„éƒ¨åˆ†éƒ½ç”¨äº†å¤šä¸ªå°ºåº¦çš„å›¾åƒç‰¹å¾ï¼Œè¿™æ˜¯YOLOç­‰æ¨¡å‹ä½¿ç”¨çš„è€æ–¹æ³•ä½†æ˜¯ä¾ç„¶æœ‰ç”¨ï¼›</p>
</li>
<li><p><strong>æç¤ºåŠŸèƒ½</strong>çš„å¼•å…¥ï¼Œæ¯”ä¼ ç»Ÿæ¶æ„æœ€å…·åˆ›æ–°æ€§çš„åœ°æ–¹ï¼Œå®ƒå¯ä»¥ä»¥ä¸åŒå½¢å¼ä¼ é€’ä½¿ç”¨è€…çš„ç›®çš„ï¼Œç›¸æ¯”äºé¢„è®¾åˆ†ç±»å†è®­ç»ƒï¼Œè¿™ç§æ–¹æ³•å¾ˆç›´æ¥åœ°æ»¡è¶³å®½æ³›æ„ä¹‰ä¸Šçš„å…·è±¡éœ€æ±‚ï¼ˆæŠ½è±¡çš„ä¸èƒ½æ»¡è¶³ï¼‰ï¼ŒSAM2å¯¹ä¸åŒç±»å‹æç¤ºçš„ç¼–ç æ–¹å¼ä¹Ÿä¸åŒï¼Œå¯†é›†å’Œç¨€ç–çš„æç¤ºä¹Ÿä¼šè¢«ä¸åŒåœ°ä½¿ç”¨ï¼›</p>
</li>
<li><p>å›¾åƒç¼–ç å™¨åº”è¯¥æ˜¯ç”¨äº†é¢„è®­ç»ƒçš„æƒé‡ï¼Œå·²ç»æœ‰å¾ˆä¸é”™çš„èƒ½åŠ›ï¼Œå†åŠ ä¸ŠSAM2åšäº†ä¸€ä¸ª1Bçš„<strong>æ•°æ®é›†</strong>ï¼Œç”¨æ¨¡å‹æœ¬èº«å°±èƒ½æºæºä¸æ–­åœ°äº§ç”Ÿæ–°çš„æ•°æ®ï¼Œç›¸å½“å¥½ç”¨ï¼›</p>
</li>
<li><p>æ©ç è§£ç å™¨çš„<strong>ç»“æ„è®¾è®¡</strong>ï¼Œå¯ä»¥ä¸é”™åœ°èåˆæç¤ºå’Œå›¾åƒä¸¤ç§æ¨¡æ€çš„ç¼–ç ï¼Œè¾“å‡ºè§£è€¦å’ŒYOLOç³»åˆ—ä¸€æ ·èƒ½å¤Ÿç‹¬ç«‹è¾“å‡ºä¸åŒæ¨¡æ€çš„é¢„æµ‹ï¼›</p>
</li>
<li><p><strong>è½»é‡</strong>ï¼Œå…¶é€Ÿåº¦è™½ç„¶ä¸æ¯”YOLOï¼Œä½†æ˜¯æ¨¡å‹ä¾ç„¶ä¸ç®—å¤§ï¼Œå¤šå°ºåº¦çš„è®¾è®¡å’Œå¾ˆå¤šé™é‡‡æ ·æ“ä½œæœ‰æ•ˆé™ä½äº†æ¨¡å‹å‚æ•°å’Œè®¡ç®—é€Ÿåº¦ï¼Œå¯¹æ•ˆæœå’Œé€Ÿåº¦åšäº†ä¸é”™çš„æƒè¡¡ï¼Œä¹Ÿæä¾›äº†å¤šä¸ªè§„æ¨¡çš„æ¨¡å‹ã€‚</p>
</li>
</ol>
<p>æ€»çš„æ¥è¯´SAM2ä¸Šèƒ½çœ‹åˆ°ViTã€YOLOç­‰å·¥ä½œç”¨åˆ°çš„å¾ˆå¤šå¥½çš„æŠ€æœ¯ï¼Œæœ¬èº«ä¹Ÿåœ¨æ¨¡æ€ä¸Šè¿›è¡Œäº†åˆ›æ–°ï¼ŒåŠ ä¸Štransformeræœ¬èº«çš„å¼ºåº¦ï¼Œä¼šå¾—åˆ°å¾ˆå¥½çš„æ•ˆæœã€‚</p>
<p>ç¼ºç‚¹å’Œæ”¹è¿›å¯èƒ½æ€§ï¼š</p>
<ol>
<li><p>SAM1çš„è®ºæ–‡ä¸­æç¤ºé‡Œé¢åŒ…å«äº†<strong>æ–‡æœ¬</strong>ï¼ŒSAM2çš„ç¤ºæ„å›¾ä¸­å»æ‰äº†æ–‡æœ¬è¿™ä¸ªæç¤ºï¼Œä½†æ˜¯ä¸¤ä¸ªé¡¹ç›®çš„æºç éƒ½æ²¡æœ‰æ–‡æœ¬èƒ½è¢«ä½œä¸ºæç¤ºè¾“å…¥æ¨¡å‹çš„è¿¹è±¡ï¼ŒSAM1åŸæ–‡æ˜¯å¤–æ¥äº†ä¸€ä¸ªCLIPçš„æ–‡æœ¬ç¼–ç å™¨ï¼Œç¼–ç åå†è¾“å…¥SAMä½œä¸ºæç¤ºï¼Œæ•ˆæœä¸Šå¯¹ç®€å•çš„è¯æœ‰æ•ˆæœï¼Œæœ€å¥½è¿˜æ˜¯å¾—é…åˆç‚¹ä½œä¸ºæç¤ºã€‚å¦‚æœæ–‡æœ¬èƒ½å®ç°æ›´å¥½çš„é¢„æµ‹é‚£å…¶å®æ˜¯è¶…è¶Šäº†å…¶å®ƒæç¤ºå½¢å¼ï¼Œå› ä¸ºç‚¹ã€æ¡†å’Œæ©ç è¾“å…¥éœ€è¦ç”¨æˆ·æœ¬èº«çŸ¥é“è¿™äº›ä¸œè¥¿åœ¨å“ªï¼Œå¹¶ä¸”åº”ç”¨åœºæ™¯å…è®¸ç”¨æˆ·è¿›è¡Œäº¤äº’å»ç»™æ¨¡å‹è¿™äº›ä¿¡æ¯ï¼Œè€Œè¿™äº›ä¿¡æ¯å¸¦æœ‰â€œä½œå¼Šâ€çš„æ€§è´¨ï¼Œè€Œæ–‡æœ¬å°±ä¸éœ€è¦äº¤äº’ä¹Ÿä¸å¸¦æœ‰â€œä½œå¼Šâ€æ€§è´¨ï¼Œè€Œæ˜¯å‡†ç¡®åœ°ååº”éœ€æ±‚ï¼Œè¿™æ ·SAMå°±èƒ½éƒ¨åˆ†åœ°æ¥è¿‘LISAçš„æ•ˆæœï¼›</p>
</li>
<li><p>å¯¹äºåˆ†å‰²ä»»åŠ¡ï¼ŒSAM2æœ¬èº«ä¸å…·æœ‰<strong>åˆ†ç±»</strong>çš„èƒ½åŠ›ï¼Œä¹Ÿå°±æ˜¯å®ƒä¸å…³å¿ƒç±»åˆ«åªå…³ç³»å®ƒé•¿ä»€ä¹ˆæ ·ï¼Œå®ƒåªçŸ¥é“ç»™å®ƒä¸€ä¸ªæç¤ºå®ƒå°±ä¸ºæ­¤åˆ†å‰²å‡ºä¸€ä¸ªæ©ç ï¼Œè€Œä¸ç»™æç¤ºçš„æƒ…å†µä¸‹æ¨¡å‹åªä¼šè¾“å‡ºä¸€ä¸ªç›®æ ‡çš„æ©ç ï¼Œæ‰€ä»¥å¦‚æœå¯¹åˆ†ç±»æœ‰éœ€è¦æˆ–è€…æƒ³è‡ªåŠ¨åŒ–ç”Ÿæˆæç¤ºï¼ŒSAM1åŸæ–‡çš„æ–¹æ³•æ˜¯å…ˆç”¨ä¸€ä¸ªç›®æ ‡æ£€æµ‹å™¨ViTDetç”Ÿæˆæ¡†ä½œä¸ºæç¤ºï¼Œè¿™å…¶å®ä¹Ÿæ˜¯æœ‰æ•ˆçš„ï¼Œå› ä¸ºå¦‚æœå¤–æ¥ä¸€ä¸ªå°æ¨¡å‹ä¹Ÿä¸ä¼šæœ‰å¾ˆå¤§å½±å“ï¼ŒåŒæ—¶è¿™ä¸€å®šç¨‹åº¦åæ˜ äº†SAMçš„å±€é™æ€§ã€‚</p>
</li>
<li><p>ç»“æ„ä¸Šæ˜¯å¦å¯ä»¥<strong>ç®€åŒ–</strong>ï¼›</p>
</li>
<li><p><strong>ä½ç½®ç¼–ç </strong>æ˜¯å¦å¯ä»¥ç”¨æ›´æ–°çš„ï¼Œé‡Œé¢æœ‰å®ç°æ—‹è½¬ä½ç½®ç¼–ç ï¼Œä½†æ˜¯æ²¡æœ‰è°ƒç”¨ï¼›</p>
</li>
</ol>
<p>æ€»çš„æ¥è¯´SAM2çš„å¯¹äºå›¾åƒåˆ†å‰²é¢†åŸŸçš„å®šä½æ›´åƒæ˜¯ä¸€ä¸ªæä¾›æç¤ºè¾“å…¥çš„åŸºåº§æ¨¡å‹ã€‚ä¸èƒ½æŠŠå®ƒå½“ä½œä¸€ä¸ªå…¨èƒ½çš„åˆ†å‰²æ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯åœ¨å®ƒä¸»æ‰“çš„æç¤ºåˆ†å‰²åŠŸèƒ½ä¹‹å¤–ï¼Œå¦‚æœè¦åˆ©ç”¨å®ƒï¼Œæ¯”è¾ƒåˆé€‚çš„ç”¨æ³•å°±æ˜¯åƒLISAä¸€æ ·æŠŠå®ƒå½“ä½œä¸€ä¸ªåˆ†å‰²å™¨æ¨¡å—å»ä½¿ç”¨ï¼Œè¿˜æœ‰å®ƒçš„è§†è§‰ç¼–ç å™¨å•ç‹¬æ‹¿å‡ºæ¥ä¹Ÿæ¯”è¾ƒæœ‰ä»·å€¼ï¼ˆç±»ä¼¼ResNet-50ï¼‰ï¼Œå› ä¸ºå®ƒå­¦è¿‡æµ·é‡çš„å›¾åƒä¿¡æ¯ã€‚</p>
<p>æ‰€ä»¥æˆ‘è®¤ä¸ºå¦‚æœè¦æ”¹è¿›SAMï¼Œä¸€ç§è·¯å¾„æ˜¯åœ¨å®ƒçš„æç¤ºåˆ†å‰²é¢†åŸŸå†…åšæ•ˆæœä¸Šçš„æå‡ï¼Œè¿˜æœ‰ä¸€ç§å°±æ˜¯æŠŠå®ƒå½“åšç³»ç»Ÿçš„ä¸€éƒ¨åˆ†åšå‡ºæ›´æœ‰ç”¨çš„åŠŸèƒ½ã€‚</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        åˆ†äº«
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>æ‰«ä¸€æ‰«ï¼Œåˆ†äº«åˆ°å¾®ä¿¡</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://legendleochen.top/2025/06/12/SAM2%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88%E5%92%8C%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/" alt="å¾®ä¿¡åˆ†äº«äºŒç»´ç ">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SAM2/" rel="tag">SAM2</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/" rel="tag">å›¾åƒåˆ†å‰²</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2025/07/12/LISA%E5%90%8E%E6%8E%A2%E7%B4%A2/" class="article-nav-link">
        <strong class="article-nav-caption">ä¸Šä¸€ç¯‡</strong>
        <div class="article-nav-title">
          
            LISAåæ¢ç´¢
          
        </div>
      </a>
    
    
      <a href="/2025/05/21/LISA%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8A%E6%89%8B%E5%92%8C%E5%BE%AE%E8%B0%83/" class="article-nav-link">
        <strong class="article-nav-caption">ä¸‹ä¸€ç¯‡</strong>
        <div class="article-nav-title">LISAå›¾åƒåˆ†å‰²æ¨¡å‹çš„ä¸Šæ‰‹å’Œå¾®è°ƒ</div>
      </a>
    
  </nav>

  
   
  
    
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2023-2025
        <i class="ri-heart-fill heart_icon"></i> LegendLeo Chen
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>è®¿é—®äººæ•°:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>æµè§ˆæ¬¡æ•°:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzzç»Ÿè®¡ -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/mylogo.png" alt="LegendLeo Chen çš„ç©ºé—´"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">ğŸš€ä¸»é¡µ</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">ğŸ’¾å½’æ¡£</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">ğŸ§­åˆ†ç±»</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">ğŸ·ï¸æ ‡ç­¾</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">ğŸ›¸å…³äº</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/analytics">ğŸ“Šç»Ÿè®¡</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="æœç´¢">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>è¯·æˆ‘å–æ¯å’–å•¡å§~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">æ”¯ä»˜å®</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">å¾®ä¿¡</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // sliderå±•å¼€çŠ¶æ€
                // todo: è¿™æ ·ä¸å¥½ï¼Œåé¢æ”¹æˆçŠ¶æ€
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // è·å¾—åŸå›¾å°ºå¯¸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // ç­‰å¾…ä¸¤ç§’é’Ÿåæ¢å¤
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // ç­‰å¾…ä¸¤ç§’é’Ÿåæ¢å¤
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=1491212&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
  <!-- èƒŒæ™¯æ°”æ³¡ -->
  <!--
  <div class="balls-container">
    <div class="balls-particles">
      <span style="--i:11;"></span>
      <span style="--i:12;"></span>
      <span style="--i:24;"></span>
      <span style="--i:10;"></span>
      <span style="--i:14;"></span>
      <span style="--i:23;"></span>
      <span style="--i:18;"></span>
      <span style="--i:16;"></span>
      <span style="--i:19;"></span>
      <span style="--i:20;"></span>
      <span style="--i:22;"></span>
      <span style="--i:25;"></span>
      <span style="--i:18;"></span>
      <span style="--i:21;"></span>
      <span style="--i:13;"></span>
      <span style="--i:15;"></span>
      <span style="--i:26;"></span>
      <span style="--i:17;"></span>
      <span style="--i:13;"></span>
      <span style="--i:26;"></span>
      <span style="--i:28;"></span>
      <span style="--i:11;"></span>
      <span style="--i:12;"></span>
      <span style="--i:24;"></span>
      <span style="--i:10;"></span>
      <span style="--i:14;"></span>
      <span style="--i:23;"></span>
      <span style="--i:18;"></span>
      <span style="--i:16;"></span>
      <span style="--i:19;"></span>
      <span style="--i:20;"></span>
      <span style="--i:22;"></span>
      <span style="--i:25;"></span>
      <span style="--i:18;"></span>
      <span style="--i:21;"></span>
      <span style="--i:13;"></span>
      <span style="--i:15;"></span>
      <span style="--i:26;"></span>
      <span style="--i:17;"></span>
      <span style="--i:13;"></span>
      <span style="--i:26;"></span>
      <span style="--i:28;"></span>
    </div>
  </div>
  <style>
    *
    {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    .balls-container
    { 
      position: fixed;
      top: 0px;
      left: 0px;
      width: 100%;
      height: 100vh;
      overflow: hidden;
      opacity: 0.3;
    }
    
    .balls-particles
    {
      position: fixed;
      display: flex;
      z-index: 3;
      padding: 0 20px;
    }
    
    .balls-particles span
    {
      position: relative;
      bottom: 30px;
      width: 30px;
      height: 30px;
      background-color: #4fc3dc;
      box-shadow: 0 0 0 10px #4fc3dc44,
      0 0 50px #4fc3dc,
      -100px 0 #4fc3dc99,
      100px 0 #ff2d7599;
      margin: 0 4px;
      border-radius: 50%;
      animation: animate 15s ease infinite;
      animation-delay: calc(125s / var(--i));
      transform: translateY(120vh);
    }
    .balls-particles span:nth-child(even) {
      background-color: #ff2d75;
      box-shadow: 0 0 0 10px #ff267544,
      0 0 50px #ff2d75,
      -100px 0 #4fc3dc99,
      100px 0 #4fc3dc99;
      ;
    }
    
    @keyframes animate {
      0%
      {
        transform: translateY(120vh) scale(0) rotate(0deg);
      }
      20%
      {
        transform: translateY(100vh) scale(1) rotate(0deg);
      }
      100%
      {
        transform: translateY(-50vh) scale(0.5) rotate(360deg);
      }
    }
  </style> -->
  <!-- åœ°æœˆç³»ç»Ÿ -->
  <!-- <div class="earth-container" >
    <div class="planet"></div>
    <div class="satellite"></div>
   </div>
   <style>
    *{
      padding: 0;
      margin: 0;
      }
      .earth-container {
        width: 36.25em;
        height: 36.25em;
        position: absolute;
        top:5%;
        left: 93%;
        transform: translate(-50%, -50%);
        opacity: 0.3;
      }
      
      .planet{
        width: 15.62*3em;
        height: 15.62*3em;
        background-color: #02c0f5;
        border-radius: 50%;
        position: absolute;
        margin: auto;
        top:0;
        right: 0;
        bottom: 0;
        left: 0;
        z-index: 1;
      }
      
      .planet::before{
        content: '';
        width: 4em;
        height: 4em;
        background-color: #008fd6;
        position: absolute;
        top:10em;
        left: 8em;
        border-radius: 50%; 
        box-shadow: 15em 15em 0 2em #00d68b, 5em 8em 0 3em #10ade1;
      }
      
      .satellite{
        width: 5em;
        height: 5em;
        background-color: #dee517;
        border-radius: 50%;
        position: relative;
        left: -5em;
        bottom: -30em;
        animation: spin 5s infinite;
        z-index: 1;
      }
      
      @keyframes spin {
        49%{
          z-index: 1;
        }
        50%{
          bottom: 3em;
          left: 35em;
          z-index: -1;
        }
        100%{
          z-index: -1;
        }
      }
    </style> -->
<!-- ä¸‰è§’å½©å¸¦èƒŒæ™¯ -->
  <canvas id="evanyou-canvas" style="opacity: 0.3; position: fixed; top: 0px; left: 0px; z-index: -1; width: 100%; height: 100%; pointer-events: none;"></canvas>
  <script src="https://cdn.jsdelivr.net/gh/XXXZhy/Blog_Image/js/evanyou_canvas.js"></script>
</body>

</html>