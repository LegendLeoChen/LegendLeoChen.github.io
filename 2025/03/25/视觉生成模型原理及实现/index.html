<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta name="description" content="一个秘密空间" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>视觉生成模型原理及实现 |  LegendLeo Chen 的空间</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/mylogo.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
<!-- 封面标闪烁 -->
<link rel="stylesheet" href="/css/zhyBlogTitle.css">
<script src="https://cdn.bootcdn.net/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- jquery，懒加载、统计、说说需要的jquery -->
<script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-视觉生成模型原理及实现"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  视觉生成模型原理及实现
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/03/25/%E8%A7%86%E8%A7%89%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/" class="article-date">
  <time datetime="2025-03-25T08:34:47.000Z" itemprop="datePublished">2025-03-25</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a class="article-category-link" href="/categories/%E7%BC%96%E7%A8%8B/">编程</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">2.6k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">12 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>本文简要记录Stable Diffusion为主的视觉生成大模型的原理和实现。</p>
<h1 id="🔥Stable-Diffusion"><a href="#🔥Stable-Diffusion" class="headerlink" title="🔥Stable Diffusion"></a>🔥Stable Diffusion</h1><span id="more"></span>
<p><img src="/2025/03/25/%E8%A7%86%E8%A7%89%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/stable_diffusion%E6%9E%B6%E6%9E%84.png" alt="Stable Diffusion架构"></p>
<ul>
<li>如图，输入prompt由CLIP模型进行编码，如果有输入图片则由VAE编码器进行编码映射到低维度的子空间（Latent Space），然后由UNet + Scheduler进行扩散，得到的特征给到VAE解码器。</li>
</ul>
<p><img src="/2025/03/25/%E8%A7%86%E8%A7%89%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/CLIP.png" alt="CLIP"></p>
<ul>
<li>CLIP训练时结合了文本标签和图像，所以可以对文本进行编码，CLIP固定了输出token序列长度为77，维度为768。</li>
<li>VAE就是通过卷积将特征图进行降维&#x2F;升维的模块，里面有激活函数、归一化之类的。</li>
</ul>
<p><img src="/2025/03/25/%E8%A7%86%E8%A7%89%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/UNet.png" alt="UNet"></p>
<ul>
<li><p>UNet利用了注意力和残差块，数据通过下采样、中间块、上采样后实现对噪声的预测，中间同尺寸有跳跃连接减少下采样损失。所以VAE部分其实不是必要的，UNet本身也能下&#x2F;上采样。</p>
</li>
<li><p>总的来说，扩散模型就是根据文本提示对一张原始带噪声的图预测其噪声，然后原图减去该噪声后得到目标图，简单来说就是一个<strong>去噪</strong>的过程。训练时就是将图片添加若干噪声，模型预测噪声后和实际加的噪声进行匹配计算损失。</p>
</li>
</ul>
<h1 id="🔥DiT"><a href="#🔥DiT" class="headerlink" title="🔥DiT"></a>🔥DiT</h1><p>diffusion transformer，将diffusion架构中的UNet的纯卷积替换为transformer结构，后续成为Sora等视觉生成模型的基础架构。<br><img src="/2025/03/25/%E8%A7%86%E8%A7%89%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/DiT%E6%9E%B6%E6%9E%84.png" alt="DiT架构"></p>
<ul>
<li>如图，最左边是模型架构，输入噪声原图和文本提示，分别编码后（图片要像ViT那样分成patch），输入到DiT块当中，输出的经过LN等层后就能输出结果。</li>
<li>右边三个都是尝试过的DiT块的结构。</li>
<li>DiT块中大体和transformer的编码器差不多，但是分为两边，左边是图片，右边多出来的是输入的文本，经过自己的MLP后进行缩放不断地连接到图片这一路。</li>
</ul>
<h1 id="🔥实现"><a href="#🔥实现" class="headerlink" title="🔥实现"></a>🔥实现</h1><p>简要通过代码来看看如何实现整个模型。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/waylandzhang/DiT_from_scratch">参考</a></p>
<h2 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">VAE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> latent_dim<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> image_size<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>VAE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>in_channels <span class="token operator">=</span> in_channels
        self<span class="token punctuation">.</span>latent_dim <span class="token operator">=</span> latent_dim
        self<span class="token punctuation">.</span>image_size <span class="token operator">=</span> image_size

        <span class="token comment" spellcheck="true"># Encoder</span>
        <span class="token comment" spellcheck="true"># 3 x 512 x 512 -> 4 x 64 x 64</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>_conv_block<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 64 x 256 x 256</span>
            self<span class="token punctuation">.</span>_conv_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 128 x 128 x 128</span>
            self<span class="token punctuation">.</span>_conv_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 256 x 64 x 64</span>
        <span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Encoder 的潜在空间输出</span>
        self<span class="token punctuation">.</span>fc_mu <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> latent_dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 4 x 64 x 64 &lt;- Latent Space</span>
        self<span class="token punctuation">.</span>fc_var <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> latent_dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 4 x 64 x 64 &lt;- Latent Space</span>

        <span class="token comment" spellcheck="true"># Decoder</span>
        <span class="token comment" spellcheck="true"># 4 x 64 x 64 -> 3 x 512 x 512</span>
        self<span class="token punctuation">.</span>decoder_input <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 256 x 64 x 64</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>_conv_transpose_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 128 x 128 x 128</span>
            self<span class="token punctuation">.</span>_conv_transpose_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 64 x 256 x 256</span>
            self<span class="token punctuation">.</span>_conv_transpose_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 3 x 512 x 512</span>
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [0, 1]</span>
        self<span class="token punctuation">.</span>tanh <span class="token operator">=</span> nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [-1, 1]</span>
            <span class="token keyword">def</span> <span class="token function">_conv_block</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># nn.GroupNorm(num_groups=1, num_channels=out_channels),</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># nn.LeakyReLU(),</span>
            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_conv_transpose_block</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),</span>
            <span class="token comment" spellcheck="true"># nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1),</span>
            <span class="token comment" spellcheck="true"># nn.GroupNorm(num_groups=1, num_channels=out_channels),</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># nn.LeakyReLU(),</span>
            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>VAE结构很简单，就是先通过卷积降采样（encoder），然后通过两个卷积层学习latent space输出（噪声的均值方差），最后通过反卷积升采样（decoder）恢复到原图。</li>
<li><code>nn.ConvTranspose2d</code>是通过转置卷积（反卷积）恢复图像尺寸：通过对特征图插入0，然后使用卷积操作获得大尺寸输出特征。</li>
<li>训练起来和普通CNN区别不大，模型的输入和标号都是原图，主要是多了噪声值（mu、var）用于计算损失。</li>
<li>当然这是最简单VAE，实际上还能把卷积换成注意力等其他结构。</li>
</ul>
<h2 id="DDPM（UNet）"><a href="#DDPM（UNet）" class="headerlink" title="DDPM（UNet）"></a>DDPM（UNet）</h2><p><img src="/2025/03/25/%E8%A7%86%E8%A7%89%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/DDPM.png" alt="DDPM"></p>
<ul>
<li>现在实现一下扩散模型（DDPM），也就是UNet这部分。</li>
</ul>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">UNet_Transformer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> time_dim<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> context_dim<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>time_dim <span class="token operator">=</span> time_dim
        self<span class="token punctuation">.</span>time_mlp <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>time_dim<span class="token punctuation">,</span> time_dim <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>SiLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>time_dim <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> time_dim<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>context_dim <span class="token operator">=</span> context_dim

        <span class="token comment" spellcheck="true"># 初始卷积</span>
        self<span class="token punctuation">.</span>init_conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>SiLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 64 x H x W</span>

        <span class="token comment" spellcheck="true"># 下采样</span>
        self<span class="token punctuation">.</span>down1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_down_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> time_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 128 x H/2 x W/2</span>
        self<span class="token punctuation">.</span>down2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_down_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> time_dim<span class="token punctuation">,</span> self_attn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> cross_attn<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> context_dim<span class="token operator">=</span>context_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 256 x H/4 x W/4</span>
        self<span class="token punctuation">.</span>down3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_down_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> time_dim<span class="token punctuation">,</span> self_attn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> cross_attn<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> context_dim<span class="token operator">=</span>context_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 512 x H/8 x W/8</span>

        <span class="token comment" spellcheck="true"># 中间块</span>
        self<span class="token punctuation">.</span>middle_block <span class="token operator">=</span> _down_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> time_dim<span class="token punctuation">,</span> context_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 512 x H/8 x W/8</span>

        <span class="token comment" spellcheck="true"># 上采样</span>
        self<span class="token punctuation">.</span>up1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_up_conv<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> time_dim<span class="token punctuation">,</span> self_attn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> cross_attn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> context_dim<span class="token operator">=</span>context_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 256 x H/4 x W/4</span>
        self<span class="token punctuation">.</span>up2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_up_conv<span class="token punctuation">(</span><span class="token number">256</span><span class="token operator">+</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> time_dim<span class="token punctuation">,</span> self_attn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> cross_attn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> context_dim<span class="token operator">=</span>context_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 128 x H/2 x W/2</span>
        self<span class="token punctuation">.</span>up3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_up_conv<span class="token punctuation">(</span><span class="token number">128</span><span class="token operator">+</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> time_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 64 x H x W</span>

        <span class="token comment" spellcheck="true"># 最终卷积</span>
        self<span class="token punctuation">.</span>final_conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            ResnetBlock<span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> time_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>SiLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>UNet结构就是先下采样，然后通过中间块，最后上采样输出即可。</li>
<li>和前面的VAE相比就是再上下采样之间用了一个中间块。并且<code>_down_block</code>、<code>_up_conv</code>都不仅是卷积，而是融合resnet和transformer的结构，学习能力更强。</li>
</ul>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><ul>
<li>接下来通过部分代码简要地看看如何训练整个 CLIP + UNet（transformer）的diffusion模型：</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    diffusion_model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    progress_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>total<span class="token operator">=</span>len<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> desc<span class="token operator">=</span>f<span class="token string">"Epoch {epoch+1}/{n_epochs}"</span><span class="token punctuation">)</span>
    epoch_loss <span class="token operator">=</span> <span class="token number">0.0</span>

    <span class="token comment" spellcheck="true"># 训练模型</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
        images <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">"images"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        text <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span>

        <span class="token comment" spellcheck="true"># 使用 CLIP 模型编码文本</span>
        text_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>model_max_length<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
        text_embeddings <span class="token operator">=</span> text_encoder<span class="token punctuation">(</span>text_inputs<span class="token punctuation">.</span>input_ids<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>last_hidden_state

        timesteps <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_timesteps<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 随机选择 timesteps</span>
        noisy_images<span class="token punctuation">,</span> noise <span class="token operator">=</span> noise_scheduler<span class="token punctuation">.</span>add_noise<span class="token punctuation">(</span>images<span class="token punctuation">,</span> timesteps<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 添加噪声</span>
        noise_pred <span class="token operator">=</span> diffusion_model<span class="token punctuation">(</span>noisy_images<span class="token punctuation">,</span> timesteps<span class="token punctuation">,</span> text_embeddings<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 预测噪声</span>
        loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>noise_pred<span class="token punctuation">,</span> noise<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 预测的噪声与真实噪声的均方误差</span>

        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># torch.nn.utils.clip_grad_norm_(diffusion_model.parameters(), 1.0)  # 梯度裁剪</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># scheduler.step()  # OneCycleLR 在每个批次后调用</span>

        epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        progress_bar<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>数据集是图-文本对，对文本分词后，先使用网上预训练好的CLIP对文本进行编码，然后用噪声器添加随机噪声（噪声添加步数也随机）。</li>
<li>然后把文本、图片、噪声步数一同输入到模型当中。计算损失就是把预测的噪声和实际噪声算均方误差，后面就是基本流程了。</li>
</ul>
<h3 id="测试（生成）"><a href="#测试（生成）" class="headerlink" title="测试（生成）"></a>测试（生成）</h3><ul>
<li>训练好的模型可以根据噪声和文本生成图像了，这时候就不用输入原图了，直接随机初始化噪声图作为输入进行去噪：</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sample_cfg</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> noise_scheduler<span class="token punctuation">,</span> n_samples<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> text_embeddings<span class="token punctuation">,</span> image_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> guidance_scale<span class="token operator">=</span><span class="token number">3.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    从噪声开始，逐渐减小噪声，直到最终的图像。
    :param model: UNet模型
    :param noise_scheduler: 噪声调度器
    :param n_samples: 生成的样本数量
    :param in_channels: 输入图像的通道数
    :param text_embeddings: 文本嵌入
    :param image_size: 图像的大小
    :param guidance_scale: 用于加权噪声预测的比例
    :return: 生成的图像
    """</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    device <span class="token operator">=</span> next<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device

    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_samples<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> image_size<span class="token punctuation">,</span> image_size<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 随机初始化噪声图像</span>
    null_embeddings <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>text_embeddings<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 用于无条件生成</span>

    <span class="token comment" spellcheck="true"># 逐步去噪</span>
    <span class="token keyword">for</span> t <span class="token keyword">in</span> reversed<span class="token punctuation">(</span>range<span class="token punctuation">(</span>noise_scheduler<span class="token punctuation">.</span>num_timesteps<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        t_batch <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">(</span>n_samples<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> t<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span>

        noise_pred_uncond <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t_batch<span class="token punctuation">,</span> y<span class="token operator">=</span>null_embeddings<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 生成一个无条件的噪声预测</span>
        noise_pred_cond <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t_batch<span class="token punctuation">,</span> y<span class="token operator">=</span>text_embeddings<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 生成一个有条件的噪声预测</span>
        noise_pred <span class="token operator">=</span> noise_pred_uncond <span class="token operator">+</span> guidance_scale <span class="token operator">*</span> <span class="token punctuation">(</span>noise_pred_cond <span class="token operator">-</span> noise_pred_uncond<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># CFG：结果加权后的噪声预测</span>

        <span class="token comment" spellcheck="true"># 采样器的去噪过程</span>
        alpha_t <span class="token operator">=</span> noise_scheduler<span class="token punctuation">.</span>alphas<span class="token punctuation">[</span>t<span class="token punctuation">]</span>
        alpha_t_bar <span class="token operator">=</span> noise_scheduler<span class="token punctuation">.</span>alphas_cumprod<span class="token punctuation">[</span>t<span class="token punctuation">]</span>
        beta_t <span class="token operator">=</span> noise_scheduler<span class="token punctuation">.</span>betas<span class="token punctuation">[</span>t<span class="token punctuation">]</span>

        <span class="token keyword">if</span> t <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
            noise <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            noise <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 去噪公式</span>
        x <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>alpha_t<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> alpha_t<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> alpha_t_bar<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> noise_pred<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>beta_t<span class="token punctuation">)</span> <span class="token operator">*</span> noise

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> x
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>生成，还是要先对文本分词、clip编码后，再生成图像，进行保存：</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> save_checkpoint_interval <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        diffusion_model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            sample_text <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"a water type pokemon"</span><span class="token punctuation">,</span> <span class="token string">"a red pokemon with a red fire tail"</span><span class="token punctuation">]</span>
            text_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>sample_text<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>model_max_length<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
            text_embeddings <span class="token operator">=</span> text_encoder<span class="token punctuation">(</span>text_input<span class="token punctuation">.</span>input_ids<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>last_hidden_state
            sampled_images <span class="token operator">=</span> sample_cfg<span class="token punctuation">(</span>diffusion_model<span class="token punctuation">,</span> noise_scheduler<span class="token punctuation">,</span> len<span class="token punctuation">(</span>sample_text<span class="token punctuation">)</span><span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> text_embeddings<span class="token punctuation">,</span> image_size<span class="token operator">=</span>image_size<span class="token punctuation">,</span> guidance_scale<span class="token operator">=</span><span class="token number">3.0</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 保存生成的图像</span>
            <span class="token keyword">for</span> i<span class="token punctuation">,</span> img <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>sampled_images<span class="token punctuation">)</span><span class="token punctuation">:</span>
                img <span class="token operator">=</span> img <span class="token operator">*</span> <span class="token number">0.5</span> <span class="token operator">+</span> <span class="token number">0.5</span>  <span class="token comment" spellcheck="true"># Rescale to [0, 1]</span>
                img <span class="token operator">=</span> img<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
                img <span class="token operator">=</span> <span class="token punctuation">(</span>img <span class="token operator">*</span> <span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>
                img_pil <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
                img_pil<span class="token punctuation">.</span>save<span class="token punctuation">(</span>f<span class="token string">'diffusion_results/generated_image_epoch_{epoch+1}_sample_{i}.png'</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Stable-Diffusion"><a href="#Stable-Diffusion" class="headerlink" title="Stable Diffusion"></a>Stable Diffusion</h2><h3 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h3><ul>
<li>接下来就是完整的CLIP + UNet + VAE的SD结构了，模型结构就是把VAE和UNet组合：</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">StableDiffusion</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> latent_dim<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> image_size<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> diffusion_timesteps<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>StableDiffusion<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># VAE</span>
        self<span class="token punctuation">.</span>vae <span class="token operator">=</span> VAE<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>in_channels<span class="token punctuation">,</span> latent_dim<span class="token operator">=</span>latent_dim<span class="token punctuation">,</span> image_size<span class="token operator">=</span>image_size<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># Diffusion model (UNet)</span>
        self<span class="token punctuation">.</span>unet <span class="token operator">=</span> UNet_Transformer<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>latent_dim<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># Noise scheduler</span>
        self<span class="token punctuation">.</span>noise_scheduler <span class="token operator">=</span> NoiseScheduler<span class="token punctuation">(</span>num_timesteps<span class="token operator">=</span>diffusion_timesteps<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>vae<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>vae<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">diffuse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> latents<span class="token punctuation">,</span> t<span class="token punctuation">,</span> context<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>unet<span class="token punctuation">(</span>latents<span class="token punctuation">,</span> t<span class="token punctuation">,</span> context<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> latents<span class="token punctuation">,</span> t<span class="token punctuation">,</span> context<span class="token punctuation">)</span><span class="token punctuation">:</span>
        noise_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>diffuse<span class="token punctuation">(</span>latents<span class="token punctuation">,</span> t<span class="token punctuation">,</span> context<span class="token punctuation">)</span>
        <span class="token keyword">return</span> noise_pred
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>这里VAE已经是预训练好的，所以训练时只要更新UNet即可。</li>
</ul>
<h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><pre class="line-numbers language-python"><code class="language-python">    <span class="token comment" spellcheck="true"># 训练模型</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
        latents <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">"latents"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        text <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span>

        <span class="token comment" spellcheck="true"># 添加噪声</span>
        timesteps <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_timesteps<span class="token punctuation">,</span> <span class="token punctuation">(</span>latents<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>
        noisy_latents<span class="token punctuation">,</span> noise <span class="token operator">=</span> model<span class="token punctuation">.</span>noise_scheduler<span class="token punctuation">.</span>add_noise<span class="token punctuation">(</span>latents<span class="token punctuation">,</span> timesteps<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 使用 CLIP 模型编码文本</span>
        text_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>model_max_length<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
        text_embeddings <span class="token operator">=</span> text_encoder<span class="token punctuation">(</span>text_inputs<span class="token punctuation">.</span>input_ids<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>last_hidden_state

        <span class="token comment" spellcheck="true"># 预测噪声</span>
        noise_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>noisy_latents<span class="token punctuation">,</span> timesteps<span class="token punctuation">,</span> text_embeddings<span class="token punctuation">)</span>
        mse_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>noise_pred<span class="token punctuation">,</span> noise<span class="token punctuation">)</span>
        div_loss <span class="token operator">=</span> diversity_loss<span class="token punctuation">(</span>noisy_latents<span class="token punctuation">,</span> use_cosine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 计算去噪后的潜在表示</span>
        alpha_t <span class="token operator">=</span> model<span class="token punctuation">.</span>noise_scheduler<span class="token punctuation">.</span>alphas<span class="token punctuation">[</span>timesteps<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> None<span class="token punctuation">,</span> None<span class="token punctuation">,</span> None<span class="token punctuation">]</span>
        sqrt_alpha_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>alpha_t<span class="token punctuation">)</span>
        sqrt_one_minus_alpha_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> alpha_t<span class="token punctuation">)</span>
        predicted_latents <span class="token operator">=</span> <span class="token punctuation">(</span>noisy_latents <span class="token operator">-</span> sqrt_one_minus_alpha_t <span class="token operator">*</span> noise_pred<span class="token punctuation">)</span> <span class="token operator">/</span> sqrt_alpha_t
        cons_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>predicted_latents<span class="token punctuation">,</span> latents<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 组合损失</span>
        total_loss <span class="token operator">=</span> mse_loss <span class="token operator">+</span> diversity_weight <span class="token operator">*</span> div_loss <span class="token operator">+</span> cons_loss <span class="token operator">*</span> current_lambda_cons
        epoch_loss <span class="token operator">+=</span> total_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        num_batches <span class="token operator">+=</span> <span class="token number">1</span>

        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        total_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_norm<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># OneCycleLR 学习率调度器</span>

        <span class="token comment" spellcheck="true"># 动态调整多样性损失的权重</span>
        <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            diversity_weight <span class="token operator">=</span> min<span class="token punctuation">(</span>diversity_weight <span class="token operator">*</span> <span class="token number">1.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 逐渐增加权重，但设置上限</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>训练流程（部分代码）和之前DDPM部分区别不大，这里数据集的<code>train_dataloader</code>里的数据已经被VAE下采样过了，所以直接配合嵌入好的文本输入模型，UNet会利用网络和公式预测噪声用于损失计算。</li>
<li>损失分为<strong>噪声损失</strong>、<strong>多样性损失</strong>和<strong>去噪后特征的损失</strong>。</li>
</ul>
<h3 id="测试（生成）-1"><a href="#测试（生成）-1" class="headerlink" title="测试（生成）"></a>测试（生成）</h3><ul>
<li>代码和之前一样，就不展示了，就多了一个，在UNet输出子空间表示时，用VAE解码成正常图片的信息：<code>sampled_images = model.decode(sampled_latents)</code></li>
</ul>
<h1 id="🔥总结"><a href="#🔥总结" class="headerlink" title="🔥总结"></a>🔥总结</h1><ul>
<li>本文记录了stable diffusion（SD）的框架及其组件细节。并通过理解开源代码了解了网络结构搭建（VAE、UNet、SD）、训练过程（CLIP+UNet、SD）以及生成过程（CLIP+UNet、SD）。</li>
<li>总的来说，SD的网络结构结合了CNN和transformer，本质是一个视觉模型。而模型生成过程就是：CLIP嵌入文本（可选）、生成噪声图像、VAE编码图文、UNet预测噪声、VAE解码出图。而训练不需要生成的图，可以去掉最后一步。模型当中的组件也都是可以换成更优秀的结构。</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://legendleochen.top/2025/03/25/%E8%A7%86%E8%A7%89%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AIGC/" rel="tag">AIGC</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/2025/03/08/leetcode%E7%AE%97%E6%B3%95%E9%A2%98hot100%EF%BC%882%EF%BC%89/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">leetcode算法题hot100（2）</div>
      </a>
    
  </nav>

  
   
  
    
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2023-2025
        <i class="ri-heart-fill heart_icon"></i> LegendLeo Chen
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/mylogo.png" alt="LegendLeo Chen 的空间"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">🚀主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">💾归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">🧭分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">🏷️标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">🛸关于</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/analytics">📊统计</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=1491212&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
  <!-- 背景气泡 -->
  <!--
  <div class="balls-container">
    <div class="balls-particles">
      <span style="--i:11;"></span>
      <span style="--i:12;"></span>
      <span style="--i:24;"></span>
      <span style="--i:10;"></span>
      <span style="--i:14;"></span>
      <span style="--i:23;"></span>
      <span style="--i:18;"></span>
      <span style="--i:16;"></span>
      <span style="--i:19;"></span>
      <span style="--i:20;"></span>
      <span style="--i:22;"></span>
      <span style="--i:25;"></span>
      <span style="--i:18;"></span>
      <span style="--i:21;"></span>
      <span style="--i:13;"></span>
      <span style="--i:15;"></span>
      <span style="--i:26;"></span>
      <span style="--i:17;"></span>
      <span style="--i:13;"></span>
      <span style="--i:26;"></span>
      <span style="--i:28;"></span>
      <span style="--i:11;"></span>
      <span style="--i:12;"></span>
      <span style="--i:24;"></span>
      <span style="--i:10;"></span>
      <span style="--i:14;"></span>
      <span style="--i:23;"></span>
      <span style="--i:18;"></span>
      <span style="--i:16;"></span>
      <span style="--i:19;"></span>
      <span style="--i:20;"></span>
      <span style="--i:22;"></span>
      <span style="--i:25;"></span>
      <span style="--i:18;"></span>
      <span style="--i:21;"></span>
      <span style="--i:13;"></span>
      <span style="--i:15;"></span>
      <span style="--i:26;"></span>
      <span style="--i:17;"></span>
      <span style="--i:13;"></span>
      <span style="--i:26;"></span>
      <span style="--i:28;"></span>
    </div>
  </div>
  <style>
    *
    {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    .balls-container
    { 
      position: fixed;
      top: 0px;
      left: 0px;
      width: 100%;
      height: 100vh;
      overflow: hidden;
      opacity: 0.3;
    }
    
    .balls-particles
    {
      position: fixed;
      display: flex;
      z-index: 3;
      padding: 0 20px;
    }
    
    .balls-particles span
    {
      position: relative;
      bottom: 30px;
      width: 30px;
      height: 30px;
      background-color: #4fc3dc;
      box-shadow: 0 0 0 10px #4fc3dc44,
      0 0 50px #4fc3dc,
      -100px 0 #4fc3dc99,
      100px 0 #ff2d7599;
      margin: 0 4px;
      border-radius: 50%;
      animation: animate 15s ease infinite;
      animation-delay: calc(125s / var(--i));
      transform: translateY(120vh);
    }
    .balls-particles span:nth-child(even) {
      background-color: #ff2d75;
      box-shadow: 0 0 0 10px #ff267544,
      0 0 50px #ff2d75,
      -100px 0 #4fc3dc99,
      100px 0 #4fc3dc99;
      ;
    }
    
    @keyframes animate {
      0%
      {
        transform: translateY(120vh) scale(0) rotate(0deg);
      }
      20%
      {
        transform: translateY(100vh) scale(1) rotate(0deg);
      }
      100%
      {
        transform: translateY(-50vh) scale(0.5) rotate(360deg);
      }
    }
  </style> -->
  <!-- 地月系统 -->
  <!-- <div class="earth-container" >
    <div class="planet"></div>
    <div class="satellite"></div>
   </div>
   <style>
    *{
      padding: 0;
      margin: 0;
      }
      .earth-container {
        width: 36.25em;
        height: 36.25em;
        position: absolute;
        top:5%;
        left: 93%;
        transform: translate(-50%, -50%);
        opacity: 0.3;
      }
      
      .planet{
        width: 15.62*3em;
        height: 15.62*3em;
        background-color: #02c0f5;
        border-radius: 50%;
        position: absolute;
        margin: auto;
        top:0;
        right: 0;
        bottom: 0;
        left: 0;
        z-index: 1;
      }
      
      .planet::before{
        content: '';
        width: 4em;
        height: 4em;
        background-color: #008fd6;
        position: absolute;
        top:10em;
        left: 8em;
        border-radius: 50%; 
        box-shadow: 15em 15em 0 2em #00d68b, 5em 8em 0 3em #10ade1;
      }
      
      .satellite{
        width: 5em;
        height: 5em;
        background-color: #dee517;
        border-radius: 50%;
        position: relative;
        left: -5em;
        bottom: -30em;
        animation: spin 5s infinite;
        z-index: 1;
      }
      
      @keyframes spin {
        49%{
          z-index: 1;
        }
        50%{
          bottom: 3em;
          left: 35em;
          z-index: -1;
        }
        100%{
          z-index: -1;
        }
      }
    </style> -->
<!-- 三角彩带背景 -->
  <canvas id="evanyou-canvas" style="opacity: 0.3; position: fixed; top: 0px; left: 0px; z-index: -1; width: 100%; height: 100%; pointer-events: none;"></canvas>
  <script src="https://cdn.jsdelivr.net/gh/XXXZhy/Blog_Image/js/evanyou_canvas.js"></script>
</body>

</html>