<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta name="description" content="一个秘密空间" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>基于LangChain的Agent上手 |  LegendLeo Chen 的空间</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/mylogo.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
<!-- 封面标闪烁 -->
<link rel="stylesheet" href="/css/zhyBlogTitle.css">
<script src="https://cdn.bootcdn.net/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- jquery，懒加载、统计、说说需要的jquery -->
<script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-基于LangChain的Agent上手"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  基于LangChain的Agent上手
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/02/24/%E5%9F%BA%E4%BA%8ELangChain%E7%9A%84Agent%E4%B8%8A%E6%89%8B/" class="article-date">
  <time datetime="2025-02-24T12:04:45.000Z" itemprop="datePublished">2025-02-24</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">4.1k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">16 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>本次借助LangChain框架，实现一个基于LLM的Agent，Agent的核心逻辑是让LLM根据动态变化的环境信息，选择执行具体的行动，并反过来影响环境，通过多轮迭代重复执行上述步骤，直到完成目标。总结就是：感知(P) — 规划(P) — 行动(A)。<span id="more"></span></p>
<h1 id="🔥Agent框架"><a href="#🔥Agent框架" class="headerlink" title="🔥Agent框架"></a>🔥Agent框架</h1><p><img src="/2025/02/24/%E5%9F%BA%E4%BA%8ELangChain%E7%9A%84Agent%E4%B8%8A%E6%89%8B/Agent%E6%A1%86%E6%9E%B6.png" alt="Agent框架"></p>
<ul>
<li>如上，Agent在工程实现上可以拆分出四大块核心模块：推理（Planning）、记忆（Memory）、工具（Tools）、行动（Action）。记忆是推理的材料，工具是行动的必需，而推理和行动是相辅相成的。</li>
</ul>
<p><img src="/2025/02/24/%E5%9F%BA%E4%BA%8ELangChain%E7%9A%84Agent%E4%B8%8A%E6%89%8B/ReAct%E6%A1%86%E6%9E%B6.png" alt="ReAct框架"></p>
<ul>
<li>上图就是Agent的<strong>主流框架ReAct</strong>，其核心就是结合了思维链和WebGPT的思想，让模型能够<strong>思考</strong>（也就是规划、推理）的同时借助<strong>工具</strong>采取<strong>行动</strong>，获得<strong>观察</strong>结果（Observation），再反过来辅助思考，如此往复完成任务。</li>
<li>总的来说：单智能体agent &#x3D; 大语言模型（LLM） + 观察（obs） + 思考（thought） + 行动（act） + 记忆（mem）。</li>
</ul>
<h1 id="🔥模型下载"><a href="#🔥模型下载" class="headerlink" title="🔥模型下载"></a>🔥模型下载</h1><p><a target="_blank" rel="noopener" href="https://huggingface.co/">huggingface</a>上选择模型，这里以Qwen&#x2F;Qwen2.5-3B-Instruct为例。</p>
<ul>
<li><p>如下图可以直接在界面中的files and versions中下载模型，把所有文件下载进一个文件夹即可。<br><img src="/2025/02/24/%E5%9F%BA%E4%BA%8ELangChain%E7%9A%84Agent%E4%B8%8A%E6%89%8B/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9.jpg" alt="huggingface模型界面"></p>
</li>
<li><p>也可以通过命令行一次性下载，先通过<code>pip install -U huggingface_hub</code>安装命令行工具，在cmd中通过以下指令登录huggingface并下载模型：</p>
</li>
</ul>
<pre class="line-numbers language-bash"><code class="language-bash">huggingface-cli login
huggingface-cli download --resume-download Qwen/Qwen2.5-3B-Instruct --local-dir D://你的存储路径
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<ul>
<li>首先第一句指令登录，会让你输入huggingface个人账户界面的access tokens的令牌，输入后即可通过第二条指令下载模型到指定位置。</li>
</ul>
<h1 id="🔥Chain链"><a href="#🔥Chain链" class="headerlink" title="🔥Chain链"></a>🔥Chain链</h1><ul>
<li>首先，先实现链。LLMChain是一个在语言模型周围添加功能的简单链，它被广泛地应用于LangChain中，是一个很基本的组件。LLMChain由一个PromptTemplate和一个语言模型（LLM或聊天模型）组成，也就是借助提示词来格式化用户输入，引导模型思考以生成符合要求的结果。</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> langchain <span class="token keyword">import</span> PromptTemplate<span class="token punctuation">,</span> LLMChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms <span class="token keyword">import</span> HuggingFacePipeline
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM<span class="token punctuation">,</span> pipeline<span class="token punctuation">,</span> AutoModelForSeq2SeqLM

model_id <span class="token operator">=</span> <span class="token string">'模型文件夹的路径'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>

pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>
    <span class="token string">"text2text-generation"</span><span class="token punctuation">,</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    max_length<span class="token operator">=</span><span class="token number">100</span>
<span class="token punctuation">)</span>

local_llm <span class="token operator">=</span> HuggingFacePipeline<span class="token punctuation">(</span>pipeline<span class="token operator">=</span>pipe<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>local_llm<span class="token punctuation">(</span><span class="token string">'法国首都在哪？'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""Question: {question} Answer: 让我们一步步思考"""</span>
prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>template<span class="token operator">=</span>template<span class="token punctuation">,</span> input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

llm_chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>prompt<span class="token operator">=</span>prompt<span class="token punctuation">,</span> llm<span class="token operator">=</span>local_llm<span class="token punctuation">)</span>
question <span class="token operator">=</span> <span class="token string">"英国首都在哪？"</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>llm_chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span>question<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>代码如上，实现起来很简单，就是加载本地模型，构建pipeline以输出文本，设置好提示词模板，就可以构建LLMChain，让模型回答问题。</li>
</ul>
<pre class="line-numbers language-txt"><code class="language-txt">法国首都在哪?_---
A.巴黎
B.马赛
C.里昂
D.南特
答案:A
在电气设备上工作，保证安全的组织措施有:----
A.工作票制度
B.工作许可制度
C.工作监护制度
D.工作间断、转移和终结制度
答案:ABCD
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>可以看到第一次提问，没有LLMChain的提示的情况下，这个小模型似乎在复现自己的数据集一样，给自己做选择题，甚至还额外出了一题无关的内容。这显然是不符合的。</li>
</ul>
<pre class="line-numbers language-txt"><code class="language-txt">Question:英国首都在哪?Answer:让我们一步步思考这个问题:
1、首先，我们需要明确什么是“英国首都”。通常情况下，“英国"指的是全英国，包括英格兰、苏格兰、威尔士和北爱尔兰。而“英国首都是指的全英国的政治中心。
2、英国的政治中心位于英格兰境内，因此我们可以直接忽略苏格兰、威尔士和北爱尔兰。
3、英国的政治中心是伦敦。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>第二次提问，LLMChain的提示词已经生效了，模型根据提示词，至少能回答正确了，对于小模型，提示词就有很不错的作用。</li>
</ul>
<h1 id="🔥Agent"><a href="#🔥Agent" class="headerlink" title="🔥Agent"></a>🔥Agent</h1><ul>
<li>接下来就是Agent的实现了。</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>agents <span class="token keyword">import</span> initialize_agent<span class="token punctuation">,</span> Tool<span class="token punctuation">,</span> AgentType
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMChain
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> HuggingFacePipeline
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>agent_toolkits<span class="token punctuation">.</span>load_tools <span class="token keyword">import</span> load_tools
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM<span class="token punctuation">,</span> pipeline

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"HF_HUB_DISABLE_SYMLINKS_WARNING"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"true"</span>

<span class="token comment" spellcheck="true"># 1. 加载模型和分词器</span>
model_id <span class="token operator">=</span> <span class="token string">'模型文件夹的路径'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 2. 创建文本生成管道</span>
pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 3. 封装为 langchain 的语言模型</span>
llm <span class="token operator">=</span> HuggingFacePipeline<span class="token punctuation">(</span>pipeline<span class="token operator">=</span>pipe<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 4. 定义一个简单的工具链</span>
<span class="token keyword">def</span> <span class="token function">answer_question</span><span class="token punctuation">(</span>question<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> str<span class="token punctuation">:</span>
    prompt_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
        template<span class="token operator">=</span><span class="token string">"Question: {question}\nAnswer: "</span><span class="token punctuation">,</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>
    chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>prompt<span class="token operator">=</span>prompt_template<span class="token punctuation">,</span> llm<span class="token operator">=</span>llm<span class="token punctuation">)</span>
    <span class="token keyword">return</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>question<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 5. 将工具注册到 Agent</span>
tools <span class="token operator">=</span> <span class="token punctuation">[</span>
    Tool<span class="token punctuation">(</span>
        name<span class="token operator">=</span><span class="token string">"Answer Question"</span><span class="token punctuation">,</span>
        func<span class="token operator">=</span>answer_question<span class="token punctuation">,</span>
        description<span class="token operator">=</span><span class="token string">"Use this tool to answer questions."</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># tools = load_tools(['wikipedia'])</span>

<span class="token comment" spellcheck="true"># 6. 初始化 Agent</span>
agent <span class="token operator">=</span> initialize_agent<span class="token punctuation">(</span>
    tools<span class="token operator">=</span>tools<span class="token punctuation">,</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    agent<span class="token operator">=</span>AgentType<span class="token punctuation">.</span>ZERO_SHOT_REACT_DESCRIPTION<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    handle_parsing_errors<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 7. 使用 Agent 运行任务</span>
question <span class="token operator">=</span> <span class="token string">"美国现任总统是谁，哪一年上任？"</span>
result <span class="token operator">=</span> agent<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>question<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Agent's response:"</span><span class="token punctuation">,</span> result<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>主要流程就是加载模型，构建pipeline，定义工具，构建agent，然后运行。</li>
<li>这里示范了如何<strong>自定义一个工具</strong>，它调用的是answer_question函数，功能就是构建一个LLMChain进行调用，也就是让模型“问自己”。而实际上有很多<strong>现有的工具</strong>，<code>tools = load_tools([&#39;wikipedia&#39;])</code>这句就是调用了wiki进行搜索，然后返回结果。接下来的结果展示的就是该工具的效果。</li>
<li>agent的初始化就是<strong>选择大模型、配置好大模型可使用的工具、确定agent类型</strong>，类型也就是之前提到的ReAct之类的逻辑框架，让llm根据一定的顺序进行思考、动作、观察等操作，也会有专门的提示词进行引导。</li>
</ul>
<p>结果如下：</p>
<pre class="line-numbers language-txt"><code class="language-txt">Answer the following questions as best you can. You have access to the following tools:

wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [wikipedia]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: 美国现任总统是谁，哪一年上任？
Thought: 我需要查询关于美国现任总统的信息。
Action: wikipedia
Action Input: 美国现任总统
Observation: 美国现任总统是乔·拜登（Joe Biden），他于2021年1月20日就职。

Thought: 我现在知道了答案。
Final Answer: 美国现任总统是乔·拜登（Joe Biden），他于2021年1月20日上任。 

注：以上信息基于2023年4月的最新情况，实际日期可能会有所变化。
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
Observation: Invalid or incomplete response
Thought:
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>前面是一堆英文的prompt，也就是这个类型的agent预设的提示词，告诉模型应该按Question、Thought、Action、Action Input、Observation、……、Thought、Final Answer的顺序进行思考、动作、观察等一系列操作，最后给出答案。</li>
<li>模型紧接着就按该顺序完成了回答，期间确实调用了Wikipedia进行搜索，还注明了数据的时间。</li>
<li>值得注意的是，最后得到了结果，但是有报错，我认为是小模型不够智能，在给完了答案后依然没有停下输出，但是Agent的整个功能还是正确实现了。</li>
</ul>
<h1 id="🔥手动实现"><a href="#🔥手动实现" class="headerlink" title="🔥手动实现"></a>🔥手动实现</h1><p>因为上面看到agent很不稳定，但是又不好改底层，所以我们可以手动模拟Agent的部分功能。这节就实现让大模型接入Agent，可以使用RAG作为工具。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token comment" spellcheck="true"># os.environ['CUDA_VISIBLE_DEVICES'] = '1, 2'       # 限定GPU</span>
<span class="token keyword">import</span> json
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM<span class="token punctuation">,</span> pipeline
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> HuggingFacePipeline
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMChain
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> TextLoader
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> CharacterTextSplitter
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> RetrievalQA
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> HuggingFaceEmbeddings
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> FAISS
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>agents <span class="token keyword">import</span> Tool
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>utilities <span class="token keyword">import</span> WikipediaAPIWrapper
<span class="token keyword">import</span> regex <span class="token keyword">as</span> re

<span class="token comment" spellcheck="true"># ======================</span>
<span class="token comment" spellcheck="true"># 模型加载</span>
<span class="token comment" spellcheck="true"># ======================</span>
model_path <span class="token operator">=</span> <span class="token string">"./model/DeepSeek-R1-Distill-Qwen-7B"</span>  <span class="token comment" spellcheck="true"># 替换为你自己的路径</span>

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> device_map<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> device_map<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">)</span>
hf_pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">)</span>

llm <span class="token operator">=</span> HuggingFacePipeline<span class="token punctuation">(</span>pipeline<span class="token operator">=</span>hf_pipe<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>这里我们用DeepseekR1蒸馏的Qwen-7B模型，它参量小的同时也有R1的思考能力。</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ======================</span>
<span class="token comment" spellcheck="true"># 向量数据库准备（RAG）</span>
<span class="token comment" spellcheck="true"># ======================</span>
<span class="token comment" spellcheck="true"># 1. 加载文档</span>
loader <span class="token operator">=</span> TextLoader<span class="token punctuation">(</span><span class="token string">"./docs/example.txt"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span>
docs <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 2. 切分文档</span>
text_splitter <span class="token operator">=</span> CharacterTextSplitter<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
splits <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 3. 嵌入模型</span>
embedding_model <span class="token operator">=</span> HuggingFaceEmbeddings<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"./model/Qwen3-Embedding-0.6B"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 4. 创建向量数据库</span>
vectordb <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>splits<span class="token punctuation">,</span> embedding_model<span class="token punctuation">)</span>

rag_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    <span class="token string">"1、你绝不能做多余回答，我不可以编造无关内容！\n2、你绝不能做过度思考！\n3、你说中文，用400字以内的话总结以下内容即可：\n\n✅{context}\n\n✅"</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 5. 构建 RetrievalQA 链</span>
rag_chain <span class="token operator">=</span> RetrievalQA<span class="token punctuation">.</span>from_chain_type<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    retriever<span class="token operator">=</span>vectordb<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    chain_type<span class="token operator">=</span><span class="token string">"stuff"</span><span class="token punctuation">,</span>
    chain_type_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"prompt"</span><span class="token punctuation">:</span> rag_prompt<span class="token punctuation">}</span>
<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>然后是RAG的实现，加载一个txt文档，然后切分后使用一个嵌入模型（也是huggingface找就行了）把文本块嵌入成向量，用FAISS库搭建向量库。</li>
<li>接着用RetrievalQA链构建检索结构，提供大模型、向量库、prompt即可，这里为了让模型输出稳定，我的prompt告诉它不要说废话，并且限制字数。</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ======================</span>
<span class="token comment" spellcheck="true"># 工具构建</span>
<span class="token comment" spellcheck="true"># ======================</span>
<span class="token keyword">def</span> <span class="token function">rag_qa_tool</span><span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> rag_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>query<span class="token punctuation">)</span>

wiki <span class="token operator">=</span> WikipediaAPIWrapper<span class="token punctuation">(</span><span class="token punctuation">)</span>

tools <span class="token operator">=</span> <span class="token punctuation">[</span>
    Tool<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"WebSearch"</span><span class="token punctuation">,</span> func<span class="token operator">=</span>wiki<span class="token punctuation">.</span>run<span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"输入搜索关键词，使用网页搜索查找实时信息"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Tool<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"MyRAGTool"</span><span class="token punctuation">,</span> func<span class="token operator">=</span>rag_qa_tool<span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"输入文本，使用RAG做检索"</span><span class="token punctuation">,</span> return_direct<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
tool_description_str <span class="token operator">=</span> <span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>f<span class="token string">"{i+1}、{tool.name}：{tool.description}；"</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> tool <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>tools<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>然后把RAG封装成工具，<code>tool_description_str</code>是生成工具的描述，作为prompt输入大模型告诉它可以用什么。</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ======================</span>
<span class="token comment" spellcheck="true"># 对话</span>
<span class="token comment" spellcheck="true"># ======================</span>
prompt_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"description"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span>f<span class="token triple-quoted-string string">"""
    a、你只能回答一个json格式数据，在100字以内。
    包含属性："action", "action_input", "message"。
    其中action是可以调用的工具函数，action_input是工具的输入参数（如果工具没有输入就为None），message是你要说的话或者思考内容。
    
    b、只可以调用的工具如下:
    {tool_description_str}
    
    现在回答我的命令：{{description}}
"""</span>
<span class="token punctuation">)</span>
chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>prompt_template<span class="token punctuation">)</span>

user_input <span class="token operator">=</span> <span class="token string">"调用我的工具总结我的文档内容，只回答一个json就行了"</span>
response <span class="token operator">=</span> chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"description"</span><span class="token punctuation">:</span> user_input<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"✅ 模型原始输出："</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>然后就是对话了，prompt设计好，告诉模型输出json，构建Chain后即可输入指令<code>user_input</code>。</li>
<li>注意，这里用f输入格式化文本，才能把<code>tool_description_str</code>传进来，而<code>input_variables</code>对应的变量<code>description</code>应该多套一层花括号。</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ======================</span>
<span class="token comment" spellcheck="true"># 解析JSON</span>
<span class="token comment" spellcheck="true"># ======================</span>
<span class="token keyword">def</span> <span class="token function">extract_json_from_response</span><span class="token punctuation">(</span>response<span class="token punctuation">:</span> str<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 找到 ```json 之后的部分</span>
    json_candidates <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>r<span class="token string">'\{(?:[^{}]|(?R))*\}'</span><span class="token punctuation">,</span> response<span class="token punctuation">)</span>

    valid_jsons <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> candidate <span class="token keyword">in</span> json_candidates<span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            obj <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>candidate<span class="token punctuation">)</span>
            valid_jsons<span class="token punctuation">.</span>append<span class="token punctuation">(</span>obj<span class="token punctuation">)</span>
        <span class="token keyword">except</span> json<span class="token punctuation">.</span>JSONDecodeError<span class="token punctuation">:</span>
            <span class="token keyword">continue</span>
    <span class="token keyword">return</span> valid_jsons

parsed_data <span class="token operator">=</span> extract_json_from_response<span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token keyword">if</span> parsed_data<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n✅ 成功解析为 Python 对象："</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>parsed_data<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># ======================</span>
<span class="token comment" spellcheck="true"># 调用工具</span>
<span class="token comment" spellcheck="true"># ======================</span>
tool <span class="token operator">=</span> next<span class="token punctuation">(</span>tool <span class="token keyword">for</span> tool <span class="token keyword">in</span> tools <span class="token keyword">if</span> tool<span class="token punctuation">.</span>name <span class="token operator">==</span> parsed_data<span class="token punctuation">[</span><span class="token string">'action'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"\n✅ 调用工具{tool.name} 收到输入: {parsed_data['action']}"</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> tool<span class="token punctuation">.</span>func<span class="token punctuation">(</span>parsed_data<span class="token punctuation">[</span><span class="token string">'action_input'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token string">'result'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>接着我们用正则表达式解析大模型生成的JSON，得到tool和它的输入参数，就可以用<code>tool.func</code>调用该工具函数了。</li>
</ul>
<p>以下是输出：</p>
<pre class="line-numbers language-txt"><code class="language-txt">✅ 模型原始输出：

    a、你只能回答一个json格式数据，在100字以内。
    包含属性："action", "action_input", "message"。
    其中action是可以调用的工具函数，action_input是工具的输入参数（如果工具没有输入就为None），message是你要说的话或者思考内容。
    
    b、只可以调用的工具如下:
    1、WebSearch：输入搜索关键词，使用网页搜索查找实时信息；
2、MyRAGTool：输入文本，使用RAG做检索；
    
    现在回答我的命令：调用我的工具总结我的文档内容，只回答一个json就行了
    文档内容：您需要总结这个文档内容

    要求：
    1. 使用指定的工具；
    2. 工具的输入参数要正确；
    3. 输出结果必须是JSON格式；
    4. 保持思考过程口语化，不要超过100字。
    请开始思考并回答问题。

</think>

{
  "action": "MyRAGTool",
  "action_input": "文档内容",
  "message": "调用MyRAGTool进行总结"
}

✅ 成功解析为 Python 对象：
{'action': 'MyRAGTool', 'action_input': '文档内容', 'message': '调用MyRAGTool进行总结'}

✅ 调用工具MyRAGTool 收到输入: MyRAGTool
1、你绝不能做多余回答，我不可以编造无关内容！
2、你绝不能做过度思考！
3、你说中文，用400字以内的话总结以下内容即可：

✅将 Q 看成第一种模态信息，KV 看成第二种模态信息，就可以实现使用 Q 查询 KV 中与之关联的那些是重要、有用的，也就实现了不同模态之间的信息交互。
……(这一段是检索到的文本，太长就省略了)
    Q (Query)：查询（向量），代表当前需要关注的信息；
    K (Key)：键（向量），代表所有可被关注的信息的索引；
    V (Value)：值（向量），代表所有可被关注的信息的具体内容。

✅ 模型输出：将 Q 看成第一种模态信息，KV 看成第二种模态信息，就可以实现使用 Q 查询 KV 中与之关联的那些是重要、有用的，也就实现了不同模态之间的信息交互。

优点：更细节的关注，能自动学习一些内容。

缺点：attention 的计算会对二维空间表示信息丢失，对图像的空间表示不是很理想（觉得这里是图像数据与文本数据本质的区别，CNN 与 transformer 的区别）

……（大段思考内容省略）
现在我需要根据上面的信息，用不超过400字的中文来总结这些内容。

接下来，我需要将这些内容整合成一个连贯的总结，控制在400字以内。确保涵盖每种方法的基本思想、代表算法、优缺点，以及常见任务，同时语言要简洁明了。

最后，检查一下是否符合用户的所有要求：避免多余回答，不编造无关内容，用中文，400字以内。确保内容准确，涵盖所有要点。
</think>

多模态对齐方法主要包括对比学习、交叉注意力和扩散模型。对比学习通过Contrastive Loss将不同模态的数据拉近到同一表示空间，代表算法是CLIP，优点是简单直接，但依赖大量数据，细节描述有限。交叉注意力利用Q和KV分别代表不同模态，通过注意力机制进行信息交互，优点是更细致关注相关信息，缺点是对二维空间表示有限，适合文本和图像对齐。扩散模型通过逐步去噪生成目标数据，引入其他模态作为条件，适用于生成任务如文本生成图像，优点是数据需求大但能处理细节，缺点是空间表示不如CNN和Transformer。三种方法各有优劣，适用于不同任务。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>可以看到首先，打印了<strong>大模型在LLMChain的输出</strong>，里面包含了输入的prompt、思考部分和最终输出，确实是一个json，它成功调用了RAG的工具；</li>
<li>然后<strong>JSON被我们的程序解析</strong>，<strong>tool被调用</strong>，RAG里面给大模型的prompt打印了出来；</li>
<li>然后是<strong>检索到的文本块</strong>，太长我就省略了，接着是<strong>RAG中大模型的输出</strong>，包括了大段的思考内容，以及最后的总结。</li>
<li>可以看到大模型在我们手动搭建的Agent下，成功借助RAG这个tool实现了对文档的检索和总结，两次的prompt设计很重要，这能有效提升输出的质量。</li>
<li>当然，这不是完整的agent实现，它相当于只做了一次Thought&#x2F;Action&#x2F;Action Input&#x2F;Observation的流程，但是足够清楚，也确实比上一节的效果更稳定。</li>
</ul>
<h1 id="🔥总结"><a href="#🔥总结" class="headerlink" title="🔥总结"></a>🔥总结</h1><ul>
<li>Agent是围绕大模型构建的一个框架，它提供了一种更合理高效的方式来使用大模型，让大模型用有除了自身智能以外的各种工具，并且可以按照一定的逻辑框架进行思考、动作、观察，让大模型不在是封闭的只能回答问题的单一个体，而是能够独立完成任务的代理。</li>
<li>使用LangChain可以轻松实现Agent的构建并实现其功能，并且可以很方便的定制各种工具，定制各种逻辑框架，让大模型能够满足不同场景用户的需求。</li>
<li>这次探索只是LangChain框架、Agent的冰山一角，但是对初步理解Agent有很大的帮助。</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://legendleochen.top/2025/02/24/%E5%9F%BA%E4%BA%8ELangChain%E7%9A%84Agent%E4%B8%8A%E6%89%8B/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Agent/" rel="tag">Agent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2025/03/05/leetcode%E7%AE%97%E6%B3%95%E9%A2%98hot100%EF%BC%881%EF%BC%89/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            leetcode算法题hot100（1）
          
        </div>
      </a>
    
    
      <a href="/2025/02/17/%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">主流大模型技术笔记</div>
      </a>
    
  </nav>

  
   
  
    
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2023-2025
        <i class="ri-heart-fill heart_icon"></i> LegendLeo Chen
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/mylogo.png" alt="LegendLeo Chen 的空间"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">🚀主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">💾归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">🧭分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">🏷️标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">🛸关于</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/analytics">📊统计</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=1491212&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
  <!-- 背景气泡 -->
  <!--
  <div class="balls-container">
    <div class="balls-particles">
      <span style="--i:11;"></span>
      <span style="--i:12;"></span>
      <span style="--i:24;"></span>
      <span style="--i:10;"></span>
      <span style="--i:14;"></span>
      <span style="--i:23;"></span>
      <span style="--i:18;"></span>
      <span style="--i:16;"></span>
      <span style="--i:19;"></span>
      <span style="--i:20;"></span>
      <span style="--i:22;"></span>
      <span style="--i:25;"></span>
      <span style="--i:18;"></span>
      <span style="--i:21;"></span>
      <span style="--i:13;"></span>
      <span style="--i:15;"></span>
      <span style="--i:26;"></span>
      <span style="--i:17;"></span>
      <span style="--i:13;"></span>
      <span style="--i:26;"></span>
      <span style="--i:28;"></span>
      <span style="--i:11;"></span>
      <span style="--i:12;"></span>
      <span style="--i:24;"></span>
      <span style="--i:10;"></span>
      <span style="--i:14;"></span>
      <span style="--i:23;"></span>
      <span style="--i:18;"></span>
      <span style="--i:16;"></span>
      <span style="--i:19;"></span>
      <span style="--i:20;"></span>
      <span style="--i:22;"></span>
      <span style="--i:25;"></span>
      <span style="--i:18;"></span>
      <span style="--i:21;"></span>
      <span style="--i:13;"></span>
      <span style="--i:15;"></span>
      <span style="--i:26;"></span>
      <span style="--i:17;"></span>
      <span style="--i:13;"></span>
      <span style="--i:26;"></span>
      <span style="--i:28;"></span>
    </div>
  </div>
  <style>
    *
    {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    .balls-container
    { 
      position: fixed;
      top: 0px;
      left: 0px;
      width: 100%;
      height: 100vh;
      overflow: hidden;
      opacity: 0.3;
    }
    
    .balls-particles
    {
      position: fixed;
      display: flex;
      z-index: 3;
      padding: 0 20px;
    }
    
    .balls-particles span
    {
      position: relative;
      bottom: 30px;
      width: 30px;
      height: 30px;
      background-color: #4fc3dc;
      box-shadow: 0 0 0 10px #4fc3dc44,
      0 0 50px #4fc3dc,
      -100px 0 #4fc3dc99,
      100px 0 #ff2d7599;
      margin: 0 4px;
      border-radius: 50%;
      animation: animate 15s ease infinite;
      animation-delay: calc(125s / var(--i));
      transform: translateY(120vh);
    }
    .balls-particles span:nth-child(even) {
      background-color: #ff2d75;
      box-shadow: 0 0 0 10px #ff267544,
      0 0 50px #ff2d75,
      -100px 0 #4fc3dc99,
      100px 0 #4fc3dc99;
      ;
    }
    
    @keyframes animate {
      0%
      {
        transform: translateY(120vh) scale(0) rotate(0deg);
      }
      20%
      {
        transform: translateY(100vh) scale(1) rotate(0deg);
      }
      100%
      {
        transform: translateY(-50vh) scale(0.5) rotate(360deg);
      }
    }
  </style> -->
  <!-- 地月系统 -->
  <!-- <div class="earth-container" >
    <div class="planet"></div>
    <div class="satellite"></div>
   </div>
   <style>
    *{
      padding: 0;
      margin: 0;
      }
      .earth-container {
        width: 36.25em;
        height: 36.25em;
        position: absolute;
        top:5%;
        left: 93%;
        transform: translate(-50%, -50%);
        opacity: 0.3;
      }
      
      .planet{
        width: 15.62*3em;
        height: 15.62*3em;
        background-color: #02c0f5;
        border-radius: 50%;
        position: absolute;
        margin: auto;
        top:0;
        right: 0;
        bottom: 0;
        left: 0;
        z-index: 1;
      }
      
      .planet::before{
        content: '';
        width: 4em;
        height: 4em;
        background-color: #008fd6;
        position: absolute;
        top:10em;
        left: 8em;
        border-radius: 50%; 
        box-shadow: 15em 15em 0 2em #00d68b, 5em 8em 0 3em #10ade1;
      }
      
      .satellite{
        width: 5em;
        height: 5em;
        background-color: #dee517;
        border-radius: 50%;
        position: relative;
        left: -5em;
        bottom: -30em;
        animation: spin 5s infinite;
        z-index: 1;
      }
      
      @keyframes spin {
        49%{
          z-index: 1;
        }
        50%{
          bottom: 3em;
          left: 35em;
          z-index: -1;
        }
        100%{
          z-index: -1;
        }
      }
    </style> -->
<!-- 三角彩带背景 -->
  <canvas id="evanyou-canvas" style="opacity: 0.3; position: fixed; top: 0px; left: 0px; z-index: -1; width: 100%; height: 100%; pointer-events: none;"></canvas>
  <script src="https://cdn.jsdelivr.net/gh/XXXZhy/Blog_Image/js/evanyou_canvas.js"></script>
</body>

</html>