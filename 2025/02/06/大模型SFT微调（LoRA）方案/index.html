<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta name="description" content="一个秘密空间" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>大模型SFT微调（LoRA）方案 |  LegendLeo Chen 的空间</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/mylogo.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
<!-- 封面标闪烁 -->
<link rel="stylesheet" href="/css/zhyBlogTitle.css">
<script src="https://cdn.bootcdn.net/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- jquery，懒加载、统计、说说需要的jquery -->
<script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-大模型SFT微调（LoRA）方案"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  大模型SFT微调（LoRA）方案
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/02/06/%E5%A4%A7%E6%A8%A1%E5%9E%8BSFT%E5%BE%AE%E8%B0%83%EF%BC%88LoRA%EF%BC%89%E6%96%B9%E6%A1%88/" class="article-date">
  <time datetime="2025-02-06T12:22:13.000Z" itemprop="datePublished">2025-02-06</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%99%E7%A8%8B/">教程</a> / <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">1.4k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">5 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>本次借助huggingface平台下载大模型和数据集，并在本地尝试进行微调，目的是跑通并体验微调过程。微调使用的是参数高效微调也就是PEFT，策略是有监督微调SFT，使用的具体方法是LoRA。<span id="more"></span><br><strong>注意：huggingface下载都是需要代理的，文中出现的python库自行用pip安装即可。</strong></p>
<h1 id="🔥模型下载"><a href="#🔥模型下载" class="headerlink" title="🔥模型下载"></a>🔥模型下载</h1><p><a target="_blank" rel="noopener" href="https://huggingface.co/">huggingface</a>上选择模型，这里以Qwen&#x2F;Qwen2.5-3B-Instruct为例。</p>
<ul>
<li><p>如下图可以直接在界面中的files and versions中下载模型，把所有文件下载进一个文件夹即可。<br><img src="/2025/02/06/%E5%A4%A7%E6%A8%A1%E5%9E%8BSFT%E5%BE%AE%E8%B0%83%EF%BC%88LoRA%EF%BC%89%E6%96%B9%E6%A1%88/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9.jpg" alt="huggingface模型界面"></p>
</li>
<li><p>也可以通过命令行一次性下载，先通过<code>pip install -U huggingface_hub</code>安装命令行工具，在cmd中通过以下指令登录huggingface并下载模型：</p>
</li>
</ul>
<pre class="line-numbers language-bash"><code class="language-bash">huggingface-cli login
huggingface-cli download --resume-download Qwen/Qwen2.5-3B-Instruct --local-dir D://你的存储路径
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<ul>
<li>首先第一句指令登录，会让你输入huggingface个人账户界面的access tokens的令牌，输入后即可通过第二条指令下载模型到指定位置。</li>
</ul>
<h1 id="🔥数据集下载"><a href="#🔥数据集下载" class="headerlink" title="🔥数据集下载"></a>🔥数据集下载</h1><p><a target="_blank" rel="noopener" href="https://huggingface.co/">huggingface</a>上选择数据集，以弱智吧数据集 LooksJuicy&#x2F;ruozhiba 为例。</p>
<ul>
<li>通过python的datasets库可以直接下载源文件：</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> load_dataset<span class="token punctuation">,</span> load_from_disk
<span class="token keyword">import</span> os

<span class="token comment" spellcheck="true"># 配置你的代理</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTP_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTPS_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span>

dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"LooksJuicy/ruozhiba"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">.</span>save_to_disk<span class="token punctuation">(</span><span class="token string">"./datasets/ruozhiba"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 保存到该目录下</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/2025/02/06/%E5%A4%A7%E6%A8%A1%E5%9E%8BSFT%E5%BE%AE%E8%B0%83%EF%BC%88LoRA%EF%BC%89%E6%96%B9%E6%A1%88/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A0%BC%E5%BC%8F.jpg" alt="数据集格式"></p>
<ul>
<li>这样只是下载源文件没有进行处理，在官网可以预览文件内容如上，该数据集由 instruction 和 output 组成，比较简单。</li>
<li>我们可以直接通过如下代码进行预处理，思路就是缓存数据集源文件并转换成可以用于训练的message（json格式），最后保存到json文件当中，这次不划分数据集，直接全部用于训练。</li>
<li>缓存是不会自动清掉的，可以在C盘的.cache里面手动删掉。</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_from_disk<span class="token punctuation">,</span> load_dataset
<span class="token keyword">import</span> os

<span class="token comment" spellcheck="true"># 配置代理</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTP_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTPS_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span>
<span class="token comment" spellcheck="true"># 系统 prompt，可以自行设置</span>
system_message <span class="token operator">=</span> <span class="token string">"回答问题"</span>

<span class="token comment" spellcheck="true"># 转换为 messages</span>
<span class="token keyword">def</span> <span class="token function">create_conversation</span><span class="token punctuation">(</span>sample<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span>
        <span class="token string">"messages"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> system_message<span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> sample<span class="token punctuation">[</span><span class="token string">"instruction"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> sample<span class="token punctuation">[</span><span class="token string">"output"</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
        <span class="token punctuation">]</span>
    <span class="token punctuation">}</span>

<span class="token comment" spellcheck="true"># 从 hub 加载数据集</span>
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"LooksJuicy/ruozhiba"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 转换 dataset 为 OAI messages</span>
dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span>create_conversation<span class="token punctuation">,</span> remove_columns<span class="token operator">=</span>dataset<span class="token punctuation">.</span>features<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token number">345</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"messages"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 保存到磁盘</span>
dataset<span class="token punctuation">.</span>to_json<span class="token punctuation">(</span><span class="token string">"train_dataset.json"</span><span class="token punctuation">,</span> orient<span class="token operator">=</span><span class="token string">"records"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="🔥微调"><a href="#🔥微调" class="headerlink" title="🔥微调"></a>🔥微调</h1><ul>
<li>有了数据集和模型，就可以进行微调了，这里以LoRA微调为例，使用transformers、trld等库进行微调。</li>
<li>主要流程就是加载数据集、加载模型及其分词器、配置LoRA参数、配置训练参数，最后就可以定义训练器进行训练了。流程上和传统深度学习一样，只不过对应的库都进行了封装，不需要手动编写训练的常规流程。</li>
<li>超参数可以自行调整，<strong>减少显存占用</strong>可以降低批次大小<code>per_device_train_batch_size</code>和梯度积累<code>gradient_accumulation_steps</code>，<strong>减少训练总时长</strong>可以减少迭代数<code>num_train_epochs</code>（可以小于1）或调整批次大小。其他参数可以自行尝试。</li>
<li>注意：生成的LoRA模型是<strong>增量模型</strong>，也就是依赖原模型存在，所以生成的模型不会很大，如有需要可以自行查找方法来保存完整模型。</li>
<li>代码如下：</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">,</span> os
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM<span class="token punctuation">,</span> BitsAndBytesConfig
<span class="token keyword">from</span> trl <span class="token keyword">import</span> SFTTrainer<span class="token punctuation">,</span> setup_chat_format
<span class="token keyword">from</span> peft <span class="token keyword">import</span> LoraConfig
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">,</span> message<span class="token operator">=</span><span class="token string">"`tokenizer` is deprecated"</span><span class="token punctuation">)</span>
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">,</span> message<span class="token operator">=</span><span class="token string">"`use_cache=True` is incompatible"</span><span class="token punctuation">)</span>
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">,</span> message<span class="token operator">=</span><span class="token string">"torch.utils.checkpoint: please pass in use_reentrant"</span><span class="token punctuation">)</span>
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">,</span> message<span class="token operator">=</span><span class="token string">"Torch was not compiled with flash attention"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 设置设备和环境</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 加载数据集</span>
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span><span class="token string">"train_dataset.json所在路径"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 加载模型和分词器</span>
model_id <span class="token operator">=</span> <span class="token string">"qwen2.5-3b模型文件夹的路径"</span>
bnb_config <span class="token operator">=</span> BitsAndBytesConfig<span class="token punctuation">(</span>
    load_in_4bit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    bnb_4bit_use_double_quant<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    bnb_4bit_quant_type<span class="token operator">=</span><span class="token string">"nf4"</span><span class="token punctuation">,</span>
    bnb_4bit_compute_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bfloat16
<span class="token punctuation">)</span>

model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    model_id<span class="token punctuation">,</span>
    device_map<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span>
    torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bfloat16<span class="token punctuation">,</span>
    quantization_config<span class="token operator">=</span>bnb_config<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>padding_side <span class="token operator">=</span> <span class="token string">'right'</span>

<span class="token comment" spellcheck="true"># 配置LoRA</span>
peft_config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>
    lora_alpha<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    lora_dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
    r<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
    bias<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span>
    task_type<span class="token operator">=</span><span class="token string">"CAUSAL_LM"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 定义训练参数</span>
args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"保存模型的路径"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>
    gradient_accumulation_steps<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
    gradient_checkpointing<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    optim<span class="token operator">=</span><span class="token string">"adamw_torch_fused"</span><span class="token punctuation">,</span>
    logging_steps<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
    save_strategy<span class="token operator">=</span><span class="token string">"steps"</span><span class="token punctuation">,</span>
    save_steps<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span>
    fp16<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 启用 fp16 混合精度训练</span>
    max_grad_norm<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>
    warmup_ratio<span class="token operator">=</span><span class="token number">0.03</span><span class="token punctuation">,</span>
    lr_scheduler_type<span class="token operator">=</span><span class="token string">"constant"</span><span class="token punctuation">,</span>
    push_to_hub<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    report_to<span class="token operator">=</span><span class="token string">"tensorboard"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建SFTTrainer</span>
trainer <span class="token operator">=</span> SFTTrainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>
    peft_config<span class="token operator">=</span>peft_config<span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 开始训练</span>
trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
trainer<span class="token punctuation">.</span>save_model<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 清理内存</span>
<span class="token keyword">del</span> model
<span class="token keyword">del</span> trainer
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="🔥测试"><a href="#🔥测试" class="headerlink" title="🔥测试"></a>🔥测试</h1><ul>
<li>训练完成后就可以进行问答，通过以下脚本实现，测试时为了使得模型稳定生成结果，可以将温度值<code>temperature</code>调小一些。</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

<span class="token comment" spellcheck="true"># 加载模型</span>
pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"微调后的模型文件夹"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 提供输入</span>
input_text <span class="token operator">=</span> <span class="token string">"为什么我的银行卡在高压锅里煮了一晚上，还是冻结状态？"</span>

<span class="token comment" spellcheck="true"># 调整生成参数</span>
output <span class="token operator">=</span> pipe<span class="token punctuation">(</span>
    input_text<span class="token punctuation">,</span>
    max_length<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 增加生成的最大长度</span>
    num_return_sequences<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 生成多个序列</span>
    temperature<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/2025/02/06/%E5%A4%A7%E6%A8%A1%E5%9E%8BSFT%E5%BE%AE%E8%B0%83%EF%BC%88LoRA%EF%BC%89%E6%96%B9%E6%A1%88/%E6%B5%8B%E8%AF%95.png" alt="测试结果"></p>
<ul>
<li>可以看到模型是可以应对弱智吧的问题。</li>
</ul>
<h1 id="🔥总结"><a href="#🔥总结" class="headerlink" title="🔥总结"></a>🔥总结</h1><p>通过该方案可以比较容易地上手微调，但是微调本身还是很吃算力的，即便是这种参数高效微调对个人电脑也相当慢，效果也不一定好，像传统深度学习训练一样，也需要很多调整。所以只是用于尝试和体验微调过程，丰富相关经验，增强知识的理解。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://legendleochen.top/2025/02/06/%E5%A4%A7%E6%A8%A1%E5%9E%8BSFT%E5%BE%AE%E8%B0%83%EF%BC%88LoRA%EF%BC%89%E6%96%B9%E6%A1%88/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LORA/" rel="tag">LORA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PEFT/" rel="tag">PEFT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SFT/" rel="tag">SFT</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/2025/01/04/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%8ARAG%E6%9E%B6%E6%9E%84%E7%9A%84%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">大模型及RAG架构的本地部署</div>
      </a>
    
  </nav>

  
   
  
    
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2023-2025
        <i class="ri-heart-fill heart_icon"></i> LegendLeo Chen
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/mylogo.png" alt="LegendLeo Chen 的空间"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">🚀主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">💾归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">🧭分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">🏷️标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">🛸关于</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/analytics">📊统计</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/secret">🔐秘密</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=1491212&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
  <!-- 背景气泡 -->
  <!--
  <div class="balls-container">
    <div class="balls-particles">
      <span style="--i:11;"></span>
      <span style="--i:12;"></span>
      <span style="--i:24;"></span>
      <span style="--i:10;"></span>
      <span style="--i:14;"></span>
      <span style="--i:23;"></span>
      <span style="--i:18;"></span>
      <span style="--i:16;"></span>
      <span style="--i:19;"></span>
      <span style="--i:20;"></span>
      <span style="--i:22;"></span>
      <span style="--i:25;"></span>
      <span style="--i:18;"></span>
      <span style="--i:21;"></span>
      <span style="--i:13;"></span>
      <span style="--i:15;"></span>
      <span style="--i:26;"></span>
      <span style="--i:17;"></span>
      <span style="--i:13;"></span>
      <span style="--i:26;"></span>
      <span style="--i:28;"></span>
      <span style="--i:11;"></span>
      <span style="--i:12;"></span>
      <span style="--i:24;"></span>
      <span style="--i:10;"></span>
      <span style="--i:14;"></span>
      <span style="--i:23;"></span>
      <span style="--i:18;"></span>
      <span style="--i:16;"></span>
      <span style="--i:19;"></span>
      <span style="--i:20;"></span>
      <span style="--i:22;"></span>
      <span style="--i:25;"></span>
      <span style="--i:18;"></span>
      <span style="--i:21;"></span>
      <span style="--i:13;"></span>
      <span style="--i:15;"></span>
      <span style="--i:26;"></span>
      <span style="--i:17;"></span>
      <span style="--i:13;"></span>
      <span style="--i:26;"></span>
      <span style="--i:28;"></span>
    </div>
  </div>
  <style>
    *
    {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    .balls-container
    { 
      position: fixed;
      top: 0px;
      left: 0px;
      width: 100%;
      height: 100vh;
      overflow: hidden;
      opacity: 0.3;
    }
    
    .balls-particles
    {
      position: fixed;
      display: flex;
      z-index: 3;
      padding: 0 20px;
    }
    
    .balls-particles span
    {
      position: relative;
      bottom: 30px;
      width: 30px;
      height: 30px;
      background-color: #4fc3dc;
      box-shadow: 0 0 0 10px #4fc3dc44,
      0 0 50px #4fc3dc,
      -100px 0 #4fc3dc99,
      100px 0 #ff2d7599;
      margin: 0 4px;
      border-radius: 50%;
      animation: animate 15s ease infinite;
      animation-delay: calc(125s / var(--i));
      transform: translateY(120vh);
    }
    .balls-particles span:nth-child(even) {
      background-color: #ff2d75;
      box-shadow: 0 0 0 10px #ff267544,
      0 0 50px #ff2d75,
      -100px 0 #4fc3dc99,
      100px 0 #4fc3dc99;
      ;
    }
    
    @keyframes animate {
      0%
      {
        transform: translateY(120vh) scale(0) rotate(0deg);
      }
      20%
      {
        transform: translateY(100vh) scale(1) rotate(0deg);
      }
      100%
      {
        transform: translateY(-50vh) scale(0.5) rotate(360deg);
      }
    }
  </style> -->
  <!-- 地月系统 -->
  <!-- <div class="earth-container" >
    <div class="planet"></div>
    <div class="satellite"></div>
   </div>
   <style>
    *{
      padding: 0;
      margin: 0;
      }
      .earth-container {
        width: 36.25em;
        height: 36.25em;
        position: absolute;
        top:5%;
        left: 93%;
        transform: translate(-50%, -50%);
        opacity: 0.3;
      }
      
      .planet{
        width: 15.62*3em;
        height: 15.62*3em;
        background-color: #02c0f5;
        border-radius: 50%;
        position: absolute;
        margin: auto;
        top:0;
        right: 0;
        bottom: 0;
        left: 0;
        z-index: 1;
      }
      
      .planet::before{
        content: '';
        width: 4em;
        height: 4em;
        background-color: #008fd6;
        position: absolute;
        top:10em;
        left: 8em;
        border-radius: 50%; 
        box-shadow: 15em 15em 0 2em #00d68b, 5em 8em 0 3em #10ade1;
      }
      
      .satellite{
        width: 5em;
        height: 5em;
        background-color: #dee517;
        border-radius: 50%;
        position: relative;
        left: -5em;
        bottom: -30em;
        animation: spin 5s infinite;
        z-index: 1;
      }
      
      @keyframes spin {
        49%{
          z-index: 1;
        }
        50%{
          bottom: 3em;
          left: 35em;
          z-index: -1;
        }
        100%{
          z-index: -1;
        }
      }
    </style> -->
<!-- 三角彩带背景 -->
  <canvas id="evanyou-canvas" style="opacity: 0.3; position: fixed; top: 0px; left: 0px; z-index: -1; width: 100%; height: 100%; pointer-events: none;"></canvas>
  <script src="https://cdn.jsdelivr.net/gh/XXXZhy/Blog_Image/js/evanyou_canvas.js"></script>
</body>

</html>